{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Des mots aux sacs de mots\n",
        "\n",
        "La tokenisation consiste \u00e0 d\u00e9couper un texte en *token*, l'approche *sac de mots* consiste \u00e0 compter les occurences de chaque mot dans chaque document de la base de donn\u00e9es."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "texte = \"\"\"\n",
        "Mardi 20 f\u00e9vrier, \u00e0 la m\u00e9diath\u00e8que des Mureaux (Yvelines), le chef de l\u2019Etat a accompagn\u00e9 \n",
        "la locataire de la rue de Valois pour la remise officielle du rapport \n",
        "sur les biblioth\u00e8ques, r\u00e9dig\u00e9 par leur ami commun, l\u2019acad\u00e9micien \n",
        "Erik Orsenna, avec le concours de No\u00ebl Corbin, inspecteur g\u00e9n\u00e9ral \n",
        "des affaires culturelles. L\u2019occasion de pr\u00e9senter les premi\u00e8res \n",
        "mesures en faveur d\u2019un \u00ab plan biblioth\u00e8ques \u00bb.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline de traitement\n",
        "\n",
        "Maintenant qu'on sait d\u00e9couper en mots ou couples de mots, il faut appliquer sur une liste de textes. On cr\u00e9e une petite liste de textes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\nMardi 20 f\u00e9vrier, \u00e0 la m\u00e9diath\u00e8que des Murea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tout petit texte</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  \\nMardi 20 f\u00e9vrier, \u00e0 la m\u00e9diath\u00e8que des Murea...\n",
              "1                                   tout petit texte"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas\n",
        "df = pandas.DataFrame(dict(text=[texte, \"tout petit texte\"]))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et on applique l'objet [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<2x51 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 51 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cd = CountVectorizer()\n",
        "cd.fit(df[\"text\"])\n",
        "res = cd.transform(df[\"text\"])\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On r\u00e9cup\u00e8re une [matrice sparse](https://docs.scipy.org/doc/scipy/reference/sparse.html) o\u00f9 chaque colonne compte le nombre d'occurence d'un mot dans le texte :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 5, 2, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 4, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 0, 0, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les mots sont les suivants :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'20': 0,\n",
              " 'acad\u00e9micien': 1,\n",
              " 'accompagn\u00e9': 2,\n",
              " 'affaires': 3,\n",
              " 'ami': 4,\n",
              " 'avec': 5,\n",
              " 'biblioth\u00e8ques': 6,\n",
              " 'chef': 7,\n",
              " 'commun': 8,\n",
              " 'concours': 9,\n",
              " 'corbin': 10,\n",
              " 'culturelles': 11,\n",
              " 'de': 12,\n",
              " 'des': 13,\n",
              " 'du': 14,\n",
              " 'en': 15,\n",
              " 'erik': 16,\n",
              " 'etat': 17,\n",
              " 'faveur': 18,\n",
              " 'f\u00e9vrier': 19,\n",
              " 'g\u00e9n\u00e9ral': 20,\n",
              " 'inspecteur': 21,\n",
              " 'la': 22,\n",
              " 'le': 23,\n",
              " 'les': 24,\n",
              " 'leur': 25,\n",
              " 'locataire': 26,\n",
              " 'mardi': 27,\n",
              " 'mesures': 28,\n",
              " 'mureaux': 29,\n",
              " 'm\u00e9diath\u00e8que': 30,\n",
              " 'no\u00ebl': 31,\n",
              " 'occasion': 32,\n",
              " 'officielle': 33,\n",
              " 'orsenna': 34,\n",
              " 'par': 35,\n",
              " 'petit': 36,\n",
              " 'plan': 37,\n",
              " 'pour': 38,\n",
              " 'premi\u00e8res': 39,\n",
              " 'pr\u00e9senter': 40,\n",
              " 'rapport': 41,\n",
              " 'remise': 42,\n",
              " 'rue': 43,\n",
              " 'r\u00e9dig\u00e9': 44,\n",
              " 'sur': 45,\n",
              " 'texte': 46,\n",
              " 'tout': 47,\n",
              " 'un': 48,\n",
              " 'valois': 49,\n",
              " 'yvelines': 50}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cd.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Un tokenizer diff\u00e9rent\n",
        "\n",
        "La classe [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) est facilement param\u00e9trable. On peut en particulier changer le *tokenizer* :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 62)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vect = CountVectorizer(tokenizer=word_tokenize)\n",
        "counts = count_vect.fit_transform(df[\"text\"])\n",
        "counts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[1, 1, 6, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 5, 2, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 3, 4, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 4],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
              "       dtype=int64)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counts.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hashing\n",
        "\n",
        "Le nombre de mots distincts peut \u00eatre tr\u00e8s grand surtout si la source des textes est bruit\u00e9e (faute d'orthographe, spams, ...). Pour r\u00e9duire le nombre de mots, on peut utiliser un *hash* \u00e0 valeur dans un ensemble plus petit que le nombre de mots d\u00e9couverts : c'est une sorte de modulo. Deux mots pourront \u00eatre comptabilis\u00e9s dans la m\u00eame colonne. On utilise la classe [HashingVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[-0.08247861,  0.16495722, -0.41239305,  0.74230749,  0.49487166],\n",
              "        [-0.4472136 ,  0.        ,  0.89442719,  0.        ,  0.        ]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "cd = HashingVectorizer(n_features=5)\n",
        "cd.fit(df[\"text\"])\n",
        "res = cd.transform(df[\"text\"])\n",
        "res.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La classe utilise la classe [FeatureHasher](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html) et plus pr\u00e9cis\u00e9ment le code dans [_hashing.pyx](https://github.com/scikit-learn/scikit-learn/blob/a24c8b464d094d2c468a16ea9f8bf8d42d949f84/sklearn/feature_extraction/_hashing.pyx)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[0.4472136 , 0.4472136 , 0.4472136 , 0.4472136 , 0.4472136 ],\n",
              "        [0.70710678, 0.        , 0.70710678, 0.        , 0.        ]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cd = HashingVectorizer(n_features=5, binary=True)\n",
        "cd.fit(df[\"text\"])\n",
        "res = cd.transform(df[\"text\"])\n",
        "res.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "R\u00e9duire les dimensions tout en gardant une certaine forme de proximit\u00e9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\nMardi 20 f\u00e9vrier, \u00e0 la m\u00e9diath\u00e8que des Murea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20 f\u00e9vrier, \u00e0 la m\u00e9diath\u00e8que des Mureaux (Yvel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>m\u00e9diath\u00e8que des Mureaux (Yvelines), le chef de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chef de l\u2019Etat a accompagn\u00e9 la locataire de la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>de Valois pour la remise officielle du rapport...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>officielle du rapport sur les biblioth\u00e8ques, r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>biblioth\u00e8ques, r\u00e9dig\u00e9 par nouveau</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tout petit texte</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  \\nMardi 20 f\u00e9vrier, \u00e0 la m\u00e9diath\u00e8que des Murea...\n",
              "1  20 f\u00e9vrier, \u00e0 la m\u00e9diath\u00e8que des Mureaux (Yvel...\n",
              "2  m\u00e9diath\u00e8que des Mureaux (Yvelines), le chef de...\n",
              "3  chef de l\u2019Etat a accompagn\u00e9 la locataire de la...\n",
              "4  de Valois pour la remise officielle du rapport...\n",
              "5  officielle du rapport sur les biblioth\u00e8ques, r...\n",
              "6                  biblioth\u00e8ques, r\u00e9dig\u00e9 par nouveau\n",
              "7                                   tout petit texte"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = pandas.DataFrame(dict(text=[texte, \n",
        "                                  \" \".join(texte.split()[1:-1]), \n",
        "                                  \" \".join(texte.split()[5:-5]), \n",
        "                                  \" \".join(texte.split()[10:-10]) + ' machine', \n",
        "                                  \" \".join(texte.split()[20:-20]) + ' learning', \n",
        "                                  \" \".join(texte.split()[25:-25]) + ' statistique', \n",
        "                                  \" \".join(texte.split()[30:-30]) + ' nouveau', \n",
        "                                  \"tout petit texte\"]))\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[-0.08873565,  0.3549426 , -0.1774713 ,  0.        , -0.26620695,\n",
              "          0.        ,  0.79862086,  0.3549426 ],\n",
              "        [-0.09053575,  0.36214298, -0.18107149,  0.        , -0.18107149,\n",
              "          0.        ,  0.81482171,  0.36214298],\n",
              "        [-0.10783277,  0.43133109, -0.21566555,  0.        ,  0.        ,\n",
              "          0.        ,  0.75482941,  0.43133109],\n",
              "        [-0.24806947,  0.3721042 ,  0.        , -0.12403473, -0.12403473,\n",
              "          0.        ,  0.86824314,  0.12403473],\n",
              "        [-0.20412415,  0.81649658,  0.        ,  0.20412415,  0.20412415,\n",
              "          0.20412415,  0.40824829,  0.        ],\n",
              "        [ 0.        ,  0.35355339,  0.35355339,  0.35355339,  0.        ,\n",
              "          0.70710678, -0.35355339,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.70710678, -0.70710678],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  1.        ,  0.        ]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cd = HashingVectorizer(n_features=8, binary=False)\n",
        "cd.fit(df2[\"text\"])\n",
        "res = cd.transform(df2[\"text\"])\n",
        "res.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.087352</td>\n",
              "      <td>0.293731</td>\n",
              "      <td>0.388511</td>\n",
              "      <td>0.916931</td>\n",
              "      <td>1.561800</td>\n",
              "      <td>1.171556</td>\n",
              "      <td>0.634632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.087352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.217844</td>\n",
              "      <td>0.368633</td>\n",
              "      <td>0.883337</td>\n",
              "      <td>1.564650</td>\n",
              "      <td>1.166111</td>\n",
              "      <td>0.608569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.293731</td>\n",
              "      <td>0.217844</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.455795</td>\n",
              "      <td>0.797058</td>\n",
              "      <td>1.543129</td>\n",
              "      <td>1.241976</td>\n",
              "      <td>0.700244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.388511</td>\n",
              "      <td>0.368633</td>\n",
              "      <td>0.455795</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.826704</td>\n",
              "      <td>1.561579</td>\n",
              "      <td>0.973412</td>\n",
              "      <td>0.513336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.916931</td>\n",
              "      <td>0.883337</td>\n",
              "      <td>0.797058</td>\n",
              "      <td>0.826704</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.130625</td>\n",
              "      <td>1.192749</td>\n",
              "      <td>1.087889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.561800</td>\n",
              "      <td>1.564650</td>\n",
              "      <td>1.543129</td>\n",
              "      <td>1.561579</td>\n",
              "      <td>1.130625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.581139</td>\n",
              "      <td>1.645329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.171556</td>\n",
              "      <td>1.166111</td>\n",
              "      <td>1.241976</td>\n",
              "      <td>0.973412</td>\n",
              "      <td>1.192749</td>\n",
              "      <td>1.581139</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.765367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.634632</td>\n",
              "      <td>0.608569</td>\n",
              "      <td>0.700244</td>\n",
              "      <td>0.513336</td>\n",
              "      <td>1.087889</td>\n",
              "      <td>1.645329</td>\n",
              "      <td>0.765367</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0  0.000000  0.087352  0.293731  0.388511  0.916931  1.561800  1.171556   \n",
              "1  0.087352  0.000000  0.217844  0.368633  0.883337  1.564650  1.166111   \n",
              "2  0.293731  0.217844  0.000000  0.455795  0.797058  1.543129  1.241976   \n",
              "3  0.388511  0.368633  0.455795  0.000000  0.826704  1.561579  0.973412   \n",
              "4  0.916931  0.883337  0.797058  0.826704  0.000000  1.130625  1.192749   \n",
              "5  1.561800  1.564650  1.543129  1.561579  1.130625  0.000000  1.581139   \n",
              "6  1.171556  1.166111  1.241976  0.973412  1.192749  1.581139  0.000000   \n",
              "7  0.634632  0.608569  0.700244  0.513336  1.087889  1.645329  0.765367   \n",
              "\n",
              "          7  \n",
              "0  0.634632  \n",
              "1  0.608569  \n",
              "2  0.700244  \n",
              "3  0.513336  \n",
              "4  1.087889  \n",
              "5  1.645329  \n",
              "6  0.765367  \n",
              "7  0.000000  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "pandas.DataFrame(pairwise_distances(res))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## tf-idf\n",
        "\n",
        "Ce genre de technique produit des matrices de tr\u00e8s grande dimension qu'il faut r\u00e9duire. On peut enlever les mots rares ou les mots tr\u00e8s fr\u00e9quents. [td-idf](https://fr.wikipedia.org/wiki/TF-IDF>) est une technique qui vient des moteurs de recherche. Elle construit le m\u00eame type de matrice (m\u00eame dimension) mais associe \u00e0 chaque couple (document - mot) un poids qui d\u00e9pend de la fr\u00e9quence d'un mot globalement et du nombre de documents contenant ce mot.\n",
        "\n",
        "$$idf(t) = \\log \\frac{\\# D}{\\#\\{d \\; | \\; t \\in d \\}}$$\n",
        "\n",
        "O\u00f9 :\n",
        "\n",
        "- $\\#D$ est le nombre de documents\n",
        "- $\\#\\{d \\; | \\; t \\in d \\}$ est le nombre de documents contenant le mot $t$\n",
        "\n",
        "$f(t,d)$ est le nombre d'occurences d'un mot $t$ dans un document $d$.\n",
        "\n",
        "$$tf(t,d) = \\frac{1}{2} + \\frac{1}{2} \\frac{f(t,d)}{\\max_{t' \\in d} f(t',d)}$$\n",
        "\n",
        "On construit le nombre $tfidf(t,f) = tf(t,d) idf(t)$ :\n",
        "\n",
        "Le terme $idf(t)$ favorise les mots pr\u00e9sent dans peu de documents, le terme $tf(t,f)$ favorise les termes r\u00e9p\u00e9t\u00e9s un grand nombre de fois dans le m\u00eame document. On applique \u00e0 la matrice pr\u00e9c\u00e9dente. Sur deux documents, cela ne sert pas \u00e0 grand-chose. On utilise la classe [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.20100756, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.50251891, 0.20100756, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.40201513, 0.20100756, 0.20100756,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.        , 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.        , 0.        , 0.10050378, 0.10050378,\n",
              "         0.10050378],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.57735027, 0.57735027, 0.        , 0.        ,\n",
              "         0.        ]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "cd = TfidfVectorizer()\n",
        "cd.fit(df[\"text\"])\n",
        "res = cd.transform(df[\"text\"])\n",
        "res.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si on d\u00e9compose "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.20100756, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.50251891, 0.20100756, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.40201513, 0.20100756, 0.20100756,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.        , 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.        , 0.        , 0.10050378, 0.10050378,\n",
              "         0.10050378],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.57735027, 0.57735027, 0.        , 0.        ,\n",
              "         0.        ]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "pipe = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
        "pipe.fit(df['text'])\n",
        "res = pipe.transform(df['text'])\n",
        "res.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ca marche aussi sur les hash."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[-0.06142775,  0.17266912, -0.30713875,  0.77701104,  0.51800736],\n",
              "        [-0.4472136 ,  0.        ,  0.89442719,  0.        ,  0.        ]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe = make_pipeline(HashingVectorizer(n_features=5), TfidfTransformer())\n",
        "pipe.fit(df['text'])\n",
        "res = pipe.transform(df['text'])\n",
        "res.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sur un jeu de donn\u00e9es\n",
        "\n",
        "L'id\u00e9e est d'appliquer une LDA ou [Latent Dirichet Application](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <td>776066992054861825</td>\n",
              "      <td>776067660979245056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb_user_mentions</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb_extended_entities</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb_hashtags</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>geo</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_hashtags</th>\n",
              "      <td>, SiJ\u00e9taisPr\u00e9sident</td>\n",
              "      <td>, SiJ\u00e9taisPr\u00e9sident</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>annee</th>\n",
              "      <td>2016</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delimit_mention</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lang</th>\n",
              "      <td>fr</td>\n",
              "      <td>fr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_str</th>\n",
              "      <td>7.76067e+17</td>\n",
              "      <td>7.76068e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_mention</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retweet_count</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>favorite_count</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>type_extended_entities</th>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>#SiJ\u00e9taisPr\u00e9sident se serait la fin du monde.....</td>\n",
              "      <td>#SiJ\u00e9taisPr\u00e9sident je donnerai plus de vacance...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb_user_photos</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb_urls</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb_symbols</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>created_at</th>\n",
              "      <td>Wed Sep 14 14:36:04 +0000 2016</td>\n",
              "      <td>Wed Sep 14 14:38:43 +0000 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delimit_hash</th>\n",
              "      <td>, 0, 18</td>\n",
              "      <td>, 0, 18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                        0  \\\n",
              "index                                                  776066992054861825   \n",
              "nb_user_mentions                                                        0   \n",
              "nb_extended_entities                                                    0   \n",
              "nb_hashtags                                                             1   \n",
              "geo                                                                   NaN   \n",
              "text_hashtags                                         , SiJ\u00e9taisPr\u00e9sident   \n",
              "annee                                                                2016   \n",
              "delimit_mention                                                       NaN   \n",
              "lang                                                                   fr   \n",
              "id_str                                                        7.76067e+17   \n",
              "text_mention                                                          NaN   \n",
              "retweet_count                                                           4   \n",
              "favorite_count                                                          3   \n",
              "type_extended_entities                                                 []   \n",
              "text                    #SiJ\u00e9taisPr\u00e9sident se serait la fin du monde.....   \n",
              "nb_user_photos                                                          0   \n",
              "nb_urls                                                                 0   \n",
              "nb_symbols                                                              0   \n",
              "created_at                                 Wed Sep 14 14:36:04 +0000 2016   \n",
              "delimit_hash                                                      , 0, 18   \n",
              "\n",
              "                                                                        1  \n",
              "index                                                  776067660979245056  \n",
              "nb_user_mentions                                                        0  \n",
              "nb_extended_entities                                                    0  \n",
              "nb_hashtags                                                             1  \n",
              "geo                                                                   NaN  \n",
              "text_hashtags                                         , SiJ\u00e9taisPr\u00e9sident  \n",
              "annee                                                                2016  \n",
              "delimit_mention                                                       NaN  \n",
              "lang                                                                   fr  \n",
              "id_str                                                        7.76068e+17  \n",
              "text_mention                                                          NaN  \n",
              "retweet_count                                                           5  \n",
              "favorite_count                                                          8  \n",
              "type_extended_entities                                                 []  \n",
              "text                    #SiJ\u00e9taisPr\u00e9sident je donnerai plus de vacance...  \n",
              "nb_user_photos                                                          0  \n",
              "nb_urls                                                                 0  \n",
              "nb_symbols                                                              0  \n",
              "created_at                                 Wed Sep 14 14:38:43 +0000 2016  \n",
              "delimit_hash                                                      , 0, 18  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from papierstat.datasets import load_tweet_dataset\n",
        "tweet = load_tweet_dataset()\n",
        "tweet = tweet[tweet[\"text\"].notnull()]\n",
        "tweet.head(n=2).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
        "res = pipeline.fit_transform(tweet['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "count = pipeline.steps[0][-1]\n",
        "voc = count.get_feature_names()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le code suivant marche parce que la base n'est pas trop petite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>0000</th>\n",
              "      <th>0079</th>\n",
              "      <th>00h</th>\n",
              "      <th>04</th>\n",
              "      <th>06</th>\n",
              "      <th>09</th>\n",
              "      <th>0ccnpoxuwu</th>\n",
              "      <th>0cxdedblpx</th>\n",
              "      <th>...</th>\n",
              "      <th>\u00eele</th>\n",
              "      <th>\u00eeles</th>\n",
              "      <th>\u00eels</th>\n",
              "      <th>\u0153il</th>\n",
              "      <th>\u0153ufs</th>\n",
              "      <th>\u0153uvre</th>\n",
              "      <th>\u0153uvrer</th>\n",
              "      <th>\u0153uvrerais</th>\n",
              "      <th>\u0153uvres</th>\n",
              "      <th>\u03b4lex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows \u00d7 11924 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    00  000  0000  0079  00h   04   06   09  0ccnpoxuwu  0cxdedblpx  ...   \\\n",
              "0  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0         0.0         0.0  ...    \n",
              "1  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0         0.0         0.0  ...    \n",
              "2  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0         0.0         0.0  ...    \n",
              "3  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0         0.0         0.0  ...    \n",
              "4  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0         0.0         0.0  ...    \n",
              "\n",
              "   \u00eele  \u00eeles  \u00eels  \u0153il  \u0153ufs  \u0153uvre  \u0153uvrer  \u0153uvrerais  \u0153uvres  \u03b4lex  \n",
              "0  0.0   0.0  0.0  0.0   0.0    0.0     0.0        0.0     0.0   0.0  \n",
              "1  0.0   0.0  0.0  0.0   0.0    0.0     0.0        0.0     0.0   0.0  \n",
              "2  0.0   0.0  0.0  0.0   0.0    0.0     0.0        0.0     0.0   0.0  \n",
              "3  0.0   0.0  0.0  0.0   0.0    0.0     0.0        0.0     0.0   0.0  \n",
              "4  0.0   0.0  0.0  0.0   0.0    0.0     0.0        0.0     0.0   0.0  \n",
              "\n",
              "[5 rows x 11924 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pandas.DataFrame(res.todense(), columns=voc)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python364_x64\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
            "  DeprecationWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
              "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
              "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
              "             mean_change_tol=0.001, n_components=10, n_jobs=1,\n",
              "             n_topics=None, perp_tol=0.1, random_state=None,\n",
              "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda = LatentDirichletAllocation(n_components=10)\n",
        "lda.fit(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(\"Topic #%d:\" % topic_idx)\n",
        "        print(\" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic #0:\n",
            "sijetaispresident je de les le la et en co https\n",
            "Topic #1:\n",
            "interdirais port camembert pizza leggings ballerine l\u00e9galiserai rendrai sijetaispresident l\u00e9opard\n",
            "Topic #2:\n",
            "revenu dormirais affaires concert bercy commun universel hiver lelab_e1 grande\n",
            "Topic #3:\n",
            "sijetaispresident la de je les le et co https des\n",
            "Topic #4:\n",
            "d\u00e9missionnerais volont\u00e9 mets ss10 organiserais officielle soir\u00e9es urgent cache offrirais\n",
            "Topic #5:\n",
            "maths lait mandat abolirai vive c\u00e9r\u00e9ales mettent allait propose morsay\n",
            "Topic #6:\n",
            "soci\u00e9t\u00e9 trahison haute l\u00e9galisation march\u00e9 michel tahaetmourad massive exercer keen\n",
            "Topic #7:\n",
            "supprimerais obligatoire lundi rendrais sieste vendredi bac promesses f\u00e9ri\u00e9 imposerai\n",
            "Topic #8:\n",
            "bah les dictateur sijetaispresident justice devoirs instaurerais arr\u00eaterai nationale police\n",
            "Topic #9:\n",
            "sijetaispresident mcdo national hymne le chocolatine co https \u00e9coles cannabis\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_top_words(lda, voc, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "comp = lda.transform(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5087, 10)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comp.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour chaque tweet, le score plus \u00e9lev\u00e9 indique la classe dans laquelle class\u00e9 le tweet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.02704576, 0.02703572, 0.02703569, 0.75666716, 0.02703569,\n",
              "       0.02703569, 0.02703569, 0.02703571, 0.02703572, 0.02703717])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comp[0,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}