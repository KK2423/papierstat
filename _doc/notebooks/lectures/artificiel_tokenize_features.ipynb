{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Des mots aux sacs de mots\n",
        "\n",
        "La tokenisation consiste \u00e0 d\u00e9couper un texte en *token*, l'approche *sac de mots* consiste \u00e0 compter les occurences de chaque mot dans chaque document de la base de donn\u00e9es."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "texte = \"\"\"\n",
        "Mardi 20 f\u00e9vrier, \u00e0 la m\u00e9diath\u00e8que des Mureaux (Yvelines), le chef de l\u2019Etat a accompagn\u00e9 \n",
        "la locataire de la rue de Valois pour la remise officielle du rapport \n",
        "sur les biblioth\u00e8ques, r\u00e9dig\u00e9 par leur ami commun, l\u2019acad\u00e9micien \n",
        "Erik Orsenna, avec le concours de No\u00ebl Corbin, inspecteur g\u00e9n\u00e9ral \n",
        "des affaires culturelles. L\u2019occasion de pr\u00e9senter les premi\u00e8res \n",
        "mesures en faveur d\u2019un \u00ab plan biblioth\u00e8ques \u00bb.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline de traitement\n",
        "\n",
        "Maintenant qu'on sait d\u00e9couper en mots ou couples de mots, il faut appliquer sur une liste de textes. On cr\u00e9e une petite liste de textes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\nMardi 20 f\u00e9vrier, \u00e0 la m\u00e9diath\u00e8que des Murea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tout petit texte</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  \\nMardi 20 f\u00e9vrier, \u00e0 la m\u00e9diath\u00e8que des Murea...\n",
              "1                                   tout petit texte"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas\n",
        "df = pandas.DataFrame(dict(text=[texte, \"tout petit texte\"]))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et on applique l'objet [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<2x51 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 51 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cd = CountVectorizer()\n",
        "cd.fit(df[\"text\"])\n",
        "res = cd.transform(df[\"text\"])\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On r\u00e9cup\u00e8re une [matrice sparse](https://docs.scipy.org/doc/scipy/reference/sparse.html) o\u00f9 chaque colonne compte le nombre d'occurence d'un mot dans le texte :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 5, 2, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 4, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 0, 0, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 1, 1, 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les mots sont les suivants :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'mardi': 27,\n",
              " '20': 0,\n",
              " 'f\u00e9vrier': 19,\n",
              " 'la': 22,\n",
              " 'm\u00e9diath\u00e8que': 30,\n",
              " 'des': 13,\n",
              " 'mureaux': 29,\n",
              " 'yvelines': 50,\n",
              " 'le': 23,\n",
              " 'chef': 7,\n",
              " 'de': 12,\n",
              " 'etat': 17,\n",
              " 'accompagn\u00e9': 2,\n",
              " 'locataire': 26,\n",
              " 'rue': 43,\n",
              " 'valois': 49,\n",
              " 'pour': 38,\n",
              " 'remise': 42,\n",
              " 'officielle': 33,\n",
              " 'du': 14,\n",
              " 'rapport': 41,\n",
              " 'sur': 45,\n",
              " 'les': 24,\n",
              " 'biblioth\u00e8ques': 6,\n",
              " 'r\u00e9dig\u00e9': 44,\n",
              " 'par': 35,\n",
              " 'leur': 25,\n",
              " 'ami': 4,\n",
              " 'commun': 8,\n",
              " 'acad\u00e9micien': 1,\n",
              " 'erik': 16,\n",
              " 'orsenna': 34,\n",
              " 'avec': 5,\n",
              " 'concours': 9,\n",
              " 'no\u00ebl': 31,\n",
              " 'corbin': 10,\n",
              " 'inspecteur': 21,\n",
              " 'g\u00e9n\u00e9ral': 20,\n",
              " 'affaires': 3,\n",
              " 'culturelles': 11,\n",
              " 'occasion': 32,\n",
              " 'pr\u00e9senter': 40,\n",
              " 'premi\u00e8res': 39,\n",
              " 'mesures': 28,\n",
              " 'en': 15,\n",
              " 'faveur': 18,\n",
              " 'un': 48,\n",
              " 'plan': 37,\n",
              " 'tout': 47,\n",
              " 'petit': 36,\n",
              " 'texte': 46}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cd.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Un tokenizer diff\u00e9rent\n",
        "\n",
        "La classe [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) est facilement param\u00e9trable. On peut en particulier changer le *tokenizer* :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 62)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vect = CountVectorizer(tokenizer=word_tokenize)\n",
        "counts = count_vect.fit_transform(df[\"text\"])\n",
        "counts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[1, 1, 6, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 5, 2, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 3, 4, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 4],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
              "       dtype=int64)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counts.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hashing\n",
        "\n",
        "Le nombre de mots distincts peut \u00eatre tr\u00e8s grand surtout si la source des textes est bruit\u00e9e (faute d'orthographe, spams, ...). Pour r\u00e9duire le nombre de mots, on peut utiliser un *hash* \u00e0 valeur dans un ensemble plus petit que le nombre de mots d\u00e9couverts : c'est une sorte de modulo. Deux mots pourront \u00eatre comptabilis\u00e9s dans la m\u00eame colonne. On utilise la classe [HashingVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[-0.08247861,  0.16495722, -0.41239305,  0.74230749,  0.49487166],\n",
              "        [-0.4472136 ,  0.        ,  0.89442719,  0.        ,  0.        ]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "cd = HashingVectorizer(n_features=5)\n",
        "cd.fit(df[\"text\"])\n",
        "res = cd.transform(df[\"text\"])\n",
        "res.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La classe utilise la classe [FeatureHasher](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html) et plus pr\u00e9cis\u00e9ment le code dans [_hashing.pyx](https://github.com/scikit-learn/scikit-learn/blob/a24c8b464d094d2c468a16ea9f8bf8d42d949f84/sklearn/feature_extraction/_hashing.pyx)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[0.4472136 , 0.4472136 , 0.4472136 , 0.4472136 , 0.4472136 ],\n",
              "        [0.70710678, 0.        , 0.70710678, 0.        , 0.        ]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cd = HashingVectorizer(n_features=5, binary=True)\n",
        "cd.fit(df[\"text\"])\n",
        "res = cd.transform(df[\"text\"])\n",
        "res.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "R\u00e9duire les dimensions tout en gardant une certaine forme de proximit\u00e9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\nMardi 20 f\u00e9vrier, \u00e0 la m\u00e9diath\u00e8que des Murea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20 f\u00e9vrier, \u00e0 la m\u00e9diath\u00e8que des Mureaux (Yvel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>m\u00e9diath\u00e8que des Mureaux (Yvelines), le chef de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chef de l\u2019Etat a accompagn\u00e9 la locataire de la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>de Valois pour la remise officielle du rapport...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>officielle du rapport sur les biblioth\u00e8ques, r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>biblioth\u00e8ques, r\u00e9dig\u00e9 par nouveau</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tout petit texte</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  \\nMardi 20 f\u00e9vrier, \u00e0 la m\u00e9diath\u00e8que des Murea...\n",
              "1  20 f\u00e9vrier, \u00e0 la m\u00e9diath\u00e8que des Mureaux (Yvel...\n",
              "2  m\u00e9diath\u00e8que des Mureaux (Yvelines), le chef de...\n",
              "3  chef de l\u2019Etat a accompagn\u00e9 la locataire de la...\n",
              "4  de Valois pour la remise officielle du rapport...\n",
              "5  officielle du rapport sur les biblioth\u00e8ques, r...\n",
              "6                  biblioth\u00e8ques, r\u00e9dig\u00e9 par nouveau\n",
              "7                                   tout petit texte"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = pandas.DataFrame(dict(text=[texte, \n",
        "                  \" \".join(texte.split()[1:-1]), \n",
        "                  \" \".join(texte.split()[5:-5]), \n",
        "                  \" \".join(texte.split()[10:-10]) + ' machine', \n",
        "                  \" \".join(texte.split()[20:-20]) + ' learning', \n",
        "                  \" \".join(texte.split()[25:-25]) + ' statistique', \n",
        "                  \" \".join(texte.split()[30:-30]) + ' nouveau', \n",
        "                  \"tout petit texte\"]))\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[-0.08873565,  0.3549426 , -0.1774713 ,  0.        , -0.26620695,\n",
              "          0.        ,  0.79862086,  0.3549426 ],\n",
              "        [-0.09053575,  0.36214298, -0.18107149,  0.        , -0.18107149,\n",
              "          0.        ,  0.81482171,  0.36214298],\n",
              "        [-0.10783277,  0.43133109, -0.21566555,  0.        ,  0.        ,\n",
              "          0.        ,  0.75482941,  0.43133109],\n",
              "        [-0.24806947,  0.3721042 ,  0.        , -0.12403473, -0.12403473,\n",
              "          0.        ,  0.86824314,  0.12403473],\n",
              "        [-0.20412415,  0.81649658,  0.        ,  0.20412415,  0.20412415,\n",
              "          0.20412415,  0.40824829,  0.        ],\n",
              "        [ 0.        ,  0.35355339,  0.35355339,  0.35355339,  0.        ,\n",
              "          0.70710678, -0.35355339,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.70710678, -0.70710678],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  1.        ,  0.        ]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cd = HashingVectorizer(n_features=8, binary=False)\n",
        "cd.fit(df2[\"text\"])\n",
        "res = cd.transform(df2[\"text\"])\n",
        "res.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.087352</td>\n",
              "      <td>0.293731</td>\n",
              "      <td>0.388511</td>\n",
              "      <td>0.916931</td>\n",
              "      <td>1.561800</td>\n",
              "      <td>1.171556</td>\n",
              "      <td>0.634632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.087352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.217844</td>\n",
              "      <td>0.368633</td>\n",
              "      <td>0.883337</td>\n",
              "      <td>1.564650</td>\n",
              "      <td>1.166111</td>\n",
              "      <td>0.608569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.293731</td>\n",
              "      <td>0.217844</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.455795</td>\n",
              "      <td>0.797058</td>\n",
              "      <td>1.543129</td>\n",
              "      <td>1.241976</td>\n",
              "      <td>0.700244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.388511</td>\n",
              "      <td>0.368633</td>\n",
              "      <td>0.455795</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.826704</td>\n",
              "      <td>1.561579</td>\n",
              "      <td>0.973412</td>\n",
              "      <td>0.513336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.916931</td>\n",
              "      <td>0.883337</td>\n",
              "      <td>0.797058</td>\n",
              "      <td>0.826704</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.130625</td>\n",
              "      <td>1.192749</td>\n",
              "      <td>1.087889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.561800</td>\n",
              "      <td>1.564650</td>\n",
              "      <td>1.543129</td>\n",
              "      <td>1.561579</td>\n",
              "      <td>1.130625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.581139</td>\n",
              "      <td>1.645329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.171556</td>\n",
              "      <td>1.166111</td>\n",
              "      <td>1.241976</td>\n",
              "      <td>0.973412</td>\n",
              "      <td>1.192749</td>\n",
              "      <td>1.581139</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.765367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.634632</td>\n",
              "      <td>0.608569</td>\n",
              "      <td>0.700244</td>\n",
              "      <td>0.513336</td>\n",
              "      <td>1.087889</td>\n",
              "      <td>1.645329</td>\n",
              "      <td>0.765367</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0  0.000000  0.087352  0.293731  0.388511  0.916931  1.561800  1.171556   \n",
              "1  0.087352  0.000000  0.217844  0.368633  0.883337  1.564650  1.166111   \n",
              "2  0.293731  0.217844  0.000000  0.455795  0.797058  1.543129  1.241976   \n",
              "3  0.388511  0.368633  0.455795  0.000000  0.826704  1.561579  0.973412   \n",
              "4  0.916931  0.883337  0.797058  0.826704  0.000000  1.130625  1.192749   \n",
              "5  1.561800  1.564650  1.543129  1.561579  1.130625  0.000000  1.581139   \n",
              "6  1.171556  1.166111  1.241976  0.973412  1.192749  1.581139  0.000000   \n",
              "7  0.634632  0.608569  0.700244  0.513336  1.087889  1.645329  0.765367   \n",
              "\n",
              "          7  \n",
              "0  0.634632  \n",
              "1  0.608569  \n",
              "2  0.700244  \n",
              "3  0.513336  \n",
              "4  1.087889  \n",
              "5  1.645329  \n",
              "6  0.765367  \n",
              "7  0.000000  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "pandas.DataFrame(pairwise_distances(res))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## tf-idf\n",
        "\n",
        "Ce genre de technique produit des matrices de tr\u00e8s grande dimension qu'il faut r\u00e9duire. On peut enlever les mots rares ou les mots tr\u00e8s fr\u00e9quents. [td-idf](https://fr.wikipedia.org/wiki/TF-IDF>) est une technique qui vient des moteurs de recherche. Elle construit le m\u00eame type de matrice (m\u00eame dimension) mais associe \u00e0 chaque couple (document - mot) un poids qui d\u00e9pend de la fr\u00e9quence d'un mot globalement et du nombre de documents contenant ce mot.\n",
        "\n",
        "$$idf(t) = \\log \\frac{\\# D}{\\#\\{d \\; | \\; t \\in d \\}}$$\n",
        "\n",
        "O\u00f9 :\n",
        "\n",
        "- $\\#D$ est le nombre de documents\n",
        "- $\\#\\{d \\; | \\; t \\in d \\}$ est le nombre de documents contenant le mot $t$\n",
        "\n",
        "$f(t,d)$ est le nombre d'occurences d'un mot $t$ dans un document $d$.\n",
        "\n",
        "$$tf(t,d) = \\frac{1}{2} + \\frac{1}{2} \\frac{f(t,d)}{\\max_{t' \\in d} f(t',d)}$$\n",
        "\n",
        "On construit le nombre $tfidf(t,f) = tf(t,d) idf(t)$ :\n",
        "\n",
        "Le terme $idf(t)$ favorise les mots pr\u00e9sent dans peu de documents, le terme $tf(t,f)$ favorise les termes r\u00e9p\u00e9t\u00e9s un grand nombre de fois dans le m\u00eame document. On applique \u00e0 la matrice pr\u00e9c\u00e9dente. Sur deux documents, cela ne sert pas \u00e0 grand-chose. On utilise la classe [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.20100756, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.50251891, 0.20100756, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.40201513, 0.20100756, 0.20100756,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.        , 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.        , 0.        , 0.10050378, 0.10050378,\n",
              "         0.10050378],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.57735027, 0.57735027, 0.        , 0.        ,\n",
              "         0.        ]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "cd = TfidfVectorizer()\n",
        "cd.fit(df[\"text\"])\n",
        "res = cd.transform(df[\"text\"])\n",
        "res.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si on d\u00e9compose :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.20100756, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.50251891, 0.20100756, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.40201513, 0.20100756, 0.20100756,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.        , 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.10050378, 0.10050378, 0.10050378, 0.10050378,\n",
              "         0.10050378, 0.        , 0.        , 0.10050378, 0.10050378,\n",
              "         0.10050378],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.57735027, 0.57735027, 0.        , 0.        ,\n",
              "         0.        ]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "pipe = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
        "pipe.fit(df['text'])\n",
        "res = pipe.transform(df['text'])\n",
        "res.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ca marche aussi sur les hash."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[-0.06142775,  0.17266912, -0.30713875,  0.77701104,  0.51800736],\n",
              "        [-0.4472136 ,  0.        ,  0.89442719,  0.        ,  0.        ]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe = make_pipeline(HashingVectorizer(n_features=5), TfidfTransformer())\n",
        "pipe.fit(df['text'])\n",
        "res = pipe.transform(df['text'])\n",
        "res.todense()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sur un jeu de donn\u00e9es\n",
        "\n",
        "L'id\u00e9e est d'appliquer une LDA ou [Latent Dirichet Application](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <td>776066992054861825</td>\n",
              "      <td>776067660979245056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb_user_mentions</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb_extended_entities</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb_hashtags</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>geo</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_hashtags</th>\n",
              "      <td>, SiJ\u00e9taisPr\u00e9sident</td>\n",
              "      <td>, SiJ\u00e9taisPr\u00e9sident</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>annee</th>\n",
              "      <td>2016</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delimit_mention</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lang</th>\n",
              "      <td>fr</td>\n",
              "      <td>fr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_str</th>\n",
              "      <td>7.76067e+17</td>\n",
              "      <td>7.76068e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_mention</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retweet_count</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>favorite_count</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>type_extended_entities</th>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>#SiJ\u00e9taisPr\u00e9sident se serait la fin du monde.....</td>\n",
              "      <td>#SiJ\u00e9taisPr\u00e9sident je donnerai plus de vacance...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb_user_photos</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb_urls</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb_symbols</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>created_at</th>\n",
              "      <td>Wed Sep 14 14:36:04 +0000 2016</td>\n",
              "      <td>Wed Sep 14 14:38:43 +0000 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delimit_hash</th>\n",
              "      <td>, 0, 18</td>\n",
              "      <td>, 0, 18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                        0  \\\n",
              "index                                                  776066992054861825   \n",
              "nb_user_mentions                                                        0   \n",
              "nb_extended_entities                                                    0   \n",
              "nb_hashtags                                                             1   \n",
              "geo                                                                   NaN   \n",
              "text_hashtags                                         , SiJ\u00e9taisPr\u00e9sident   \n",
              "annee                                                                2016   \n",
              "delimit_mention                                                       NaN   \n",
              "lang                                                                   fr   \n",
              "id_str                                                        7.76067e+17   \n",
              "text_mention                                                          NaN   \n",
              "retweet_count                                                           4   \n",
              "favorite_count                                                          3   \n",
              "type_extended_entities                                                 []   \n",
              "text                    #SiJ\u00e9taisPr\u00e9sident se serait la fin du monde.....   \n",
              "nb_user_photos                                                          0   \n",
              "nb_urls                                                                 0   \n",
              "nb_symbols                                                              0   \n",
              "created_at                                 Wed Sep 14 14:36:04 +0000 2016   \n",
              "delimit_hash                                                      , 0, 18   \n",
              "\n",
              "                                                                        1  \n",
              "index                                                  776067660979245056  \n",
              "nb_user_mentions                                                        0  \n",
              "nb_extended_entities                                                    0  \n",
              "nb_hashtags                                                             1  \n",
              "geo                                                                   NaN  \n",
              "text_hashtags                                         , SiJ\u00e9taisPr\u00e9sident  \n",
              "annee                                                                2016  \n",
              "delimit_mention                                                       NaN  \n",
              "lang                                                                   fr  \n",
              "id_str                                                        7.76068e+17  \n",
              "text_mention                                                          NaN  \n",
              "retweet_count                                                           5  \n",
              "favorite_count                                                          8  \n",
              "type_extended_entities                                                 []  \n",
              "text                    #SiJ\u00e9taisPr\u00e9sident je donnerai plus de vacance...  \n",
              "nb_user_photos                                                          0  \n",
              "nb_urls                                                                 0  \n",
              "nb_symbols                                                              0  \n",
              "created_at                                 Wed Sep 14 14:38:43 +0000 2016  \n",
              "delimit_hash                                                      , 0, 18  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from papierstat.datasets import load_tweet_dataset\n",
        "tweet = load_tweet_dataset()\n",
        "tweet = tweet[tweet[\"text\"].notnull()]\n",
        "tweet.head(n=2).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
        "res = pipeline.fit_transform(tweet['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "count = pipeline.steps[0][-1]\n",
        "voc = count.get_feature_names()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le code suivant marche parce que la base n'est pas trop petite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>0000</th>\n",
              "      <th>0079</th>\n",
              "      <th>00h</th>\n",
              "      <th>04</th>\n",
              "      <th>06</th>\n",
              "      <th>09</th>\n",
              "      <th>0ccnpoxuwu</th>\n",
              "      <th>0cxdedblpx</th>\n",
              "      <th>...</th>\n",
              "      <th>\u00eeles</th>\n",
              "      <th>\u00eels</th>\n",
              "      <th>\u0153il</th>\n",
              "      <th>\u0153ufs</th>\n",
              "      <th>\u0153uvre</th>\n",
              "      <th>\u0153uvrer</th>\n",
              "      <th>\u0153uvrerais</th>\n",
              "      <th>\u0153uvres</th>\n",
              "      <th>\u03b4lex</th>\n",
              "      <th>whole_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.354877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#Macron appelle \u00e0 poursuivre l'\u0153uvre de #Rocar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.328786</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Quelle est-t-elle cette \"\u0153uvre de Michel Rocar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4063</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.399841</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#SiJetaisPresident je durcirais les p\u00e9nalit\u00e9s ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows \u00d7 11925 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       00  000  0000  0079  00h   04   06   09  0ccnpoxuwu  0cxdedblpx  \\\n",
              "109   0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0         0.0         0.0   \n",
              "151   0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0         0.0         0.0   \n",
              "4063  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0         0.0         0.0   \n",
              "\n",
              "                            ...                          \u00eeles  \u00eels  \u0153il  \u0153ufs  \\\n",
              "109                         ...                           0.0  0.0  0.0   0.0   \n",
              "151                         ...                           0.0  0.0  0.0   0.0   \n",
              "4063                        ...                           0.0  0.0  0.0   0.0   \n",
              "\n",
              "         \u0153uvre  \u0153uvrer  \u0153uvrerais  \u0153uvres  \u03b4lex  \\\n",
              "109   0.354877     0.0        0.0     0.0   0.0   \n",
              "151   0.328786     0.0        0.0     0.0   0.0   \n",
              "4063  0.399841     0.0        0.0     0.0   0.0   \n",
              "\n",
              "                                            whole_tweet  \n",
              "109   #Macron appelle \u00e0 poursuivre l'\u0153uvre de #Rocar...  \n",
              "151   Quelle est-t-elle cette \"\u0153uvre de Michel Rocar...  \n",
              "4063  #SiJetaisPresident je durcirais les p\u00e9nalit\u00e9s ...  \n",
              "\n",
              "[3 rows x 11925 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pandas.DataFrame(res.todense(), columns=voc)\n",
        "data['whole_tweet'] = tweet['text']\n",
        "data[data['\u0153uvre'] > 0].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python365_x64\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
            "  DeprecationWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
              "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
              "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
              "             mean_change_tol=0.001, n_components=10, n_jobs=1,\n",
              "             n_topics=None, perp_tol=0.1, random_state=None,\n",
              "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda = LatentDirichletAllocation(n_components=10)\n",
        "lda.fit(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(\"Topic #%d:\" % topic_idx)\n",
        "        print(\" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic #0:\n",
            "sieste imposerai cantine frites scolaire self affaires obligatoire profiterais grec\n",
            "Topic #1:\n",
            "pizza domicile meufs purge constitution haute drogues trahison demissionerai do\n",
            "Topic #2:\n",
            "organiserai semaines mets organiserais kebabs lep roux raie cache empire\n",
            "Topic #3:\n",
            "abolirai ss10 desigual urgent int\u00e9rieur avanc\u00e9s wiko morsay t\u00e9l\u00e9r\u00e9alit\u00e9 lcp\n",
            "Topic #4:\n",
            "interdirais les sijetaispresident seraient port ballerines camembert d\u00e9missionnerais droit gratuits\n",
            "Topic #5:\n",
            "rendrais \u00e9coles l\u00e9gal mandat poudlard obligatoire sortie vive bouton 8h\n",
            "Topic #6:\n",
            "l\u00e9galiserai promesses famille ill\u00e9gal rendrai tiendrais arfa dutreil beuh sports\n",
            "Topic #7:\n",
            "sijetaispresident je ministre l\u00e9galiserais co https culture nommerais les la\n",
            "Topic #8:\n",
            "sijetaispresident de je la les le et co https macron\n",
            "Topic #9:\n",
            "chocolatine bac pain kfc lenorman cc lait tacos notaires christineboutin\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_top_words(lda, voc, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "comp = lda.transform(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5087, 10)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comp.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour chaque tweet, le score plus \u00e9lev\u00e9 indique la classe dans laquelle class\u00e9 le tweet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0.02214216, 0.02214216, 0.02214216, 0.02214216, 0.02214224,\n",
              "        0.02214216, 0.02214216, 0.02214232, 0.80072034, 0.02214216]),\n",
              " 8,\n",
              " '#SiJ\u00e9taisPr\u00e9sident je donnerai plus de vacances \ud83d\ude0c, genre 1mois de cours 1 mois de vacances etc...\\r\\nVotez pour moi !\ud83d\ude02')"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val = comp[1,:]\n",
        "val, val.argmax(), tweet['text'][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On regarde les tweets les plus repr\u00e9sentatifs du topic 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>0.021209</td>\n",
              "      <td>0.021209</td>\n",
              "      <td>0.021209</td>\n",
              "      <td>0.606043</td>\n",
              "      <td>0.021210</td>\n",
              "      <td>0.021209</td>\n",
              "      <td>0.021209</td>\n",
              "      <td>0.021210</td>\n",
              "      <td>0.224283</td>\n",
              "      <td>0.021209</td>\n",
              "      <td>Sondage @OdoxaSondages D\u00e9cryptage demain en pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2391</th>\n",
              "      <td>0.026966</td>\n",
              "      <td>0.026966</td>\n",
              "      <td>0.026966</td>\n",
              "      <td>0.600969</td>\n",
              "      <td>0.026966</td>\n",
              "      <td>0.026966</td>\n",
              "      <td>0.026966</td>\n",
              "      <td>0.026966</td>\n",
              "      <td>0.183305</td>\n",
              "      <td>0.026966</td>\n",
              "      <td>Jss sure c'est Raouf qui a cree ce # \ud83d\ude02\ud83d\ude02 @justd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2354</th>\n",
              "      <td>0.039798</td>\n",
              "      <td>0.039799</td>\n",
              "      <td>0.039798</td>\n",
              "      <td>0.599248</td>\n",
              "      <td>0.039889</td>\n",
              "      <td>0.039798</td>\n",
              "      <td>0.039798</td>\n",
              "      <td>0.039870</td>\n",
              "      <td>0.082205</td>\n",
              "      <td>0.039798</td>\n",
              "      <td>#SiJetaisPresident j'abrogerais #college2016...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>0.022561</td>\n",
              "      <td>0.022561</td>\n",
              "      <td>0.022561</td>\n",
              "      <td>0.591920</td>\n",
              "      <td>0.022561</td>\n",
              "      <td>0.022561</td>\n",
              "      <td>0.022561</td>\n",
              "      <td>0.022562</td>\n",
              "      <td>0.227592</td>\n",
              "      <td>0.022561</td>\n",
              "      <td>Sondage @13h15 / @OdoxaSondages. D\u00e9cryptage de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4706</th>\n",
              "      <td>0.020940</td>\n",
              "      <td>0.020940</td>\n",
              "      <td>0.020940</td>\n",
              "      <td>0.588835</td>\n",
              "      <td>0.020940</td>\n",
              "      <td>0.020940</td>\n",
              "      <td>0.020940</td>\n",
              "      <td>0.020941</td>\n",
              "      <td>0.243645</td>\n",
              "      <td>0.020940</td>\n",
              "      <td>Politiciens criminels #Sarkozy #Macron #LePen ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "383   0.021209  0.021209  0.021209  0.606043  0.021210  0.021209  0.021209   \n",
              "2391  0.026966  0.026966  0.026966  0.600969  0.026966  0.026966  0.026966   \n",
              "2354  0.039798  0.039799  0.039798  0.599248  0.039889  0.039798  0.039798   \n",
              "370   0.022561  0.022561  0.022561  0.591920  0.022561  0.022561  0.022561   \n",
              "4706  0.020940  0.020940  0.020940  0.588835  0.020940  0.020940  0.020940   \n",
              "\n",
              "             7         8         9  \\\n",
              "383   0.021210  0.224283  0.021209   \n",
              "2391  0.026966  0.183305  0.026966   \n",
              "2354  0.039870  0.082205  0.039798   \n",
              "370   0.022562  0.227592  0.022561   \n",
              "4706  0.020941  0.243645  0.020940   \n",
              "\n",
              "                                                  tweet  \n",
              "383   Sondage @OdoxaSondages D\u00e9cryptage demain en pl...  \n",
              "2391  Jss sure c'est Raouf qui a cree ce # \ud83d\ude02\ud83d\ude02 @justd...  \n",
              "2354    #SiJetaisPresident j'abrogerais #college2016...  \n",
              "370   Sondage @13h15 / @OdoxaSondages. D\u00e9cryptage de...  \n",
              "4706  Politiciens criminels #Sarkozy #Macron #LePen ...  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction = pandas.DataFrame(comp)\n",
        "prediction['tweet'] = tweet['text']\n",
        "t3 = prediction.sort_values(3, ascending=False)\n",
        "t3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sondage @OdoxaSondages D\u00e9cryptage demain en plateau dans le @13h15 de @LaurentDelahous #Macron https://t.co/wJex9S0Ute nice #Nice06\n",
            "---\n",
            "Jss sure c'est Raouf qui a cree ce # \ud83d\ude02\ud83d\ude02 @justdelgrosso #SiJetaisPresident\n",
            "---\n",
            "#SiJetaisPresident j'abrogerais #college2016...\n",
            "---\n",
            "Sondage @13h15 / @OdoxaSondages. D\u00e9cryptage demain en plateau dans le @13h15 de @LaurentDelahous #Pr\u00e9cision #Macron https://t.co/wAEbrJxY7m\n",
            "---\n",
            "Politiciens criminels #Sarkozy #Macron #LePen #Fabius (y a quand m\u00eame des gosses morts pour ce dernier) la liste est longue #stopcorruption\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n---\\n\".join(list(t3['tweet'].head())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}