{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification de phrases avec word2vec\n",
        "\n",
        "Le texte est toujours d\u00e9licat \u00e0 traiter. La langue est importante et plus le vocabulaire est \u00e9tendu, plus il faut de donn\u00e9es. Le probl\u00e8me qui suit est classique, on cherche \u00e0 cat\u00e9goriser des phrases en sentiment positif ou n\u00e9gatif. Ce pourrait \u00eatre aussi classer des spams. Le probl\u00e8me le plus simple : une phrase, un label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les donn\u00e9es\n",
        "\n",
        "Elles proviennent de [Sentiment Labelled Sentences Data Set](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentance</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentance  sentiment  \\\n",
              "0  So there is no way for me to plug it in here i...          0   \n",
              "1                        Good case, Excellent value.          1   \n",
              "2                             Great for the jawbone.          1   \n",
              "3  Tied to charger for conversations lasting more...          0   \n",
              "4                                  The mic is great.          1   \n",
              "\n",
              "                  source  \n",
              "0  amazon_cells_labelled  \n",
              "1  amazon_cells_labelled  \n",
              "2  amazon_cells_labelled  \n",
              "3  amazon_cells_labelled  \n",
              "4  amazon_cells_labelled  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from papierstat.datasets import load_sentiment_dataset\n",
        "df = load_sentiment_dataset()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>sentance</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">amazon_cells_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">imdb_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">yelp_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 sentance\n",
              "source                sentiment          \n",
              "amazon_cells_labelled 0               500\n",
              "                      1               500\n",
              "imdb_labelled         0               500\n",
              "                      1               500\n",
              "yelp_labelled         0               500\n",
              "                      1               500"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(['source', 'sentiment']).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On d\u00e9coupe en train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[[\"sentance\"]], df['sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## L'approche classique\n",
        "\n",
        "[TF-IDF](https://fr.wikipedia.org/wiki/TF-IDF) est une approche tr\u00e8s r\u00e9pandue lorsqu'il s'agit de convertir des phrases en features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 4371)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "pipe = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
        "pipe.fit(X_train['sentance'])\n",
        "feat_train = pipe.transform(X_train['sentance'])\n",
        "feat_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_train.min(), feat_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(750, 4371)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test = pipe.transform(X_test['sentance'])\n",
        "feat_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python370_x64\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
            "  from numpy.core.umath_tests import inner1d\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=50)\n",
        "clf.fit(feat_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7706666666666667"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "score = clf.predict_proba(feat_test)\n",
        "fpr, tpr, th = roc_curve(y_test, score[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "aucf = auc(fpr, tpr)\n",
        "ax.plot(fpr, tpr, label='auc=%1.5f' % aucf)\n",
        "ax.set_title('Courbe ROC - classifieur de sentiments')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les n-grammes\n",
        "\n",
        "L'approche pr\u00e9sent\u00e9e ci-dessus ne tient pas compte de l'ordre des mots. Chaque phrase est convertie en un sac de mots (ou [bag of words](https://fr.wikipedia.org/wiki/Sac_de_mots)). Il est n\u00e9anmoins possible de tenir compte de s\u00e9quence plus ou moins longue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\xavie\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# s'il faut t\u00e9l\u00e9charger des donn\u00e9es\n",
        "if False:\n",
        "    import nltk\n",
        "    nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(None, None, 'Special'),\n",
              " (None, 'Special', 'mention'),\n",
              " ('Special', 'mention', 'should'),\n",
              " ('mention', 'should', 'be'),\n",
              " ('should', 'be', 'made'),\n",
              " ('be', 'made', 'of'),\n",
              " ('made', 'of', 'the')]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "generated_ngrams = ngrams(word_tokenize(X_train.iloc[0,0]), 3, pad_left=True, pad_right=True)\n",
        "list(generated_ngrams)[:7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[scikit-learn](http://scikit-learn.org/stable/modules/feature_extraction.html#limitations-of-the-bag-of-words-representation) permet d'essayer cette id\u00e9e simplement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 20187)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe2 = make_pipeline(CountVectorizer(ngram_range=(1, 2)),\n",
        "                      TfidfTransformer())\n",
        "pipe2.fit(X_train['sentance'])\n",
        "feat_train2 = pipe2.transform(X_train['sentance'])\n",
        "feat_train2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il y a plus de colonnes, on v\u00e9rifie malgr\u00e9 tout que les features ressemblent \u00e0 des couples de mots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['00',\n",
              " '10',\n",
              " '10 10',\n",
              " '10 and',\n",
              " '10 feet',\n",
              " '10 minutes',\n",
              " '10 of',\n",
              " '10 on',\n",
              " '10 out',\n",
              " '10 plus']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cl = pipe2.steps[0]\n",
        "cl[1].get_feature_names()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est le cas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "feat_test2 = pipe2.transform(X_test['sentance'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf2 = RandomForestClassifier(n_estimators=50)\n",
        "clf2.fit(feat_train2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7933333333333333"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf2.score(feat_test2, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cela n'am\u00e9liore pas de fa\u00e7on significative. Il faudrait faire une cross-validation pour s'en assurer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## R\u00e9duire les dimensions avec une ACP\n",
        "\n",
        "C'est un moyen fr\u00e9quemment utilis\u00e9 pour r\u00e9duire les dimensions. On choisit le mod\u00e8le [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD) plut\u00f4t que l'[ACP](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA) dont l'impl\u00e9mentation ne supporte pas les features sparses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "pipe_svd = make_pipeline(CountVectorizer(), TruncatedSVD(n_components=300))\n",
        "pipe_svd.fit(X_train['sentance'])\n",
        "feat_train_svd = pipe_svd.transform(X_train['sentance'])\n",
        "feat_train_svd.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_svd = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd.fit(feat_train_svd, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.72"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test_svd = pipe_svd.transform(X_test['sentance'])\n",
        "clf_svd.score(feat_test_svd, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et si on repart de TF-IDF :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.744"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_svd_tfidf = make_pipeline(CountVectorizer(), \n",
        "                     TfidfTransformer(),\n",
        "                     TruncatedSVD(n_components=300))\n",
        "pipe_svd_tfidf.fit(X_train['sentance'])\n",
        "feat_train_svd_tfidf = pipe_svd_tfidf.transform(X_train['sentance'])\n",
        "\n",
        "clf_svd_tfidf = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd_tfidf.fit(feat_train_svd_tfidf, y_train)\n",
        "\n",
        "feat_test_svd_tfidf = pipe_svd_tfidf.transform(X_test['sentance'])\n",
        "clf_svd_tfidf.score(feat_test_svd_tfidf, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est mieux mais cela reste moins bien que le *tf-idf* sans r\u00e9duction de dimensions. Cela veut dire qu'il faut garder plus de dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec\n",
        "\n",
        "[word2vec](https://en.wikipedia.org/wiki/Word2vec) est une sorte d'ACP non lin\u00e9aire en ce sens qu'il r\u00e9duit les dimensions. Il faut lire [Analyse en composantes principales (ACP) et Auto Encoders](http://www.xavierdupre.fr/app/mlstatpy/helpsphinx/c_ml/rn/rn_9_auto.html) pour comprendre le lien entre ACP, ACP non lin\u00e9aire, r\u00e9seaux de neurones diabolo et compression. *word2vec* est plus d'une ACP non lin\u00e9aire car il prend en compte le contexte mais ne s'en \u00e9loigne pas tant que ce \u00e7a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python370_x64\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
            "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['special',\n",
              " 'mention',\n",
              " 'should',\n",
              " 'be',\n",
              " 'made',\n",
              " 'of',\n",
              " 'the',\n",
              " 'superb',\n",
              " 'music',\n",
              " 'score',\n",
              " 'and',\n",
              " 'sound',\n",
              " 'effects',\n",
              " 'which',\n",
              " 'are',\n",
              " 'an',\n",
              " 'integral',\n",
              " 'element',\n",
              " 'in',\n",
              " 'helping',\n",
              " 'to',\n",
              " 'make',\n",
              " 'this',\n",
              " 'such',\n",
              " 'a',\n",
              " 'memorable',\n",
              " 'and',\n",
              " 'enjoyable',\n",
              " 'cartoon']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.utils import tokenize\n",
        "sentance = [list(tokenize(s, deacc=True, lower=True)) for s in X_train['sentance']]\n",
        "sentance[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les param\u00e8tres d'apprentissage du mod\u00e8le [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) ne sont pas toujours d\u00e9crit de fa\u00e7on explicite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2250"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.models import word2vec\n",
        "model = word2vec.Word2Vec(sentance, size=300, window=20,\n",
        "                          min_count=2, workers=1, iter=100)\n",
        "model.corpus_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['special', 'mention', 'should', 'be', 'made']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = model.wv.vocab\n",
        "list(vocab)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('trained_word2vec.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les dix premi\u00e8res coordonn\u00e9es du vecteur associ\u00e9 au mot ``after``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((300,),\n",
              " array([-0.77467316,  0.8400039 ,  0.18615854, -0.21912785, -0.5166347 ,\n",
              "         0.09925058,  0.9017967 ,  1.2229382 , -0.10760584,  0.14310674],\n",
              "       dtype=float32))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv['after'].shape, model.wv['after'][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lorsque le mot est inconnu :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"word 'rrrrrrrr' not in vocabulary\"\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    model.wv['rrrrrrrr']\n",
        "except KeyError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour chaque phrase, on fait la somme des vecteurs associ\u00e9s aux mots qui la composent ou pas si le mot n'est pas dans le vocabulaire. Il y a probablement des fonctions d\u00e9j\u00e0 pr\u00eates \u00e0 l'emploi mais la documentation de [gensim](https://radimrehurek.com/gensim/index.html) n'\u00e9tait pas assez explicite et lire l'article [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) puis celui-ci [Distributed Representations of Words and Phrases\n",
        "and their Compositionality](https://arxiv.org/pdf/1310.4546.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def get_vect(word, model):\n",
        "    try:\n",
        "        return model.wv[word]\n",
        "    except KeyError:\n",
        "        return numpy.zeros((model.vector_size,))\n",
        "\n",
        "def sum_vectors(phrase, model):\n",
        "    return sum(get_vect(w, model) for w in phrase)\n",
        "\n",
        "def word2vec_features(X, model):\n",
        "    feats = numpy.vstack([sum_vectors(p, model) for p in X])\n",
        "    return feats\n",
        "\n",
        "wv_train_feat = word2vec_features(X_train[\"sentance\"], model)\n",
        "wv_train_feat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv = RandomForestClassifier(n_estimators=50)\n",
        "clfwv.fit(wv_train_feat, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv_test_feat = word2vec_features(X_test[\"sentance\"], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.544"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv.score(wv_test_feat, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La performance est nettement moindre et notamment moindre que la performance obtenue avec l'*ACP*. Il faudrait sans doute jouer avec les hyperparam\u00e8tres de l'apprentissage ou r\u00e9utiliser un model appris sur un corpus similaire aux donn\u00e9es initiales mais nettement plus grand. On peut constater que la fonction de similarit\u00e9s ne retourne pas des r\u00e9sultat tr\u00e8s int\u00e9ressants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a',\n",
              " 'ability',\n",
              " 'about',\n",
              " 'above',\n",
              " 'absolutely',\n",
              " 'abysmal',\n",
              " 'accept',\n",
              " 'accused',\n",
              " 'achievement',\n",
              " 'acknowledged']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = list(sorted(model.wv.vocab))\n",
        "words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python370_x64\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>abysmal</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>above</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.157058</td>\n",
              "      <td>0.542828</td>\n",
              "      <td>0.239325</td>\n",
              "      <td>-0.007335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>0.157058</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.529392</td>\n",
              "      <td>0.032989</td>\n",
              "      <td>0.275927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abysmal</th>\n",
              "      <td>0.542828</td>\n",
              "      <td>0.529392</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.025218</td>\n",
              "      <td>-0.043980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0.239325</td>\n",
              "      <td>0.032989</td>\n",
              "      <td>0.025218</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.414822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>-0.007335</td>\n",
              "      <td>0.275927</td>\n",
              "      <td>-0.043980</td>\n",
              "      <td>0.414822</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             above  absolutely   abysmal     after    before\n",
              "w1                                                            \n",
              "above       1.000000    0.157058  0.542828  0.239325 -0.007335\n",
              "absolutely  0.157058    1.000000  0.529392  0.032989  0.275927\n",
              "abysmal     0.542828    0.529392  1.000000  0.025218 -0.043980\n",
              "after       0.239325    0.032989  0.025218  1.000000  0.414822\n",
              "before     -0.007335    0.275927 -0.043980  0.414822  1.000000"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subset = ['after', 'before', words[3], words[4], words[5]]\n",
        "rows = []\n",
        "for w in subset:\n",
        "    for ww in subset:\n",
        "        rows.append(dict(w1=w, w2=ww, d=model.wv.similarity(w, ww)))\n",
        "import pandas\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec pr\u00e9-entra\u00een\u00e9s\n",
        "\n",
        "Ce mod\u00e8le est plus performant avec plus de donn\u00e9es.\n",
        "On peut t\u00e9l\u00e9charger des mod\u00e8les pr\u00e9-entra\u00eener sur des donn\u00e9es plus volumineuses :\n",
        " [Pre-Trained Word2Vec Models](https://github.com/jhlau/doc2vec) ou encore [Pre-trained word vectors of 30+ languages](https://github.com/Kyubyong/wordvectors). Ceux-ci sont plut\u00f4t gros (> 600 Mo). Le module *spacy* propose une version plus l\u00e9g\u00e8re et mieux document\u00e9e [Word Vectors and Semantic Similarity](https://spacy.io/usage/vectors-similarity) avec les donn\u00e9es [en_core_web_md](https://github.com/explosion/spacy-models/releases)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python370_x64\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  return f(*args, **kwds)\n",
            "c:\\python370_x64\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
            "  return f(*args, **kwds)\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.cli import download\n",
        "# download(\"en_core_web_md\")  # \u00e7a ne marche pas toujours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T\u00e9l\u00e9chargement de  en_core_web_md-2.0.0.tar.gz\n",
            "[download_data]    download 'https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz' to 'en_core_web_md-2.0.0.tar.gz'\n",
            "Found en_core_web_md-2.0.0/en_core_web_md/en_core_web_md-2.0.0\n",
            "Chargement des donn\u00e9es par spacy.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python370_x64\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  return f(*args, **kwds)\n",
            "c:\\python370_x64\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
            "  return f(*args, **kwds)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "unzip_dest = 'en_core_web_md-2.0.0.tar/dist/en_core_web_md-2.0.0/en_core_web_md/en_core_web_md-2.0.0'\n",
        "if not os.path.exists(unzip_dest):\n",
        "    from pyquickhelper.pycode import is_travis_or_appveyor\n",
        "    if not is_travis_or_appveyor():\n",
        "        # On le fait seulement si ce n'est pas un test d'int\u00e9gration continue.\n",
        "        url = \"https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/\"\n",
        "        name = \"en_core_web_md-2.0.0.tar.gz\"\n",
        "        print(\"T\u00e9l\u00e9chargement de \", name)\n",
        "        from pyensae.datasource import download_data\n",
        "        unzipped = download_data(name, url=url, fLOG=print)\n",
        "        unzip_dest = os.path.split(unzipped[0])[0]\n",
        "        unzip_dest = \"en_core_web_md-2.0.0/en_core_web_md/en_core_web_md-2.0.0\"\n",
        "        print(\"Found\", unzip_dest)\n",
        "        \n",
        "if os.path.exists(unzip_dest):\n",
        "    print(\"Chargement des donn\u00e9es par spacy.\")\n",
        "    nlp = spacy.load(unzip_dest)\n",
        "    continue_wv = True\n",
        "else:\n",
        "    continue_wv = False\n",
        "    print('Pas de donn\u00e9es on passe la suite.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python370_x64\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "      <th>films</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>about</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.329528</td>\n",
              "      <td>-0.097802</td>\n",
              "      <td>0.341220</td>\n",
              "      <td>0.237582</td>\n",
              "      <td>0.257464</td>\n",
              "      <td>-0.067431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>above</th>\n",
              "      <td>0.329528</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.157058</td>\n",
              "      <td>0.239325</td>\n",
              "      <td>-0.007335</td>\n",
              "      <td>0.109095</td>\n",
              "      <td>0.149444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>-0.097802</td>\n",
              "      <td>0.157058</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.032989</td>\n",
              "      <td>0.275927</td>\n",
              "      <td>-0.147693</td>\n",
              "      <td>0.234480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0.341220</td>\n",
              "      <td>0.239325</td>\n",
              "      <td>0.032989</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.414822</td>\n",
              "      <td>0.072878</td>\n",
              "      <td>0.211817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>0.237582</td>\n",
              "      <td>-0.007335</td>\n",
              "      <td>0.275927</td>\n",
              "      <td>0.414822</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.055273</td>\n",
              "      <td>-0.048712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>films</th>\n",
              "      <td>0.257464</td>\n",
              "      <td>0.109095</td>\n",
              "      <td>-0.147693</td>\n",
              "      <td>0.072878</td>\n",
              "      <td>-0.055273</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.062384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>italian</th>\n",
              "      <td>-0.067431</td>\n",
              "      <td>0.149444</td>\n",
              "      <td>0.234480</td>\n",
              "      <td>0.211817</td>\n",
              "      <td>-0.048712</td>\n",
              "      <td>0.062384</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             about     above  absolutely     after    before     films  \\\n",
              "w1                                                                         \n",
              "about       1.000000  0.329528   -0.097802  0.341220  0.237582  0.257464   \n",
              "above       0.329528  1.000000    0.157058  0.239325 -0.007335  0.109095   \n",
              "absolutely -0.097802  0.157058    1.000000  0.032989  0.275927 -0.147693   \n",
              "after       0.341220  0.239325    0.032989  1.000000  0.414822  0.072878   \n",
              "before      0.237582 -0.007335    0.275927  0.414822  1.000000 -0.055273   \n",
              "films       0.257464  0.109095   -0.147693  0.072878 -0.055273  1.000000   \n",
              "italian    -0.067431  0.149444    0.234480  0.211817 -0.048712  0.062384   \n",
              "\n",
              "w2           italian  \n",
              "w1                    \n",
              "about      -0.067431  \n",
              "above       0.149444  \n",
              "absolutely  0.234480  \n",
              "after       0.211817  \n",
              "before     -0.048712  \n",
              "films       0.062384  \n",
              "italian     1.000000  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    tokens = nlp('after before italian films about above absolutely')\n",
        "    rows = []\n",
        "    for token1 in tokens:\n",
        "        for token2 in tokens:\n",
        "            sim = model.wv.similarity(token1.text, token2.text)\n",
        "            rows.append(dict(w1=token1.text, w2=token2.text, d=sim))\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(300,) [ 0.2069    0.44321  -0.12522  -0.017724 -0.064277 -0.44308   0.014019\n",
            " -0.10119   0.22699   3.1689  ]\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(tokens[0].vector.shape, tokens[0].vector[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2250, 300)\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def spacy_sum_vectors(phrase, nlp):\n",
        "    dec = nlp(phrase)\n",
        "    return sum(w.vector for w in dec)\n",
        "\n",
        "def spacy_word2vec_features(X, nlp):\n",
        "    feats = numpy.vstack([spacy_sum_vectors(p, nlp) for p in X])\n",
        "    return feats\n",
        "\n",
        "if continue_wv:\n",
        "    wv_train_feat2 = spacy_word2vec_features(X_train[\"sentance\"], nlp)\n",
        "    print(wv_train_feat2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    clfwv2 = RandomForestClassifier(n_estimators=50)\n",
        "    clfwv2.fit(wv_train_feat2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    wv_test_feat2 = spacy_word2vec_features(X_test[\"sentance\"], nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7773333333333333\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(clfwv2.score(wv_test_feat2, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est un peu mieux mais un peu plus co\u00fbteux en temps de calcul mais m\u00eame sans entra\u00eenement, le mod\u00e8le obtenu est plus performant avec 300 dimensions que celui obtenu avec l'ACP. Le corpus ext\u00e9rieur au probl\u00e8me apporte de la valeur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}