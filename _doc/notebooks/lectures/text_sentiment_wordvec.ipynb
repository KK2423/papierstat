{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification de phrases avec word2vec\n",
        "\n",
        "Le texte est toujours d\u00e9licat \u00e0 traiter. La langue est importante et plus le vocabulaire est \u00e9tendu, plus il faut de donn\u00e9es. Le probl\u00e8me qui suit est classique, on cherche \u00e0 cat\u00e9goriser des phrases en sentiment positif ou n\u00e9gatif. Ce pourrait \u00eatre aussi classer des spams. Le probl\u00e8me le plus simple : une phrase, un label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les donn\u00e9es\n",
        "\n",
        "Elles proviennent de [Sentiment Labelled Sentences Data Set](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentance</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentance  sentiment  \\\n",
              "0  So there is no way for me to plug it in here i...          0   \n",
              "1                        Good case, Excellent value.          1   \n",
              "2                             Great for the jawbone.          1   \n",
              "3  Tied to charger for conversations lasting more...          0   \n",
              "4                                  The mic is great.          1   \n",
              "\n",
              "                  source  \n",
              "0  amazon_cells_labelled  \n",
              "1  amazon_cells_labelled  \n",
              "2  amazon_cells_labelled  \n",
              "3  amazon_cells_labelled  \n",
              "4  amazon_cells_labelled  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from papierstat.datasets import load_sentiment_dataset\n",
        "df = load_sentiment_dataset()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>sentance</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">amazon_cells_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">imdb_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">yelp_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 sentance\n",
              "source                sentiment          \n",
              "amazon_cells_labelled 0               500\n",
              "                      1               500\n",
              "imdb_labelled         0               500\n",
              "                      1               500\n",
              "yelp_labelled         0               500\n",
              "                      1               500"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(['source', 'sentiment']).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On d\u00e9coupe en train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[[\"sentance\"]], df['sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## L'approche classique\n",
        "\n",
        "[TF-IDF](https://fr.wikipedia.org/wiki/TF-IDF) est une approche tr\u00e8s r\u00e9pandue lorsqu'il s'agit de convertir des phrases en features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 4428)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "pipe = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
        "pipe.fit(X_train['sentance'])\n",
        "feat_train = pipe.transform(X_train['sentance'])\n",
        "feat_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_train.min(), feat_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(750, 4428)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test = pipe.transform(X_test['sentance'])\n",
        "feat_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=50)\n",
        "clf.fit(feat_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7853333333333333"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "score = clf.predict_proba(feat_test)\n",
        "fpr, tpr, th = roc_curve(y_test, score[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "aucf = auc(fpr, tpr)\n",
        "ax.plot(fpr, tpr, label='auc=%1.5f' % aucf)\n",
        "ax.set_title('Courbe ROC - classifieur de sentiments')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les n-grammes\n",
        "\n",
        "L'approche pr\u00e9sent\u00e9e ci-dessus ne tient pas compte de l'ordre des mots. Chaque phrase est convertie en un sac de mots (ou [bag of words](https://fr.wikipedia.org/wiki/Sac_de_mots)). Il est n\u00e9anmoins possible de tenir compte de s\u00e9quence plus ou moins longue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# s'il faut t\u00e9l\u00e9charger des donn\u00e9es\n",
        "if False:\n",
        "    import nltk\n",
        "    nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(None, None, 'It'),\n",
              " (None, 'It', 'feels'),\n",
              " ('It', 'feels', 'poorly'),\n",
              " ('feels', 'poorly', 'constructed'),\n",
              " ('poorly', 'constructed', ','),\n",
              " ('constructed', ',', 'the'),\n",
              " (',', 'the', 'menus')]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "generated_ngrams = ngrams(word_tokenize(X_train.iloc[0,0]), 3, pad_left=True, pad_right=True)\n",
        "list(generated_ngrams)[:7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[scikit-learn](http://scikit-learn.org/stable/modules/feature_extraction.html#limitations-of-the-bag-of-words-representation) permet d'essayer cette id\u00e9e simplement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 20449)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe2 = make_pipeline(CountVectorizer(ngram_range=(1, 2)),\n",
        "                      TfidfTransformer())\n",
        "pipe2.fit(X_train['sentance'])\n",
        "feat_train2 = pipe2.transform(X_train['sentance'])\n",
        "feat_train2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il y a plus de colonnes, on v\u00e9rifie malgr\u00e9 tout que les features ressemblent \u00e0 des couples de mots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['00',\n",
              " '10',\n",
              " '10 10',\n",
              " '10 and',\n",
              " '10 feet',\n",
              " '10 grade',\n",
              " '10 minutes',\n",
              " '10 of',\n",
              " '10 on',\n",
              " '10 out']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cl = pipe2.steps[0]\n",
        "cl[1].get_feature_names()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est le cas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "feat_test2 = pipe2.transform(X_test['sentance'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf2 = RandomForestClassifier(n_estimators=50)\n",
        "clf2.fit(feat_train2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7573333333333333"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf2.score(feat_test2, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cela n'am\u00e9liore pas de fa\u00e7on significative. Il faudrait faire une cross-validation pour s'en assurer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## R\u00e9duire les dimensions avec une ACP\n",
        "\n",
        "C'est un moyen fr\u00e9quemment utilis\u00e9 pour r\u00e9duire les dimensions. On choisit le mod\u00e8le [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD) plut\u00f4t que l'[ACP](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA) dont l'impl\u00e9mentation ne supporte pas les features sparses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "pipe_svd = make_pipeline(CountVectorizer(), TruncatedSVD(n_components=300))\n",
        "pipe_svd.fit(X_train['sentance'])\n",
        "feat_train_svd = pipe_svd.transform(X_train['sentance'])\n",
        "feat_train_svd.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_svd = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd.fit(feat_train_svd, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.716"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test_svd = pipe_svd.transform(X_test['sentance'])\n",
        "clf_svd.score(feat_test_svd, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et si on repart de TF-IDF :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7013333333333334"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_svd_tfidf = make_pipeline(CountVectorizer(), \n",
        "                     TfidfTransformer(),\n",
        "                     TruncatedSVD(n_components=300))\n",
        "pipe_svd_tfidf.fit(X_train['sentance'])\n",
        "feat_train_svd_tfidf = pipe_svd_tfidf.transform(X_train['sentance'])\n",
        "\n",
        "clf_svd_tfidf = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd_tfidf.fit(feat_train_svd_tfidf, y_train)\n",
        "\n",
        "feat_test_svd_tfidf = pipe_svd_tfidf.transform(X_test['sentance'])\n",
        "clf_svd_tfidf.score(feat_test_svd_tfidf, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est mieux mais cela reste moins bien que le *tf-idf* sans r\u00e9duction de dimensions. Cela veut dire qu'il faut garder plus de dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec\n",
        "\n",
        "[word2vec](https://en.wikipedia.org/wiki/Word2vec) est une sorte d'ACP non lin\u00e9aire en ce sens qu'il r\u00e9duit les dimensions. Il faut lire [Analyse en composantes principales (ACP) et Auto Encoders](http://www.xavierdupre.fr/app/mlstatpy/helpsphinx/c_ml/rn/rn_9_auto.html) pour comprendre le lien entre ACP, ACP non lin\u00e9aire, r\u00e9seaux de neurones diabolo et compression. *word2vec* est plus d'une ACP non lin\u00e9aire car il prend en compte le contexte mais ne s'en \u00e9loigne pas tant que ce \u00e7a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['it',\n",
              " 'feels',\n",
              " 'poorly',\n",
              " 'constructed',\n",
              " 'the',\n",
              " 'menus',\n",
              " 'are',\n",
              " 'difficult',\n",
              " 'to',\n",
              " 'navigate',\n",
              " 'and',\n",
              " 'the',\n",
              " 'buttons',\n",
              " 'are',\n",
              " 'so',\n",
              " 'recessed',\n",
              " 'that',\n",
              " 'it',\n",
              " 'is',\n",
              " 'difficult',\n",
              " 'to',\n",
              " 'push',\n",
              " 'them']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.utils import tokenize\n",
        "sentance = [list(tokenize(s, deacc=True, lower=True)) for s in X_train['sentance']]\n",
        "sentance[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les param\u00e8tres d'apprentissage du mod\u00e8le [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) ne sont pas toujours d\u00e9crit de fa\u00e7on explicite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2250"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.models import word2vec\n",
        "model = word2vec.Word2Vec(sentance, size=300, window=20,\n",
        "                          min_count=2, workers=1, iter=100)\n",
        "model.corpus_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['it', 'feels', 'poorly', 'constructed', 'the']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = model.wv.vocab\n",
        "list(vocab)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('trained_word2vec.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les dix premi\u00e8res coordonn\u00e9es du vecteur associ\u00e9 au mot ``after``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((300,),\n",
              " array([ 0.9671115 ,  1.3525798 , -0.49374732, -0.18475717, -0.06998392,\n",
              "        -0.79253405, -0.18820015, -0.2896375 , -0.77397734, -0.5275416 ],\n",
              "       dtype=float32))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv['after'].shape, model.wv['after'][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lorsque le mot est inconnu :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"word 'rrrrrrrr' not in vocabulary\"\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    model.wv['rrrrrrrr']\n",
        "except KeyError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour chaque phrase, on fait la somme des vecteurs associ\u00e9s aux mots qui la composent ou pas si le mot n'est pas dans le vocabulaire. Il y a probablement des fonctions d\u00e9j\u00e0 pr\u00eates \u00e0 l'emploi mais la documentation de [gensim](https://radimrehurek.com/gensim/index.html) n'\u00e9tait pas assez explicite et lire l'article [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) puis celui-ci [Distributed Representations of Words and Phrases\n",
        "and their Compositionality](https://arxiv.org/pdf/1310.4546.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def get_vect(word, model):\n",
        "    try:\n",
        "        return model.wv[word]\n",
        "    except KeyError:\n",
        "        return numpy.zeros((model.vector_size,))\n",
        "\n",
        "def sum_vectors(phrase, model):\n",
        "    return sum(get_vect(w, model) for w in phrase)\n",
        "\n",
        "def word2vec_features(X, model):\n",
        "    feats = numpy.vstack([sum_vectors(p, model) for p in X])\n",
        "    return feats\n",
        "\n",
        "wv_train_feat = word2vec_features(X_train[\"sentance\"], model)\n",
        "wv_train_feat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv = RandomForestClassifier(n_estimators=50)\n",
        "clfwv.fit(wv_train_feat, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv_test_feat = word2vec_features(X_test[\"sentance\"], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5573333333333333"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv.score(wv_test_feat, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La performance est nettement moindre et notamment moindre que la performance obtenue avec l'*ACP*. Il faudrait sans doute jouer avec les hyperparam\u00e8tres de l'apprentissage ou r\u00e9utiliser un model appris sur un corpus similaire aux donn\u00e9es initiales mais nettement plus grand. On peut constater que la fonction de similarit\u00e9s ne retourne pas des r\u00e9sultat tr\u00e8s int\u00e9ressants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a',\n",
              " 'ability',\n",
              " 'able',\n",
              " 'about',\n",
              " 'above',\n",
              " 'absolutely',\n",
              " 'abysmal',\n",
              " 'accept',\n",
              " 'access',\n",
              " 'accused']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = list(sorted(model.wv.vocab))\n",
        "words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>about</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.134235</td>\n",
              "      <td>0.073940</td>\n",
              "      <td>0.426866</td>\n",
              "      <td>-0.130222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>above</th>\n",
              "      <td>0.134235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.195141</td>\n",
              "      <td>0.236995</td>\n",
              "      <td>-0.195996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>0.073940</td>\n",
              "      <td>0.195141</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.028921</td>\n",
              "      <td>0.180653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0.426866</td>\n",
              "      <td>0.236995</td>\n",
              "      <td>0.028921</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.157039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>-0.130222</td>\n",
              "      <td>-0.195996</td>\n",
              "      <td>0.180653</td>\n",
              "      <td>0.157039</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             about     above  absolutely     after    before\n",
              "w1                                                            \n",
              "about       1.000000  0.134235    0.073940  0.426866 -0.130222\n",
              "above       0.134235  1.000000    0.195141  0.236995 -0.195996\n",
              "absolutely  0.073940  0.195141    1.000000  0.028921  0.180653\n",
              "after       0.426866  0.236995    0.028921  1.000000  0.157039\n",
              "before     -0.130222 -0.195996    0.180653  0.157039  1.000000"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subset = ['after', 'before', words[3], words[4], words[5]]\n",
        "rows = []\n",
        "for w in subset:\n",
        "    for ww in subset:\n",
        "        rows.append(dict(w1=w, w2=ww, d=model.wv.similarity(w, ww)))\n",
        "import pandas\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec pr\u00e9-entra\u00een\u00e9s\n",
        "\n",
        "Ce mod\u00e8le est plus performant avec plus de donn\u00e9es.\n",
        "On peut t\u00e9l\u00e9charger des mod\u00e8les pr\u00e9-entra\u00eener sur des donn\u00e9es plus volumineuses :\n",
        " [Pre-Trained Word2Vec Models](https://github.com/jhlau/doc2vec) ou encore [Pre-trained word vectors of 30+ languages](https://github.com/Kyubyong/wordvectors). Ceux-ci sont plut\u00f4t gros (> 600 Mo). Le module *spacy* propose une version plus l\u00e9g\u00e8re et mieux document\u00e9e [Word Vectors and Semantic Similarity](https://spacy.io/usage/vectors-similarity) avec les donn\u00e9es [en_core_web_md](https://github.com/explosion/spacy-models/releases)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.cli import download\n",
        "# download(\"en_core_web_md\")  # \u00e7a ne marche pas toujours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T\u00e9l\u00e9chargement de  en_core_web_md-2.1.0.tar.gz\n",
            "[download_data]    download 'https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz' to 'en_core_web_md-2.1.0.tar.gz'\n",
            "Found en_core_web_md-2.1.0/en_core_web_md/en_core_web_md-2.1.0\n",
            "Chargement des donn\u00e9es par spacy.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "version = \"2.1.0\"\n",
        "unzip_dest = 'en_core_web_md-{0}.tar/dist/en_core_web_md-{0}/en_core_web_md/en_core_web_md-{0}'.format(version)\n",
        "if not os.path.exists(unzip_dest):\n",
        "    from pyquickhelper.pycode import is_travis_or_appveyor\n",
        "    if not is_travis_or_appveyor():\n",
        "        # On le fait seulement si ce n'est pas un test d'int\u00e9gration continue.\n",
        "        url = \"https://github.com/explosion/spacy-models/releases/download/en_core_web_md-%s/\" % version\n",
        "        name = \"en_core_web_md-%s.tar.gz\" % version\n",
        "        print(\"T\u00e9l\u00e9chargement de \", name)\n",
        "        from pyensae.datasource import download_data\n",
        "        unzipped = download_data(name, url=url, fLOG=print)\n",
        "        unzip_dest = os.path.split(unzipped[0])[0]\n",
        "        unzip_dest = \"en_core_web_md-{0}/en_core_web_md/en_core_web_md-{0}\".format(version)\n",
        "        print(\"Found\", unzip_dest)\n",
        "        \n",
        "if os.path.exists(unzip_dest):\n",
        "    print(\"Chargement des donn\u00e9es par spacy.\")\n",
        "    nlp = spacy.load(unzip_dest)\n",
        "    continue_wv = True\n",
        "else:\n",
        "    continue_wv = False\n",
        "    print('Pas de donn\u00e9es on passe la suite.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "      <th>films</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>about</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.134235</td>\n",
              "      <td>0.073940</td>\n",
              "      <td>0.426866</td>\n",
              "      <td>-0.130222</td>\n",
              "      <td>0.125484</td>\n",
              "      <td>0.015697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>above</th>\n",
              "      <td>0.134235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.195141</td>\n",
              "      <td>0.236995</td>\n",
              "      <td>-0.195996</td>\n",
              "      <td>0.212968</td>\n",
              "      <td>0.078192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>0.073940</td>\n",
              "      <td>0.195141</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.028921</td>\n",
              "      <td>0.180653</td>\n",
              "      <td>0.043050</td>\n",
              "      <td>0.162685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0.426866</td>\n",
              "      <td>0.236995</td>\n",
              "      <td>0.028921</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.157039</td>\n",
              "      <td>0.073300</td>\n",
              "      <td>0.121299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>-0.130222</td>\n",
              "      <td>-0.195996</td>\n",
              "      <td>0.180653</td>\n",
              "      <td>0.157039</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.221895</td>\n",
              "      <td>-0.110091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>films</th>\n",
              "      <td>0.125484</td>\n",
              "      <td>0.212968</td>\n",
              "      <td>0.043050</td>\n",
              "      <td>0.073300</td>\n",
              "      <td>0.221895</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.209109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>italian</th>\n",
              "      <td>0.015697</td>\n",
              "      <td>0.078192</td>\n",
              "      <td>0.162685</td>\n",
              "      <td>0.121299</td>\n",
              "      <td>-0.110091</td>\n",
              "      <td>0.209109</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             about     above  absolutely     after    before     films  \\\n",
              "w1                                                                         \n",
              "about       1.000000  0.134235    0.073940  0.426866 -0.130222  0.125484   \n",
              "above       0.134235  1.000000    0.195141  0.236995 -0.195996  0.212968   \n",
              "absolutely  0.073940  0.195141    1.000000  0.028921  0.180653  0.043050   \n",
              "after       0.426866  0.236995    0.028921  1.000000  0.157039  0.073300   \n",
              "before     -0.130222 -0.195996    0.180653  0.157039  1.000000  0.221895   \n",
              "films       0.125484  0.212968    0.043050  0.073300  0.221895  1.000000   \n",
              "italian     0.015697  0.078192    0.162685  0.121299 -0.110091  0.209109   \n",
              "\n",
              "w2           italian  \n",
              "w1                    \n",
              "about       0.015697  \n",
              "above       0.078192  \n",
              "absolutely  0.162685  \n",
              "after       0.121299  \n",
              "before     -0.110091  \n",
              "films       0.209109  \n",
              "italian     1.000000  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    tokens = nlp('after before italian films about above absolutely')\n",
        "    rows = []\n",
        "    for token1 in tokens:\n",
        "        for token2 in tokens:\n",
        "            sim = model.wv.similarity(token1.text, token2.text)\n",
        "            rows.append(dict(w1=token1.text, w2=token2.text, d=sim))\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(300,) [ 0.2069    0.44321  -0.12522  -0.017724 -0.064277 -0.44308   0.014019\n",
            " -0.10119   0.22699   3.1689  ]\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(tokens[0].vector.shape, tokens[0].vector[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2250, 300)\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def spacy_sum_vectors(phrase, nlp):\n",
        "    dec = nlp(phrase)\n",
        "    return sum(w.vector for w in dec)\n",
        "\n",
        "def spacy_word2vec_features(X, nlp):\n",
        "    feats = numpy.vstack([spacy_sum_vectors(p, nlp) for p in X])\n",
        "    return feats\n",
        "\n",
        "if continue_wv:\n",
        "    wv_train_feat2 = spacy_word2vec_features(X_train[\"sentance\"], nlp)\n",
        "    print(wv_train_feat2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    clfwv2 = RandomForestClassifier(n_estimators=50)\n",
        "    clfwv2.fit(wv_train_feat2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    wv_test_feat2 = spacy_word2vec_features(X_test[\"sentance\"], nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.78\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(clfwv2.score(wv_test_feat2, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est un peu mieux mais un peu plus co\u00fbteux en temps de calcul mais m\u00eame sans entra\u00eenement, le mod\u00e8le obtenu est plus performant avec 300 dimensions que celui obtenu avec l'ACP. Le corpus ext\u00e9rieur au probl\u00e8me apporte de la valeur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}