{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification de phrases avec word2vec\n",
        "\n",
        "Le texte est toujours d\u00e9licat \u00e0 traiter. La langue est importante et plus le vocabulaire est \u00e9tendu, plus il faut de donn\u00e9es. Le probl\u00e8me qui suit est classique, on cherche \u00e0 cat\u00e9goriser des phrases en sentiment positif ou n\u00e9gatif. Ce pourrait \u00eatre aussi classer des spams. Le probl\u00e8me le plus simple : une phrase, un label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les donn\u00e9es\n",
        "\n",
        "Elles proviennent de [Sentiment Labelled Sentences Data Set](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  sentiment  \\\n",
              "0  So there is no way for me to plug it in here i...          0   \n",
              "1                        Good case, Excellent value.          1   \n",
              "2                             Great for the jawbone.          1   \n",
              "3  Tied to charger for conversations lasting more...          0   \n",
              "4                                  The mic is great.          1   \n",
              "\n",
              "                  source  \n",
              "0  amazon_cells_labelled  \n",
              "1  amazon_cells_labelled  \n",
              "2  amazon_cells_labelled  \n",
              "3  amazon_cells_labelled  \n",
              "4  amazon_cells_labelled  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from papierstat.datasets import load_sentiment_dataset\n",
        "df = load_sentiment_dataset()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">amazon_cells_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">imdb_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">yelp_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 sentence\n",
              "source                sentiment          \n",
              "amazon_cells_labelled 0               500\n",
              "                      1               500\n",
              "imdb_labelled         0               500\n",
              "                      1               500\n",
              "yelp_labelled         0               500\n",
              "                      1               500"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(['source', 'sentiment']).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On d\u00e9coupe en train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[[\"sentence\"]], df['sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## L'approche classique\n",
        "\n",
        "[TF-IDF](https://fr.wikipedia.org/wiki/TF-IDF) est une approche tr\u00e8s r\u00e9pandue lorsqu'il s'agit de convertir des phrases en features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 4324)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "pipe = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
        "pipe.fit(X_train['sentence'])\n",
        "feat_train = pipe.transform(X_train['sentence'])\n",
        "feat_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_train.min(), feat_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(750, 4324)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test = pipe.transform(X_test['sentence'])\n",
        "feat_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=50)\n",
        "clf.fit(feat_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.768"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "score = clf.predict_proba(feat_test)\n",
        "fpr, tpr, th = roc_curve(y_test, score[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "aucf = auc(fpr, tpr)\n",
        "ax.plot(fpr, tpr, label='auc=%1.5f' % aucf)\n",
        "ax.set_title('Courbe ROC - classifieur de sentiments')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autres mod\u00e8les que la RandomForest\n",
        "\n",
        "La for\u00eat al\u00e9atoire n'est pas n\u00e9cessairement le meilleur mod\u00e8le, comme l'affirme [#25 - Choix des classificateurs dans Classification de phrases avec word2vect](https://github.com/sdpython/papierstat/issues/25). La transformation du texte en feature g\u00e9n\u00e8re beaucoup de variables et un arbre de d\u00e9cision n'exploite quasiment que le fait qu'elles soient non nulles. Un arbre de d\u00e9cision consiste \u00e0 prendre des d\u00e9cisions sur des seuils puis retourne une constante tirer d'une feuille de l'arbre. Un mod\u00e8le lin\u00e9aire ferait tout aussi bien l'affaire avec en plus la possibilit\u00e9 de tenir compte de la valeur de la variable.\n",
        "\n",
        "L'autre aspect \u00e0 prendre en compte est la profondeur de l'arbre. Par d\u00e9faut, elle est de 10, soit $2^{10}=1024$ d\u00e9cisions de seuils, soit au mieux $2^{10}$ variables ce qui est loin du nombre de variables total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(750, 4324)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Essayons d'abord avec un mod\u00e8le lin\u00e9aire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8013333333333333"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(feat_train, y_train)\n",
        "lr.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8106666666666666"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(feat_train, y_train)\n",
        "mnb.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On v\u00e9rifie ensuite qu'en augmentant la profondeur de l'arbre, la for\u00eat al\u00e9atoire est plus performante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7466666666666667"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf20 = RandomForestClassifier(n_estimators=50, max_depth=20)\n",
        "clf20.fit(feat_train, y_train)\n",
        "clf20.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7693333333333333"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf40 = RandomForestClassifier(n_estimators=50, max_depth=40)\n",
        "clf40.fit(feat_train, y_train)\n",
        "clf40.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7693333333333333"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf60 = RandomForestClassifier(n_estimators=50, max_depth=60)\n",
        "clf60.fit(feat_train, y_train)\n",
        "clf60.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ainsi qu'en augmentant le nombre d'arbre puisque l'algorithme balaiera plus de variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7693333333333333"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf40 = RandomForestClassifier(n_estimators=200, max_depth=40)\n",
        "clf40.fit(feat_train, y_train)\n",
        "clf40.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Un seul arbre de d\u00e9cision produira des r\u00e9sultats plut\u00f4t pauvres."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7053333333333334"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(feat_train, y_train)\n",
        "dt.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Enfin, un mod\u00e8le de gradient boosting devrait sans doute d\u00e9passer les for\u00eats al\u00e9atoires puisque les arbres ne sont plus appris ind\u00e9pendemment les uns des autres."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.772"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gbc40 = GradientBoostingClassifier(n_estimators=200, max_depth=40)\n",
        "gbc40.fit(feat_train, y_train)\n",
        "gbc40.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On garde la r\u00e9gression logistique pour la suite."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les n-grammes\n",
        "\n",
        "L'approche pr\u00e9sent\u00e9e ci-dessus ne tient pas compte de l'ordre des mots. Chaque phrase est convertie en un sac de mots (ou [bag of words](https://fr.wikipedia.org/wiki/Sac_de_mots)). Il est n\u00e9anmoins possible de tenir compte de s\u00e9quence plus ou moins longue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# s'il faut t\u00e9l\u00e9charger des donn\u00e9es\n",
        "if False:\n",
        "    import nltk\n",
        "    nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(None, None, 'Their'),\n",
              " (None, 'Their', 'chow'),\n",
              " ('Their', 'chow', 'mein'),\n",
              " ('chow', 'mein', 'is'),\n",
              " ('mein', 'is', 'so'),\n",
              " ('is', 'so', 'good'),\n",
              " ('so', 'good', '!')]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "generated_ngrams = ngrams(word_tokenize(X_train.iloc[0,0]), 3, pad_left=True, pad_right=True)\n",
        "list(generated_ngrams)[:7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[scikit-learn](http://scikit-learn.org/stable/modules/feature_extraction.html#limitations-of-the-bag-of-words-representation) permet d'essayer cette id\u00e9e simplement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 20067)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe2 = make_pipeline(CountVectorizer(ngram_range=(1, 2)),\n",
        "                      TfidfTransformer())\n",
        "pipe2.fit(X_train['sentence'])\n",
        "feat_train2 = pipe2.transform(X_train['sentence'])\n",
        "feat_train2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il y a plus de colonnes, on v\u00e9rifie malgr\u00e9 tout que les features ressemblent \u00e0 des couples de mots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['00',\n",
              " '10',\n",
              " '10 10',\n",
              " '10 feet',\n",
              " '10 for',\n",
              " '10 grade',\n",
              " '10 minutes',\n",
              " '10 on',\n",
              " '10 out',\n",
              " '10 plus']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cl = pipe2.steps[0]\n",
        "cl[1].get_feature_names()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est le cas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "feat_test2 = pipe2.transform(X_test['sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf2 = LogisticRegression()\n",
        "clf2.fit(feat_train2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf2.score(feat_test2, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cela n'am\u00e9liore pas de fa\u00e7on significative. Il faudrait faire une cross-validation pour s'en assurer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## R\u00e9duire les dimensions avec une ACP\n",
        "\n",
        "C'est un moyen fr\u00e9quemment utilis\u00e9 pour r\u00e9duire les dimensions. On choisit le mod\u00e8le [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD) plut\u00f4t que l'[ACP](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA) dont l'impl\u00e9mentation ne supporte pas les features sparses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "pipe_svd = make_pipeline(CountVectorizer(), TruncatedSVD(n_components=300))\n",
        "pipe_svd.fit(X_train['sentence'])\n",
        "feat_train_svd = pipe_svd.transform(X_train['sentence'])\n",
        "feat_train_svd.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_svd = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd.fit(feat_train_svd, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.684"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test_svd = pipe_svd.transform(X_test['sentence'])\n",
        "clf_svd.score(feat_test_svd, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7533333333333333"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_svd = LogisticRegression()\n",
        "lr_svd.fit(feat_train_svd, y_train)\n",
        "lr_svd.score(feat_test_svd, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et si on repart de TF-IDF :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7786666666666666"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_svd_tfidf = make_pipeline(CountVectorizer(), \n",
        "                     TfidfTransformer(),\n",
        "                     TruncatedSVD(n_components=300))\n",
        "pipe_svd_tfidf.fit(X_train['sentence'])\n",
        "feat_train_svd_tfidf = pipe_svd_tfidf.transform(X_train['sentence'])\n",
        "\n",
        "clf_svd_tfidf = LogisticRegression()\n",
        "clf_svd_tfidf.fit(feat_train_svd_tfidf, y_train)\n",
        "\n",
        "feat_test_svd_tfidf = pipe_svd_tfidf.transform(X_test['sentence'])\n",
        "clf_svd_tfidf.score(feat_test_svd_tfidf, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est mieux mais cela reste moins bien que le *tf-idf* sans r\u00e9duction de dimensions. Cela veut dire qu'il faut garder plus de dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec\n",
        "\n",
        "[word2vec](https://en.wikipedia.org/wiki/Word2vec) est une sorte d'ACP non lin\u00e9aire en ce sens qu'il r\u00e9duit les dimensions. Il faut lire [Analyse en composantes principales (ACP) et Auto Encoders](http://www.xavierdupre.fr/app/mlstatpy/helpsphinx/c_ml/rn/rn_9_auto.html) pour comprendre le lien entre ACP, ACP non lin\u00e9aire, r\u00e9seaux de neurones diabolo et compression. *word2vec* est plus d'une ACP non lin\u00e9aire car il prend en compte le contexte mais ne s'en \u00e9loigne pas tant que ce \u00e7a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['their', 'chow', 'mein', 'is', 'so', 'good']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.utils import tokenize\n",
        "sentance = [list(tokenize(s, deacc=True, lower=True)) for s in X_train['sentence']]\n",
        "sentance[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les param\u00e8tres d'apprentissage du mod\u00e8le [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) ne sont pas toujours d\u00e9crit de fa\u00e7on explicite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2250"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.models import word2vec\n",
        "model = word2vec.Word2Vec(sentance, size=300, window=20,\n",
        "                          min_count=2, workers=1, iter=100)\n",
        "model.corpus_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['their', 'chow', 'is', 'so', 'good']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = model.wv.vocab\n",
        "list(vocab)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('trained_word2vec.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les dix premi\u00e8res coordonn\u00e9es du vecteur associ\u00e9 au mot ``after``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((300,),\n",
              " array([-0.35271704, -0.7440025 , -0.71504265,  0.5013653 , -0.8039807 ,\n",
              "        -1.1835612 , -0.24699177,  0.03716084,  0.04742139, -0.31049225],\n",
              "       dtype=float32))"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv['after'].shape, model.wv['after'][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lorsque le mot est inconnu :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"word 'rrrrrrrr' not in vocabulary\"\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    model.wv['rrrrrrrr']\n",
        "except KeyError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour chaque phrase, on fait la somme des vecteurs associ\u00e9s aux mots qui la composent ou pas si le mot n'est pas dans le vocabulaire. Il y a probablement des fonctions d\u00e9j\u00e0 pr\u00eates \u00e0 l'emploi mais la documentation de [gensim](https://radimrehurek.com/gensim/index.html) n'\u00e9tait pas assez explicite et lire l'article [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) puis celui-ci [Distributed Representations of Words and Phrases\n",
        "and their Compositionality](https://arxiv.org/pdf/1310.4546.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def get_vect(word, model):\n",
        "    try:\n",
        "        return model.wv[word]\n",
        "    except KeyError:\n",
        "        return numpy.zeros((model.vector_size,))\n",
        "\n",
        "def sum_vectors(phrase, model):\n",
        "    return sum(get_vect(w, model) for w in phrase)\n",
        "\n",
        "def word2vec_features(X, model):\n",
        "    feats = numpy.vstack([sum_vectors(p, model) for p in X])\n",
        "    return feats\n",
        "\n",
        "wv_train_feat = word2vec_features(X_train[\"sentence\"], model)\n",
        "wv_train_feat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "clfwv.fit(wv_train_feat, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv_test_feat = word2vec_features(X_test[\"sentence\"], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5653333333333334"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv.score(wv_test_feat, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La performance est nettement moindre et notamment moindre que la performance obtenue avec l'*ACP*. Il faudrait sans doute jouer avec les hyperparam\u00e8tres de l'apprentissage ou r\u00e9utiliser un model appris sur un corpus similaire aux donn\u00e9es initiales mais nettement plus grand. On peut constater que la fonction de similarit\u00e9s ne retourne pas des r\u00e9sultat tr\u00e8s int\u00e9ressants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a',\n",
              " 'ability',\n",
              " 'able',\n",
              " 'about',\n",
              " 'above',\n",
              " 'absolutely',\n",
              " 'accept',\n",
              " 'accidentally',\n",
              " 'accused',\n",
              " 'achievement']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = list(sorted(model.wv.vocab))\n",
        "words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>about</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.193730</td>\n",
              "      <td>-0.248471</td>\n",
              "      <td>0.426798</td>\n",
              "      <td>0.081973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>above</th>\n",
              "      <td>0.193730</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.215933</td>\n",
              "      <td>0.232336</td>\n",
              "      <td>0.081327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>-0.248471</td>\n",
              "      <td>0.215933</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.062538</td>\n",
              "      <td>0.059916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0.426798</td>\n",
              "      <td>0.232336</td>\n",
              "      <td>0.062538</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.216423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>0.081973</td>\n",
              "      <td>0.081327</td>\n",
              "      <td>0.059916</td>\n",
              "      <td>0.216423</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             about     above  absolutely     after    before\n",
              "w1                                                            \n",
              "about       1.000000  0.193730   -0.248471  0.426798  0.081973\n",
              "above       0.193730  1.000000    0.215933  0.232336  0.081327\n",
              "absolutely -0.248471  0.215933    1.000000  0.062538  0.059916\n",
              "after       0.426798  0.232336    0.062538  1.000000  0.216423\n",
              "before      0.081973  0.081327    0.059916  0.216423  1.000000"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subset = ['after', 'before', words[3], words[4], words[5]]\n",
        "rows = []\n",
        "for w in subset:\n",
        "    for ww in subset:\n",
        "        rows.append(dict(w1=w, w2=ww, d=model.wv.similarity(w, ww)))\n",
        "import pandas\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec pr\u00e9-entra\u00een\u00e9s\n",
        "\n",
        "Ce mod\u00e8le est plus performant avec plus de donn\u00e9es.\n",
        "On peut t\u00e9l\u00e9charger des mod\u00e8les pr\u00e9-entra\u00eener sur des donn\u00e9es plus volumineuses :\n",
        " [Pre-Trained Word2Vec Models](https://github.com/jhlau/doc2vec) ou encore [Pre-trained word vectors of 30+ languages](https://github.com/Kyubyong/wordvectors). Ceux-ci sont plut\u00f4t gros (> 600 Mo). Le module *spacy* propose une version plus l\u00e9g\u00e8re et mieux document\u00e9e [Word Vectors and Semantic Similarity](https://spacy.io/usage/vectors-similarity) avec les donn\u00e9es [en_core_web_md](https://github.com/explosion/spacy-models/releases)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.cli import download\n",
        "# download(\"en_core_web_md\")  # \u00e7a ne marche pas toujours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T\u00e9l\u00e9chargement de  en_core_web_md-2.1.0.tar.gz\n",
            "Found en_core_web_md-2.1.0/en_core_web_md/en_core_web_md-2.1.0\n",
            "Chargement des donn\u00e9es par spacy.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "version = \"2.1.0\"\n",
        "unzip_dest = 'en_core_web_md-{0}.tar/dist/en_core_web_md-{0}/en_core_web_md/en_core_web_md-{0}'.format(version)\n",
        "if not os.path.exists(unzip_dest):\n",
        "    from pyquickhelper.pycode import is_travis_or_appveyor\n",
        "    if not is_travis_or_appveyor():\n",
        "        # On le fait seulement si ce n'est pas un test d'int\u00e9gration continue.\n",
        "        url = \"https://github.com/explosion/spacy-models/releases/download/en_core_web_md-%s/\" % version\n",
        "        name = \"en_core_web_md-%s.tar.gz\" % version\n",
        "        print(\"T\u00e9l\u00e9chargement de \", name)\n",
        "        from pyensae.datasource import download_data\n",
        "        unzipped = download_data(name, url=url, fLOG=print)\n",
        "        unzip_dest = os.path.split(unzipped[0])[0]\n",
        "        unzip_dest = \"en_core_web_md-{0}/en_core_web_md/en_core_web_md-{0}\".format(version)\n",
        "        print(\"Found\", unzip_dest)\n",
        "        \n",
        "if os.path.exists(unzip_dest):\n",
        "    print(\"Chargement des donn\u00e9es par spacy.\")\n",
        "    nlp = spacy.load(unzip_dest)\n",
        "    continue_wv = True\n",
        "else:\n",
        "    continue_wv = False\n",
        "    print('Pas de donn\u00e9es on passe la suite.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "      <th>films</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>about</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.193730</td>\n",
              "      <td>-0.248471</td>\n",
              "      <td>0.426798</td>\n",
              "      <td>0.081973</td>\n",
              "      <td>0.175330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>above</th>\n",
              "      <td>0.193730</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.215933</td>\n",
              "      <td>0.232336</td>\n",
              "      <td>0.081327</td>\n",
              "      <td>-0.226075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>-0.248471</td>\n",
              "      <td>0.215933</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.062538</td>\n",
              "      <td>0.059916</td>\n",
              "      <td>-0.033369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0.426798</td>\n",
              "      <td>0.232336</td>\n",
              "      <td>0.062538</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.216423</td>\n",
              "      <td>0.116398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>0.081973</td>\n",
              "      <td>0.081327</td>\n",
              "      <td>0.059916</td>\n",
              "      <td>0.216423</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.147834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>films</th>\n",
              "      <td>0.175330</td>\n",
              "      <td>-0.226075</td>\n",
              "      <td>-0.033369</td>\n",
              "      <td>0.116398</td>\n",
              "      <td>0.147834</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             about     above  absolutely     after    before     films\n",
              "w1                                                                      \n",
              "about       1.000000  0.193730   -0.248471  0.426798  0.081973  0.175330\n",
              "above       0.193730  1.000000    0.215933  0.232336  0.081327 -0.226075\n",
              "absolutely -0.248471  0.215933    1.000000  0.062538  0.059916 -0.033369\n",
              "after       0.426798  0.232336    0.062538  1.000000  0.216423  0.116398\n",
              "before      0.081973  0.081327    0.059916  0.216423  1.000000  0.147834\n",
              "films       0.175330 -0.226075   -0.033369  0.116398  0.147834  1.000000"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    tokens = nlp('after before films about above absolutely')\n",
        "    rows = []\n",
        "    for token1 in tokens:\n",
        "        for token2 in tokens:\n",
        "            sim = model.wv.similarity(token1.text, token2.text)\n",
        "            rows.append(dict(w1=token1.text, w2=token2.text, d=sim))\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(300,) [ 0.2069    0.44321  -0.12522  -0.017724 -0.064277 -0.44308   0.014019\n",
            " -0.10119   0.22699   3.1689  ]\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(tokens[0].vector.shape, tokens[0].vector[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2250, 300)\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def spacy_sum_vectors(phrase, nlp):\n",
        "    dec = nlp(phrase)\n",
        "    return sum(w.vector for w in dec)\n",
        "\n",
        "def spacy_word2vec_features(X, nlp):\n",
        "    feats = numpy.vstack([spacy_sum_vectors(p, nlp) for p in X])\n",
        "    return feats\n",
        "\n",
        "if continue_wv:\n",
        "    try:\n",
        "        wv_train_feat2 = spacy_word2vec_features(X_train[\"sentence\"], nlp)\n",
        "        print(wv_train_feat2.shape)\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "        continue_wv = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    clfwv2 = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "    clfwv2.fit(wv_train_feat2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    wv_test_feat2 = spacy_word2vec_features(X_test[\"sentence\"], nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8053333333333333\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(clfwv2.score(wv_test_feat2, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est un peu mieux mais un peu plus co\u00fbteux en temps de calcul mais m\u00eame sans entra\u00eenement, le mod\u00e8le obtenu est plus performant avec 300 dimensions que celui obtenu avec l'ACP. Le corpus ext\u00e9rieur au probl\u00e8me apporte de la valeur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}