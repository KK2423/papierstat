{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification de phrases avec word2vec\n",
        "\n",
        "Le texte est toujours d\u00e9licat \u00e0 traiter. La langue est importante et plus le vocabulaire est \u00e9tendu, plus il faut de donn\u00e9es. Le probl\u00e8me qui suit est classique, on cherche \u00e0 cat\u00e9goriser des phrases en sentiment positif ou n\u00e9gatif. Ce pourrait \u00eatre aussi classer des spams. Le probl\u00e8me le plus simple : une phrase, un label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les donn\u00e9es\n",
        "\n",
        "Elles proviennent de [Sentiment Labelled Sentences Data Set](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  sentiment  \\\n",
              "0  So there is no way for me to plug it in here i...          0   \n",
              "1                        Good case, Excellent value.          1   \n",
              "2                             Great for the jawbone.          1   \n",
              "3  Tied to charger for conversations lasting more...          0   \n",
              "4                                  The mic is great.          1   \n",
              "\n",
              "                  source  \n",
              "0  amazon_cells_labelled  \n",
              "1  amazon_cells_labelled  \n",
              "2  amazon_cells_labelled  \n",
              "3  amazon_cells_labelled  \n",
              "4  amazon_cells_labelled  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from papierstat.datasets import load_sentiment_dataset\n",
        "df = load_sentiment_dataset()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">amazon_cells_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">imdb_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">yelp_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 sentence\n",
              "source                sentiment          \n",
              "amazon_cells_labelled 0               500\n",
              "                      1               500\n",
              "imdb_labelled         0               500\n",
              "                      1               500\n",
              "yelp_labelled         0               500\n",
              "                      1               500"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(['source', 'sentiment']).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On d\u00e9coupe en train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[[\"sentence\"]], df['sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## L'approche classique\n",
        "\n",
        "[TF-IDF](https://fr.wikipedia.org/wiki/TF-IDF) est une approche tr\u00e8s r\u00e9pandue lorsqu'il s'agit de convertir des phrases en features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 4335)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "pipe = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
        "pipe.fit(X_train['sentence'])\n",
        "feat_train = pipe.transform(X_train['sentence'])\n",
        "feat_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_train.min(), feat_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(750, 4335)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test = pipe.transform(X_test['sentence'])\n",
        "feat_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=50)\n",
        "clf.fit(feat_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7706666666666667"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "score = clf.predict_proba(feat_test)\n",
        "fpr, tpr, th = roc_curve(y_test, score[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "aucf = auc(fpr, tpr)\n",
        "ax.plot(fpr, tpr, label='auc=%1.5f' % aucf)\n",
        "ax.set_title('Courbe ROC - classifieur de sentiments')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autres mod\u00e8les que la RandomForest\n",
        "\n",
        "La for\u00eat al\u00e9atoire n'est pas n\u00e9cessairement le meilleur mod\u00e8le, comme l'affirme [#25 - Choix des classificateurs dans Classification de phrases avec word2vect](https://github.com/sdpython/papierstat/issues/25). La transformation du texte en feature g\u00e9n\u00e8re beaucoup de variables et un arbre de d\u00e9cision n'exploite quasiment que le fait qu'elles soient non nulles. Un arbre de d\u00e9cision consiste \u00e0 prendre des d\u00e9cisions sur des seuils puis retourne une constante tirer d'une feuille de l'arbre. Un mod\u00e8le lin\u00e9aire ferait tout aussi bien l'affaire avec en plus la possibilit\u00e9 de tenir compte de la valeur de la variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.82"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(feat_train, y_train)\n",
        "lr.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8173333333333334"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(feat_train, y_train)\n",
        "mnb.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.756"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(feat_train, y_train)\n",
        "dt.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On garde la r\u00e9gression logistique pour la suite."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les n-grammes\n",
        "\n",
        "L'approche pr\u00e9sent\u00e9e ci-dessus ne tient pas compte de l'ordre des mots. Chaque phrase est convertie en un sac de mots (ou [bag of words](https://fr.wikipedia.org/wiki/Sac_de_mots)). Il est n\u00e9anmoins possible de tenir compte de s\u00e9quence plus ou moins longue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# s'il faut t\u00e9l\u00e9charger des donn\u00e9es\n",
        "if False:\n",
        "    import nltk\n",
        "    nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(None, None, 'The'),\n",
              " (None, 'The', 'building'),\n",
              " ('The', 'building', 'itself'),\n",
              " ('building', 'itself', 'seems'),\n",
              " ('itself', 'seems', 'pretty'),\n",
              " ('seems', 'pretty', 'neat'),\n",
              " ('pretty', 'neat', ';')]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "generated_ngrams = ngrams(word_tokenize(X_train.iloc[0,0]), 3, pad_left=True, pad_right=True)\n",
        "list(generated_ngrams)[:7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[scikit-learn](http://scikit-learn.org/stable/modules/feature_extraction.html#limitations-of-the-bag-of-words-representation) permet d'essayer cette id\u00e9e simplement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 20157)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe2 = make_pipeline(CountVectorizer(ngram_range=(1, 2)),\n",
        "                      TfidfTransformer())\n",
        "pipe2.fit(X_train['sentence'])\n",
        "feat_train2 = pipe2.transform(X_train['sentence'])\n",
        "feat_train2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il y a plus de colonnes, on v\u00e9rifie malgr\u00e9 tout que les features ressemblent \u00e0 des couples de mots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['00',\n",
              " '10',\n",
              " '10 10',\n",
              " '10 feet',\n",
              " '10 for',\n",
              " '10 minutes',\n",
              " '10 on',\n",
              " '10 out',\n",
              " '10 plus',\n",
              " '10 scale']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cl = pipe2.steps[0]\n",
        "cl[1].get_feature_names()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est le cas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "feat_test2 = pipe2.transform(X_test['sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf2 = LogisticRegression()\n",
        "clf2.fit(feat_train2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.82"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf2.score(feat_test2, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cela n'am\u00e9liore pas de fa\u00e7on significative. Il faudrait faire une cross-validation pour s'en assurer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## R\u00e9duire les dimensions avec une ACP\n",
        "\n",
        "C'est un moyen fr\u00e9quemment utilis\u00e9 pour r\u00e9duire les dimensions. On choisit le mod\u00e8le [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD) plut\u00f4t que l'[ACP](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA) dont l'impl\u00e9mentation ne supporte pas les features sparses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "pipe_svd = make_pipeline(CountVectorizer(), TruncatedSVD(n_components=300))\n",
        "pipe_svd.fit(X_train['sentence'])\n",
        "feat_train_svd = pipe_svd.transform(X_train['sentence'])\n",
        "feat_train_svd.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_svd = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd.fit(feat_train_svd, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6906666666666667"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test_svd = pipe_svd.transform(X_test['sentence'])\n",
        "clf_svd.score(feat_test_svd, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7693333333333333"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_svd = LogisticRegression()\n",
        "lr_svd.fit(feat_train_svd, y_train)\n",
        "lr_svd.score(feat_test_svd, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et si on repart de TF-IDF :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7786666666666666"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_svd_tfidf = make_pipeline(CountVectorizer(), \n",
        "                     TfidfTransformer(),\n",
        "                     TruncatedSVD(n_components=300))\n",
        "pipe_svd_tfidf.fit(X_train['sentence'])\n",
        "feat_train_svd_tfidf = pipe_svd_tfidf.transform(X_train['sentence'])\n",
        "\n",
        "clf_svd_tfidf = LogisticRegression()\n",
        "clf_svd_tfidf.fit(feat_train_svd_tfidf, y_train)\n",
        "\n",
        "feat_test_svd_tfidf = pipe_svd_tfidf.transform(X_test['sentence'])\n",
        "clf_svd_tfidf.score(feat_test_svd_tfidf, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est mieux mais cela reste moins bien que le *tf-idf* sans r\u00e9duction de dimensions. Cela veut dire qu'il faut garder plus de dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec\n",
        "\n",
        "[word2vec](https://en.wikipedia.org/wiki/Word2vec) est une sorte d'ACP non lin\u00e9aire en ce sens qu'il r\u00e9duit les dimensions. Il faut lire [Analyse en composantes principales (ACP) et Auto Encoders](http://www.xavierdupre.fr/app/mlstatpy/helpsphinx/c_ml/rn/rn_9_auto.html) pour comprendre le lien entre ACP, ACP non lin\u00e9aire, r\u00e9seaux de neurones diabolo et compression. *word2vec* est plus d'une ACP non lin\u00e9aire car il prend en compte le contexte mais ne s'en \u00e9loigne pas tant que ce \u00e7a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the',\n",
              " 'building',\n",
              " 'itself',\n",
              " 'seems',\n",
              " 'pretty',\n",
              " 'neat',\n",
              " 'the',\n",
              " 'bathroom',\n",
              " 'is',\n",
              " 'pretty',\n",
              " 'trippy',\n",
              " 'but',\n",
              " 'i',\n",
              " 'wouldn',\n",
              " 't',\n",
              " 'eat',\n",
              " 'here',\n",
              " 'again']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.utils import tokenize\n",
        "sentance = [list(tokenize(s, deacc=True, lower=True)) for s in X_train['sentence']]\n",
        "sentance[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les param\u00e8tres d'apprentissage du mod\u00e8le [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) ne sont pas toujours d\u00e9crit de fa\u00e7on explicite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2250"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.models import word2vec\n",
        "model = word2vec.Word2Vec(sentance, size=300, window=20,\n",
        "                          min_count=2, workers=1, iter=100)\n",
        "model.corpus_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the', 'building', 'itself', 'seems', 'pretty']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = model.wv.vocab\n",
        "list(vocab)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('trained_word2vec.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les dix premi\u00e8res coordonn\u00e9es du vecteur associ\u00e9 au mot ``after``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((300,),\n",
              " array([ 0.02298025, -0.56248665, -0.2573145 ,  0.662218  , -0.23411235,\n",
              "        -0.39516386,  0.0824462 ,  1.0074098 ,  1.403397  ,  0.5792489 ],\n",
              "       dtype=float32))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv['after'].shape, model.wv['after'][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lorsque le mot est inconnu :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"word 'rrrrrrrr' not in vocabulary\"\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    model.wv['rrrrrrrr']\n",
        "except KeyError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour chaque phrase, on fait la somme des vecteurs associ\u00e9s aux mots qui la composent ou pas si le mot n'est pas dans le vocabulaire. Il y a probablement des fonctions d\u00e9j\u00e0 pr\u00eates \u00e0 l'emploi mais la documentation de [gensim](https://radimrehurek.com/gensim/index.html) n'\u00e9tait pas assez explicite et lire l'article [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) puis celui-ci [Distributed Representations of Words and Phrases\n",
        "and their Compositionality](https://arxiv.org/pdf/1310.4546.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def get_vect(word, model):\n",
        "    try:\n",
        "        return model.wv[word]\n",
        "    except KeyError:\n",
        "        return numpy.zeros((model.vector_size,))\n",
        "\n",
        "def sum_vectors(phrase, model):\n",
        "    return sum(get_vect(w, model) for w in phrase)\n",
        "\n",
        "def word2vec_features(X, model):\n",
        "    feats = numpy.vstack([sum_vectors(p, model) for p in X])\n",
        "    return feats\n",
        "\n",
        "wv_train_feat = word2vec_features(X_train[\"sentence\"], model)\n",
        "wv_train_feat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "clfwv.fit(wv_train_feat, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv_test_feat = word2vec_features(X_test[\"sentence\"], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5986666666666667"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv.score(wv_test_feat, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La performance est nettement moindre et notamment moindre que la performance obtenue avec l'*ACP*. Il faudrait sans doute jouer avec les hyperparam\u00e8tres de l'apprentissage ou r\u00e9utiliser un model appris sur un corpus similaire aux donn\u00e9es initiales mais nettement plus grand. On peut constater que la fonction de similarit\u00e9s ne retourne pas des r\u00e9sultat tr\u00e8s int\u00e9ressants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a',\n",
              " 'ability',\n",
              " 'able',\n",
              " 'about',\n",
              " 'above',\n",
              " 'absolutely',\n",
              " 'accept',\n",
              " 'access',\n",
              " 'accidentally',\n",
              " 'accused']"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = list(sorted(model.wv.vocab))\n",
        "words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>about</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.207230</td>\n",
              "      <td>-0.122160</td>\n",
              "      <td>0.281463</td>\n",
              "      <td>0.120163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>above</th>\n",
              "      <td>0.207230</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.277403</td>\n",
              "      <td>0.137205</td>\n",
              "      <td>0.245130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>-0.122160</td>\n",
              "      <td>0.277403</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.046879</td>\n",
              "      <td>0.005526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0.281463</td>\n",
              "      <td>0.137205</td>\n",
              "      <td>-0.046879</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.414653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>0.120163</td>\n",
              "      <td>0.245130</td>\n",
              "      <td>0.005526</td>\n",
              "      <td>0.414653</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             about     above  absolutely     after    before\n",
              "w1                                                            \n",
              "about       1.000000  0.207230   -0.122160  0.281463  0.120163\n",
              "above       0.207230  1.000000    0.277403  0.137205  0.245130\n",
              "absolutely -0.122160  0.277403    1.000000 -0.046879  0.005526\n",
              "after       0.281463  0.137205   -0.046879  1.000000  0.414653\n",
              "before      0.120163  0.245130    0.005526  0.414653  1.000000"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subset = ['after', 'before', words[3], words[4], words[5]]\n",
        "rows = []\n",
        "for w in subset:\n",
        "    for ww in subset:\n",
        "        rows.append(dict(w1=w, w2=ww, d=model.wv.similarity(w, ww)))\n",
        "import pandas\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec pr\u00e9-entra\u00een\u00e9s\n",
        "\n",
        "Ce mod\u00e8le est plus performant avec plus de donn\u00e9es.\n",
        "On peut t\u00e9l\u00e9charger des mod\u00e8les pr\u00e9-entra\u00eener sur des donn\u00e9es plus volumineuses :\n",
        " [Pre-Trained Word2Vec Models](https://github.com/jhlau/doc2vec) ou encore [Pre-trained word vectors of 30+ languages](https://github.com/Kyubyong/wordvectors). Ceux-ci sont plut\u00f4t gros (> 600 Mo). Le module *spacy* propose une version plus l\u00e9g\u00e8re et mieux document\u00e9e [Word Vectors and Semantic Similarity](https://spacy.io/usage/vectors-similarity) avec les donn\u00e9es [en_core_web_md](https://github.com/explosion/spacy-models/releases)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.cli import download\n",
        "# download(\"en_core_web_md\")  # \u00e7a ne marche pas toujours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T\u00e9l\u00e9chargement de  en_core_web_md-2.1.0.tar.gz\n",
            "Found en_core_web_md-2.1.0/en_core_web_md/en_core_web_md-2.1.0\n",
            "Chargement des donn\u00e9es par spacy.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "version = \"2.1.0\"\n",
        "unzip_dest = 'en_core_web_md-{0}.tar/dist/en_core_web_md-{0}/en_core_web_md/en_core_web_md-{0}'.format(version)\n",
        "if not os.path.exists(unzip_dest):\n",
        "    from pyquickhelper.pycode import is_travis_or_appveyor\n",
        "    if not is_travis_or_appveyor():\n",
        "        # On le fait seulement si ce n'est pas un test d'int\u00e9gration continue.\n",
        "        url = \"https://github.com/explosion/spacy-models/releases/download/en_core_web_md-%s/\" % version\n",
        "        name = \"en_core_web_md-%s.tar.gz\" % version\n",
        "        print(\"T\u00e9l\u00e9chargement de \", name)\n",
        "        from pyensae.datasource import download_data\n",
        "        unzipped = download_data(name, url=url, fLOG=print)\n",
        "        unzip_dest = os.path.split(unzipped[0])[0]\n",
        "        unzip_dest = \"en_core_web_md-{0}/en_core_web_md/en_core_web_md-{0}\".format(version)\n",
        "        print(\"Found\", unzip_dest)\n",
        "        \n",
        "if os.path.exists(unzip_dest):\n",
        "    print(\"Chargement des donn\u00e9es par spacy.\")\n",
        "    nlp = spacy.load(unzip_dest)\n",
        "    continue_wv = True\n",
        "else:\n",
        "    continue_wv = False\n",
        "    print('Pas de donn\u00e9es on passe la suite.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "      <th>films</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>about</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.207230</td>\n",
              "      <td>-0.122160</td>\n",
              "      <td>0.281463</td>\n",
              "      <td>0.120163</td>\n",
              "      <td>0.166976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>above</th>\n",
              "      <td>0.207230</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.277403</td>\n",
              "      <td>0.137205</td>\n",
              "      <td>0.245130</td>\n",
              "      <td>-0.279092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>-0.122160</td>\n",
              "      <td>0.277403</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.046879</td>\n",
              "      <td>0.005526</td>\n",
              "      <td>-0.266474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0.281463</td>\n",
              "      <td>0.137205</td>\n",
              "      <td>-0.046879</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.414653</td>\n",
              "      <td>0.174238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>0.120163</td>\n",
              "      <td>0.245130</td>\n",
              "      <td>0.005526</td>\n",
              "      <td>0.414653</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.061146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>films</th>\n",
              "      <td>0.166976</td>\n",
              "      <td>-0.279092</td>\n",
              "      <td>-0.266474</td>\n",
              "      <td>0.174238</td>\n",
              "      <td>0.061146</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             about     above  absolutely     after    before     films\n",
              "w1                                                                      \n",
              "about       1.000000  0.207230   -0.122160  0.281463  0.120163  0.166976\n",
              "above       0.207230  1.000000    0.277403  0.137205  0.245130 -0.279092\n",
              "absolutely -0.122160  0.277403    1.000000 -0.046879  0.005526 -0.266474\n",
              "after       0.281463  0.137205   -0.046879  1.000000  0.414653  0.174238\n",
              "before      0.120163  0.245130    0.005526  0.414653  1.000000  0.061146\n",
              "films       0.166976 -0.279092   -0.266474  0.174238  0.061146  1.000000"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    tokens = nlp('after before films about above absolutely')\n",
        "    rows = []\n",
        "    for token1 in tokens:\n",
        "        for token2 in tokens:\n",
        "            sim = model.wv.similarity(token1.text, token2.text)\n",
        "            rows.append(dict(w1=token1.text, w2=token2.text, d=sim))\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(300,) [ 0.2069    0.44321  -0.12522  -0.017724 -0.064277 -0.44308   0.014019\n",
            " -0.10119   0.22699   3.1689  ]\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(tokens[0].vector.shape, tokens[0].vector[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2250, 300)\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def spacy_sum_vectors(phrase, nlp):\n",
        "    dec = nlp(phrase)\n",
        "    return sum(w.vector for w in dec)\n",
        "\n",
        "def spacy_word2vec_features(X, nlp):\n",
        "    feats = numpy.vstack([spacy_sum_vectors(p, nlp) for p in X])\n",
        "    return feats\n",
        "\n",
        "if continue_wv:\n",
        "    try:\n",
        "        wv_train_feat2 = spacy_word2vec_features(X_train[\"sentence\"], nlp)\n",
        "        print(wv_train_feat2.shape)\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "        continue_wv = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    clfwv2 = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "    clfwv2.fit(wv_train_feat2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    wv_test_feat2 = spacy_word2vec_features(X_test[\"sentence\"], nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8346666666666667\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(clfwv2.score(wv_test_feat2, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est un peu mieux mais un peu plus co\u00fbteux en temps de calcul mais m\u00eame sans entra\u00eenement, le mod\u00e8le obtenu est plus performant avec 300 dimensions que celui obtenu avec l'ACP. Le corpus ext\u00e9rieur au probl\u00e8me apporte de la valeur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}