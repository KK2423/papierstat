{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification de phrases avec word2vec\n",
        "\n",
        "Le texte est toujours d\u00e9licat \u00e0 traiter. La langue est importante et plus le vocabulaire est \u00e9tendu, plus il faut de donn\u00e9es. Le probl\u00e8me qui suit est classique, on cherche \u00e0 cat\u00e9goriser des phrases en sentiment positif ou n\u00e9gatif. Ce pourrait \u00eatre aussi classer des spams. Le probl\u00e8me le plus simple : une phrase, un label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les donn\u00e9es\n",
        "\n",
        "Elles proviennent de [Sentiment Labelled Sentences Data Set](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentance</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentance  sentiment  \\\n",
              "0  So there is no way for me to plug it in here i...          0   \n",
              "1                        Good case, Excellent value.          1   \n",
              "2                             Great for the jawbone.          1   \n",
              "3  Tied to charger for conversations lasting more...          0   \n",
              "4                                  The mic is great.          1   \n",
              "\n",
              "                  source  \n",
              "0  amazon_cells_labelled  \n",
              "1  amazon_cells_labelled  \n",
              "2  amazon_cells_labelled  \n",
              "3  amazon_cells_labelled  \n",
              "4  amazon_cells_labelled  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from papierstat.datasets import load_sentiment_dataset\n",
        "df = load_sentiment_dataset()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>sentance</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">amazon_cells_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">imdb_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">yelp_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 sentance\n",
              "source                sentiment          \n",
              "amazon_cells_labelled 0               500\n",
              "                      1               500\n",
              "imdb_labelled         0               500\n",
              "                      1               500\n",
              "yelp_labelled         0               500\n",
              "                      1               500"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(['source', 'sentiment']).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On d\u00e9coupe en train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[[\"sentance\"]], df['sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## L'approche classique\n",
        "\n",
        "[TF-IDF](https://fr.wikipedia.org/wiki/TF-IDF) est une approche tr\u00e8s r\u00e9pandue lorsqu'il s'agit de convertir des phrases en features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 4432)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "pipe = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
        "pipe.fit(X_train['sentance'])\n",
        "feat_train = pipe.transform(X_train['sentance'])\n",
        "feat_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_train.min(), feat_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(750, 4432)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test = pipe.transform(X_test['sentance'])\n",
        "feat_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
              "                       min_impurity_split=None, min_samples_leaf=1,\n",
              "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                       n_estimators=50, n_jobs=None, oob_score=False,\n",
              "                       random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=50)\n",
        "clf.fit(feat_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.784"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "score = clf.predict_proba(feat_test)\n",
        "fpr, tpr, th = roc_curve(y_test, score[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "aucf = auc(fpr, tpr)\n",
        "ax.plot(fpr, tpr, label='auc=%1.5f' % aucf)\n",
        "ax.set_title('Courbe ROC - classifieur de sentiments')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les n-grammes\n",
        "\n",
        "L'approche pr\u00e9sent\u00e9e ci-dessus ne tient pas compte de l'ordre des mots. Chaque phrase est convertie en un sac de mots (ou [bag of words](https://fr.wikipedia.org/wiki/Sac_de_mots)). Il est n\u00e9anmoins possible de tenir compte de s\u00e9quence plus ou moins longue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# s'il faut t\u00e9l\u00e9charger des donn\u00e9es\n",
        "if False:\n",
        "    import nltk\n",
        "    nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(None, None, 'Their'),\n",
              " (None, 'Their', 'steaks'),\n",
              " ('Their', 'steaks', 'are'),\n",
              " ('steaks', 'are', '100'),\n",
              " ('are', '100', '%'),\n",
              " ('100', '%', 'recommended'),\n",
              " ('%', 'recommended', '!')]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "generated_ngrams = ngrams(word_tokenize(X_train.iloc[0,0]), 3, pad_left=True, pad_right=True)\n",
        "list(generated_ngrams)[:7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[scikit-learn](http://scikit-learn.org/stable/modules/feature_extraction.html#limitations-of-the-bag-of-words-representation) permet d'essayer cette id\u00e9e simplement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 20391)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe2 = make_pipeline(CountVectorizer(ngram_range=(1, 2)),\n",
        "                      TfidfTransformer())\n",
        "pipe2.fit(X_train['sentance'])\n",
        "feat_train2 = pipe2.transform(X_train['sentance'])\n",
        "feat_train2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il y a plus de colonnes, on v\u00e9rifie malgr\u00e9 tout que les features ressemblent \u00e0 des couples de mots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['00',\n",
              " '10',\n",
              " '10 10',\n",
              " '10 and',\n",
              " '10 feet',\n",
              " '10 for',\n",
              " '10 grade',\n",
              " '10 minutes',\n",
              " '10 of',\n",
              " '10 on']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cl = pipe2.steps[0]\n",
        "cl[1].get_feature_names()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est le cas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "feat_test2 = pipe2.transform(X_test['sentance'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
              "                       min_impurity_split=None, min_samples_leaf=1,\n",
              "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                       n_estimators=50, n_jobs=None, oob_score=False,\n",
              "                       random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf2 = RandomForestClassifier(n_estimators=50)\n",
        "clf2.fit(feat_train2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7506666666666667"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf2.score(feat_test2, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cela n'am\u00e9liore pas de fa\u00e7on significative. Il faudrait faire une cross-validation pour s'en assurer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## R\u00e9duire les dimensions avec une ACP\n",
        "\n",
        "C'est un moyen fr\u00e9quemment utilis\u00e9 pour r\u00e9duire les dimensions. On choisit le mod\u00e8le [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD) plut\u00f4t que l'[ACP](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA) dont l'impl\u00e9mentation ne supporte pas les features sparses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "pipe_svd = make_pipeline(CountVectorizer(), TruncatedSVD(n_components=300))\n",
        "pipe_svd.fit(X_train['sentance'])\n",
        "feat_train_svd = pipe_svd.transform(X_train['sentance'])\n",
        "feat_train_svd.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
              "                       min_impurity_split=None, min_samples_leaf=1,\n",
              "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                       n_estimators=50, n_jobs=None, oob_score=False,\n",
              "                       random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_svd = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd.fit(feat_train_svd, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6973333333333334"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test_svd = pipe_svd.transform(X_test['sentance'])\n",
        "clf_svd.score(feat_test_svd, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et si on repart de TF-IDF :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.684"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_svd_tfidf = make_pipeline(CountVectorizer(), \n",
        "                     TfidfTransformer(),\n",
        "                     TruncatedSVD(n_components=300))\n",
        "pipe_svd_tfidf.fit(X_train['sentance'])\n",
        "feat_train_svd_tfidf = pipe_svd_tfidf.transform(X_train['sentance'])\n",
        "\n",
        "clf_svd_tfidf = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd_tfidf.fit(feat_train_svd_tfidf, y_train)\n",
        "\n",
        "feat_test_svd_tfidf = pipe_svd_tfidf.transform(X_test['sentance'])\n",
        "clf_svd_tfidf.score(feat_test_svd_tfidf, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est mieux mais cela reste moins bien que le *tf-idf* sans r\u00e9duction de dimensions. Cela veut dire qu'il faut garder plus de dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec\n",
        "\n",
        "[word2vec](https://en.wikipedia.org/wiki/Word2vec) est une sorte d'ACP non lin\u00e9aire en ce sens qu'il r\u00e9duit les dimensions. Il faut lire [Analyse en composantes principales (ACP) et Auto Encoders](http://www.xavierdupre.fr/app/mlstatpy/helpsphinx/c_ml/rn/rn_9_auto.html) pour comprendre le lien entre ACP, ACP non lin\u00e9aire, r\u00e9seaux de neurones diabolo et compression. *word2vec* est plus d'une ACP non lin\u00e9aire car il prend en compte le contexte mais ne s'en \u00e9loigne pas tant que ce \u00e7a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['their', 'steaks', 'are', 'recommended']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.utils import tokenize\n",
        "sentance = [list(tokenize(s, deacc=True, lower=True)) for s in X_train['sentance']]\n",
        "sentance[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les param\u00e8tres d'apprentissage du mod\u00e8le [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) ne sont pas toujours d\u00e9crit de fa\u00e7on explicite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2250"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.models import word2vec\n",
        "model = word2vec.Word2Vec(sentance, size=300, window=20,\n",
        "                          min_count=2, workers=1, iter=100)\n",
        "model.corpus_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['their', 'steaks', 'are', 'recommended', 'everything']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = model.wv.vocab\n",
        "list(vocab)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('trained_word2vec.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les dix premi\u00e8res coordonn\u00e9es du vecteur associ\u00e9 au mot ``after``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((300,),\n",
              " array([-0.7537293 ,  0.04438523, -0.34767985, -0.3105609 , -0.20994365,\n",
              "        -1.2574697 ,  0.75126386, -0.30711934, -1.4219059 , -0.04746056],\n",
              "       dtype=float32))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv['after'].shape, model.wv['after'][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lorsque le mot est inconnu :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"word 'rrrrrrrr' not in vocabulary\"\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    model.wv['rrrrrrrr']\n",
        "except KeyError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour chaque phrase, on fait la somme des vecteurs associ\u00e9s aux mots qui la composent ou pas si le mot n'est pas dans le vocabulaire. Il y a probablement des fonctions d\u00e9j\u00e0 pr\u00eates \u00e0 l'emploi mais la documentation de [gensim](https://radimrehurek.com/gensim/index.html) n'\u00e9tait pas assez explicite et lire l'article [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) puis celui-ci [Distributed Representations of Words and Phrases\n",
        "and their Compositionality](https://arxiv.org/pdf/1310.4546.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def get_vect(word, model):\n",
        "    try:\n",
        "        return model.wv[word]\n",
        "    except KeyError:\n",
        "        return numpy.zeros((model.vector_size,))\n",
        "\n",
        "def sum_vectors(phrase, model):\n",
        "    return sum(get_vect(w, model) for w in phrase)\n",
        "\n",
        "def word2vec_features(X, model):\n",
        "    feats = numpy.vstack([sum_vectors(p, model) for p in X])\n",
        "    return feats\n",
        "\n",
        "wv_train_feat = word2vec_features(X_train[\"sentance\"], model)\n",
        "wv_train_feat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
              "                       min_impurity_split=None, min_samples_leaf=1,\n",
              "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                       n_estimators=50, n_jobs=None, oob_score=False,\n",
              "                       random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv = RandomForestClassifier(n_estimators=50)\n",
        "clfwv.fit(wv_train_feat, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv_test_feat = word2vec_features(X_test[\"sentance\"], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.576"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv.score(wv_test_feat, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La performance est nettement moindre et notamment moindre que la performance obtenue avec l'*ACP*. Il faudrait sans doute jouer avec les hyperparam\u00e8tres de l'apprentissage ou r\u00e9utiliser un model appris sur un corpus similaire aux donn\u00e9es initiales mais nettement plus grand. On peut constater que la fonction de similarit\u00e9s ne retourne pas des r\u00e9sultat tr\u00e8s int\u00e9ressants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a',\n",
              " 'ability',\n",
              " 'able',\n",
              " 'about',\n",
              " 'above',\n",
              " 'absolutely',\n",
              " 'accidentally',\n",
              " 'acknowledged',\n",
              " 'acting',\n",
              " 'action']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = list(sorted(model.wv.vocab))\n",
        "words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>about</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200461</td>\n",
              "      <td>-0.023665</td>\n",
              "      <td>0.358278</td>\n",
              "      <td>-0.046249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>above</th>\n",
              "      <td>0.200461</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.458367</td>\n",
              "      <td>0.370139</td>\n",
              "      <td>0.179178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>-0.023665</td>\n",
              "      <td>0.458367</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.021543</td>\n",
              "      <td>0.309783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0.358278</td>\n",
              "      <td>0.370139</td>\n",
              "      <td>0.021543</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.476953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>-0.046249</td>\n",
              "      <td>0.179178</td>\n",
              "      <td>0.309783</td>\n",
              "      <td>0.476953</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             about     above  absolutely     after    before\n",
              "w1                                                            \n",
              "about       1.000000  0.200461   -0.023665  0.358278 -0.046249\n",
              "above       0.200461  1.000000    0.458367  0.370139  0.179178\n",
              "absolutely -0.023665  0.458367    1.000000  0.021543  0.309783\n",
              "after       0.358278  0.370139    0.021543  1.000000  0.476953\n",
              "before     -0.046249  0.179178    0.309783  0.476953  1.000000"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subset = ['after', 'before', words[3], words[4], words[5]]\n",
        "rows = []\n",
        "for w in subset:\n",
        "    for ww in subset:\n",
        "        rows.append(dict(w1=w, w2=ww, d=model.wv.similarity(w, ww)))\n",
        "import pandas\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec pr\u00e9-entra\u00een\u00e9s\n",
        "\n",
        "Ce mod\u00e8le est plus performant avec plus de donn\u00e9es.\n",
        "On peut t\u00e9l\u00e9charger des mod\u00e8les pr\u00e9-entra\u00eener sur des donn\u00e9es plus volumineuses :\n",
        " [Pre-Trained Word2Vec Models](https://github.com/jhlau/doc2vec) ou encore [Pre-trained word vectors of 30+ languages](https://github.com/Kyubyong/wordvectors). Ceux-ci sont plut\u00f4t gros (> 600 Mo). Le module *spacy* propose une version plus l\u00e9g\u00e8re et mieux document\u00e9e [Word Vectors and Semantic Similarity](https://spacy.io/usage/vectors-similarity) avec les donn\u00e9es [en_core_web_md](https://github.com/explosion/spacy-models/releases)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.cli import download\n",
        "# download(\"en_core_web_md\")  # \u00e7a ne marche pas toujours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T\u00e9l\u00e9chargement de  en_core_web_md-2.1.0.tar.gz\n",
            "[download_data]    download 'https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz' to 'en_core_web_md-2.1.0.tar.gz'\n",
            "Found en_core_web_md-2.1.0/en_core_web_md/en_core_web_md-2.1.0\n",
            "Chargement des donn\u00e9es par spacy.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "version = \"2.1.0\"\n",
        "unzip_dest = 'en_core_web_md-{0}.tar/dist/en_core_web_md-{0}/en_core_web_md/en_core_web_md-{0}'.format(version)\n",
        "if not os.path.exists(unzip_dest):\n",
        "    from pyquickhelper.pycode import is_travis_or_appveyor\n",
        "    if not is_travis_or_appveyor():\n",
        "        # On le fait seulement si ce n'est pas un test d'int\u00e9gration continue.\n",
        "        url = \"https://github.com/explosion/spacy-models/releases/download/en_core_web_md-%s/\" % version\n",
        "        name = \"en_core_web_md-%s.tar.gz\" % version\n",
        "        print(\"T\u00e9l\u00e9chargement de \", name)\n",
        "        from pyensae.datasource import download_data\n",
        "        unzipped = download_data(name, url=url, fLOG=print)\n",
        "        unzip_dest = os.path.split(unzipped[0])[0]\n",
        "        unzip_dest = \"en_core_web_md-{0}/en_core_web_md/en_core_web_md-{0}\".format(version)\n",
        "        print(\"Found\", unzip_dest)\n",
        "        \n",
        "if os.path.exists(unzip_dest):\n",
        "    print(\"Chargement des donn\u00e9es par spacy.\")\n",
        "    nlp = spacy.load(unzip_dest)\n",
        "    continue_wv = True\n",
        "else:\n",
        "    continue_wv = False\n",
        "    print('Pas de donn\u00e9es on passe la suite.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "      <th>films</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>about</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200461</td>\n",
              "      <td>-0.023665</td>\n",
              "      <td>0.358278</td>\n",
              "      <td>-0.046249</td>\n",
              "      <td>0.228728</td>\n",
              "      <td>0.054806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>above</th>\n",
              "      <td>0.200461</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.458367</td>\n",
              "      <td>0.370139</td>\n",
              "      <td>0.179178</td>\n",
              "      <td>-0.086631</td>\n",
              "      <td>0.290311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>-0.023665</td>\n",
              "      <td>0.458367</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.021543</td>\n",
              "      <td>0.309783</td>\n",
              "      <td>-0.228776</td>\n",
              "      <td>0.298303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0.358278</td>\n",
              "      <td>0.370139</td>\n",
              "      <td>0.021543</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.476953</td>\n",
              "      <td>0.233439</td>\n",
              "      <td>0.086766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>-0.046249</td>\n",
              "      <td>0.179178</td>\n",
              "      <td>0.309783</td>\n",
              "      <td>0.476953</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.016871</td>\n",
              "      <td>-0.092970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>films</th>\n",
              "      <td>0.228728</td>\n",
              "      <td>-0.086631</td>\n",
              "      <td>-0.228776</td>\n",
              "      <td>0.233439</td>\n",
              "      <td>0.016871</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.276604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>italian</th>\n",
              "      <td>0.054806</td>\n",
              "      <td>0.290311</td>\n",
              "      <td>0.298303</td>\n",
              "      <td>0.086766</td>\n",
              "      <td>-0.092970</td>\n",
              "      <td>0.276604</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             about     above  absolutely     after    before     films  \\\n",
              "w1                                                                         \n",
              "about       1.000000  0.200461   -0.023665  0.358278 -0.046249  0.228728   \n",
              "above       0.200461  1.000000    0.458367  0.370139  0.179178 -0.086631   \n",
              "absolutely -0.023665  0.458367    1.000000  0.021543  0.309783 -0.228776   \n",
              "after       0.358278  0.370139    0.021543  1.000000  0.476953  0.233439   \n",
              "before     -0.046249  0.179178    0.309783  0.476953  1.000000  0.016871   \n",
              "films       0.228728 -0.086631   -0.228776  0.233439  0.016871  1.000000   \n",
              "italian     0.054806  0.290311    0.298303  0.086766 -0.092970  0.276604   \n",
              "\n",
              "w2           italian  \n",
              "w1                    \n",
              "about       0.054806  \n",
              "above       0.290311  \n",
              "absolutely  0.298303  \n",
              "after       0.086766  \n",
              "before     -0.092970  \n",
              "films       0.276604  \n",
              "italian     1.000000  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    tokens = nlp('after before italian films about above absolutely')\n",
        "    rows = []\n",
        "    for token1 in tokens:\n",
        "        for token2 in tokens:\n",
        "            sim = model.wv.similarity(token1.text, token2.text)\n",
        "            rows.append(dict(w1=token1.text, w2=token2.text, d=sim))\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(300,) [ 0.2069    0.44321  -0.12522  -0.017724 -0.064277 -0.44308   0.014019\n",
            " -0.10119   0.22699   3.1689  ]\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(tokens[0].vector.shape, tokens[0].vector[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2250, 300)\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def spacy_sum_vectors(phrase, nlp):\n",
        "    dec = nlp(phrase)\n",
        "    return sum(w.vector for w in dec)\n",
        "\n",
        "def spacy_word2vec_features(X, nlp):\n",
        "    feats = numpy.vstack([spacy_sum_vectors(p, nlp) for p in X])\n",
        "    return feats\n",
        "\n",
        "if continue_wv:\n",
        "    wv_train_feat2 = spacy_word2vec_features(X_train[\"sentance\"], nlp)\n",
        "    print(wv_train_feat2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    clfwv2 = RandomForestClassifier(n_estimators=50)\n",
        "    clfwv2.fit(wv_train_feat2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    wv_test_feat2 = spacy_word2vec_features(X_test[\"sentance\"], nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7813333333333333\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(clfwv2.score(wv_test_feat2, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est un peu mieux mais un peu plus co\u00fbteux en temps de calcul mais m\u00eame sans entra\u00eenement, le mod\u00e8le obtenu est plus performant avec 300 dimensions que celui obtenu avec l'ACP. Le corpus ext\u00e9rieur au probl\u00e8me apporte de la valeur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}