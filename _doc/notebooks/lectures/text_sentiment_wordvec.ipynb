{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification de phrases avec word2vec\n",
        "\n",
        "Le texte est toujours d\u00e9licat \u00e0 traiter. La langue est importante et plus le vocabulaire est \u00e9tendu, plus il faut de donn\u00e9es. Le probl\u00e8me qui suit est classique, on cherche \u00e0 cat\u00e9goriser des phrases en sentiment positif ou n\u00e9gatif. Ce pourrait \u00eatre aussi classer des spams. Le probl\u00e8me le plus simple : une phrase, un label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les donn\u00e9es\n",
        "\n",
        "Elles proviennent de [Sentiment Labelled Sentences Data Set](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentance</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentance  sentiment  \\\n",
              "0  So there is no way for me to plug it in here i...          0   \n",
              "1                        Good case, Excellent value.          1   \n",
              "2                             Great for the jawbone.          1   \n",
              "3  Tied to charger for conversations lasting more...          0   \n",
              "4                                  The mic is great.          1   \n",
              "\n",
              "                  source  \n",
              "0  amazon_cells_labelled  \n",
              "1  amazon_cells_labelled  \n",
              "2  amazon_cells_labelled  \n",
              "3  amazon_cells_labelled  \n",
              "4  amazon_cells_labelled  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from papierstat.datasets import load_sentiment_dataset\n",
        "df = load_sentiment_dataset()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>sentance</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td rowspan=\"2\" valign=\"top\">amazon_cells_labelled</td>\n",
              "      <td>0</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td rowspan=\"2\" valign=\"top\">imdb_labelled</td>\n",
              "      <td>0</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td rowspan=\"2\" valign=\"top\">yelp_labelled</td>\n",
              "      <td>0</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 sentance\n",
              "source                sentiment          \n",
              "amazon_cells_labelled 0               500\n",
              "                      1               500\n",
              "imdb_labelled         0               500\n",
              "                      1               500\n",
              "yelp_labelled         0               500\n",
              "                      1               500"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(['source', 'sentiment']).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On d\u00e9coupe en train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[[\"sentance\"]], df['sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## L'approche classique\n",
        "\n",
        "[TF-IDF](https://fr.wikipedia.org/wiki/TF-IDF) est une approche tr\u00e8s r\u00e9pandue lorsqu'il s'agit de convertir des phrases en features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 4400)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "pipe = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
        "pipe.fit(X_train['sentance'])\n",
        "feat_train = pipe.transform(X_train['sentance'])\n",
        "feat_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_train.min(), feat_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(750, 4400)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test = pipe.transform(X_test['sentance'])\n",
        "feat_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=50)\n",
        "clf.fit(feat_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.788"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "score = clf.predict_proba(feat_test)\n",
        "fpr, tpr, th = roc_curve(y_test, score[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "aucf = auc(fpr, tpr)\n",
        "ax.plot(fpr, tpr, label='auc=%1.5f' % aucf)\n",
        "ax.set_title('Courbe ROC - classifieur de sentiments')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les n-grammes\n",
        "\n",
        "L'approche pr\u00e9sent\u00e9e ci-dessus ne tient pas compte de l'ordre des mots. Chaque phrase est convertie en un sac de mots (ou [bag of words](https://fr.wikipedia.org/wiki/Sac_de_mots)). Il est n\u00e9anmoins possible de tenir compte de s\u00e9quence plus ou moins longue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# s'il faut t\u00e9l\u00e9charger des donn\u00e9es\n",
        "if False:\n",
        "    import nltk\n",
        "    nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(None, None, 'I'),\n",
              " (None, 'I', '*heart*'),\n",
              " ('I', '*heart*', 'this'),\n",
              " ('*heart*', 'this', 'place'),\n",
              " ('this', 'place', '.'),\n",
              " ('place', '.', None),\n",
              " ('.', None, None)]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "generated_ngrams = ngrams(word_tokenize(X_train.iloc[0,0]), 3, pad_left=True, pad_right=True)\n",
        "list(generated_ngrams)[:7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[scikit-learn](http://scikit-learn.org/stable/modules/feature_extraction.html#limitations-of-the-bag-of-words-representation) permet d'essayer cette id\u00e9e simplement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 20342)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe2 = make_pipeline(CountVectorizer(ngram_range=(1, 2)),\n",
        "                      TfidfTransformer())\n",
        "pipe2.fit(X_train['sentance'])\n",
        "feat_train2 = pipe2.transform(X_train['sentance'])\n",
        "feat_train2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il y a plus de colonnes, on v\u00e9rifie malgr\u00e9 tout que les features ressemblent \u00e0 des couples de mots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['00',\n",
              " '10',\n",
              " '10 10',\n",
              " '10 and',\n",
              " '10 for',\n",
              " '10 grade',\n",
              " '10 minutes',\n",
              " '10 of',\n",
              " '10 on',\n",
              " '10 out']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cl = pipe2.steps[0]\n",
        "cl[1].get_feature_names()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est le cas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "feat_test2 = pipe2.transform(X_test['sentance'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf2 = RandomForestClassifier(n_estimators=50)\n",
        "clf2.fit(feat_train2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7893333333333333"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf2.score(feat_test2, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cela n'am\u00e9liore pas de fa\u00e7on significative. Il faudrait faire une cross-validation pour s'en assurer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## R\u00e9duire les dimensions avec une ACP\n",
        "\n",
        "C'est un moyen fr\u00e9quemment utilis\u00e9 pour r\u00e9duire les dimensions. On choisit le mod\u00e8le [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD) plut\u00f4t que l'[ACP](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA) dont l'impl\u00e9mentation ne supporte pas les features sparses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "pipe_svd = make_pipeline(CountVectorizer(), TruncatedSVD(n_components=300))\n",
        "pipe_svd.fit(X_train['sentance'])\n",
        "feat_train_svd = pipe_svd.transform(X_train['sentance'])\n",
        "feat_train_svd.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_svd = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd.fit(feat_train_svd, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6893333333333334"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test_svd = pipe_svd.transform(X_test['sentance'])\n",
        "clf_svd.score(feat_test_svd, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et si on repart de TF-IDF :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7213333333333334"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_svd_tfidf = make_pipeline(CountVectorizer(), \n",
        "                     TfidfTransformer(),\n",
        "                     TruncatedSVD(n_components=300))\n",
        "pipe_svd_tfidf.fit(X_train['sentance'])\n",
        "feat_train_svd_tfidf = pipe_svd_tfidf.transform(X_train['sentance'])\n",
        "\n",
        "clf_svd_tfidf = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd_tfidf.fit(feat_train_svd_tfidf, y_train)\n",
        "\n",
        "feat_test_svd_tfidf = pipe_svd_tfidf.transform(X_test['sentance'])\n",
        "clf_svd_tfidf.score(feat_test_svd_tfidf, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est mieux mais cela reste moins bien que le *tf-idf* sans r\u00e9duction de dimensions. Cela veut dire qu'il faut garder plus de dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec\n",
        "\n",
        "[word2vec](https://en.wikipedia.org/wiki/Word2vec) est une sorte d'ACP non lin\u00e9aire en ce sens qu'il r\u00e9duit les dimensions. Il faut lire [Analyse en composantes principales (ACP) et Auto Encoders](http://www.xavierdupre.fr/app/mlstatpy/helpsphinx/c_ml/rn/rn_9_auto.html) pour comprendre le lien entre ACP, ACP non lin\u00e9aire, r\u00e9seaux de neurones diabolo et compression. *word2vec* est plus d'une ACP non lin\u00e9aire car il prend en compte le contexte mais ne s'en \u00e9loigne pas tant que ce \u00e7a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i', 'heart', 'this', 'place']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.utils import tokenize\n",
        "sentance = [list(tokenize(s, deacc=True, lower=True)) for s in X_train['sentance']]\n",
        "sentance[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les param\u00e8tres d'apprentissage du mod\u00e8le [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) ne sont pas toujours d\u00e9crit de fa\u00e7on explicite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2250"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.models import word2vec\n",
        "model = word2vec.Word2Vec(sentance, size=300, window=20,\n",
        "                          min_count=2, workers=1, iter=100)\n",
        "model.corpus_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i', 'heart', 'this', 'place', 'so']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = model.wv.vocab\n",
        "list(vocab)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('trained_word2vec.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les dix premi\u00e8res coordonn\u00e9es du vecteur associ\u00e9 au mot ``after``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((300,),\n",
              " array([-1.3176018 , -1.3460263 , -0.6796115 ,  0.5054756 , -1.3413163 ,\n",
              "        -1.59745   ,  0.7052183 , -0.3164459 ,  0.18885957, -1.6917483 ],\n",
              "       dtype=float32))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv['after'].shape, model.wv['after'][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lorsque le mot est inconnu :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"word 'rrrrrrrr' not in vocabulary\"\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    model.wv['rrrrrrrr']\n",
        "except KeyError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour chaque phrase, on fait la somme des vecteurs associ\u00e9s aux mots qui la composent ou pas si le mot n'est pas dans le vocabulaire. Il y a probablement des fonctions d\u00e9j\u00e0 pr\u00eates \u00e0 l'emploi mais la documentation de [gensim](https://radimrehurek.com/gensim/index.html) n'\u00e9tait pas assez explicite et lire l'article [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) puis celui-ci [Distributed Representations of Words and Phrases\n",
        "and their Compositionality](https://arxiv.org/pdf/1310.4546.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def get_vect(word, model):\n",
        "    try:\n",
        "        return model.wv[word]\n",
        "    except KeyError:\n",
        "        return numpy.zeros((model.vector_size,))\n",
        "\n",
        "def sum_vectors(phrase, model):\n",
        "    return sum(get_vect(w, model) for w in phrase)\n",
        "\n",
        "def word2vec_features(X, model):\n",
        "    feats = numpy.vstack([sum_vectors(p, model) for p in X])\n",
        "    return feats\n",
        "\n",
        "wv_train_feat = word2vec_features(X_train[\"sentance\"], model)\n",
        "wv_train_feat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv = RandomForestClassifier(n_estimators=50)\n",
        "clfwv.fit(wv_train_feat, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv_test_feat = word2vec_features(X_test[\"sentance\"], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.56"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv.score(wv_test_feat, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La performance est nettement moindre et notamment moindre que la performance obtenue avec l'*ACP*. Il faudrait sans doute jouer avec les hyperparam\u00e8tres de l'apprentissage ou r\u00e9utiliser un model appris sur un corpus similaire aux donn\u00e9es initiales mais nettement plus grand. On peut constater que la fonction de similarit\u00e9s ne retourne pas des r\u00e9sultat tr\u00e8s int\u00e9ressants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a',\n",
              " 'ability',\n",
              " 'able',\n",
              " 'about',\n",
              " 'above',\n",
              " 'absolutely',\n",
              " 'abysmal',\n",
              " 'access',\n",
              " 'accidentally',\n",
              " 'accused']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = list(sorted(model.wv.vocab))\n",
        "words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>about</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.212220</td>\n",
              "      <td>-0.027013</td>\n",
              "      <td>0.236452</td>\n",
              "      <td>0.256707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>above</td>\n",
              "      <td>0.212220</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.232470</td>\n",
              "      <td>0.179590</td>\n",
              "      <td>0.088611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>absolutely</td>\n",
              "      <td>-0.027013</td>\n",
              "      <td>0.232470</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.014706</td>\n",
              "      <td>0.113076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>after</td>\n",
              "      <td>0.236452</td>\n",
              "      <td>0.179590</td>\n",
              "      <td>-0.014706</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.286992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>before</td>\n",
              "      <td>0.256707</td>\n",
              "      <td>0.088611</td>\n",
              "      <td>0.113076</td>\n",
              "      <td>0.286992</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             about     above  absolutely     after    before\n",
              "w1                                                            \n",
              "about       1.000000  0.212220   -0.027013  0.236452  0.256707\n",
              "above       0.212220  1.000000    0.232470  0.179590  0.088611\n",
              "absolutely -0.027013  0.232470    1.000000 -0.014706  0.113076\n",
              "after       0.236452  0.179590   -0.014706  1.000000  0.286992\n",
              "before      0.256707  0.088611    0.113076  0.286992  1.000000"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subset = ['after', 'before', words[3], words[4], words[5]]\n",
        "rows = []\n",
        "for w in subset:\n",
        "    for ww in subset:\n",
        "        rows.append(dict(w1=w, w2=ww, d=model.wv.similarity(w, ww)))\n",
        "import pandas\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec pr\u00e9-entra\u00een\u00e9s\n",
        "\n",
        "Ce mod\u00e8le est plus performant avec plus de donn\u00e9es.\n",
        "On peut t\u00e9l\u00e9charger des mod\u00e8les pr\u00e9-entra\u00eener sur des donn\u00e9es plus volumineuses :\n",
        " [Pre-Trained Word2Vec Models](https://github.com/jhlau/doc2vec) ou encore [Pre-trained word vectors of 30+ languages](https://github.com/Kyubyong/wordvectors). Ceux-ci sont plut\u00f4t gros (> 600 Mo). Le module *spacy* propose une version plus l\u00e9g\u00e8re et mieux document\u00e9e [Word Vectors and Semantic Similarity](https://spacy.io/usage/vectors-similarity) avec les donn\u00e9es [en_core_web_md](https://github.com/explosion/spacy-models/releases)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.cli import download\n",
        "# download(\"en_core_web_md\")  # \u00e7a ne marche pas toujours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T\u00e9l\u00e9chargement de  en_core_web_md-2.1.0.tar.gz\n",
            "Found en_core_web_md-2.1.0/en_core_web_md/en_core_web_md-2.1.0\n",
            "Chargement des donn\u00e9es par spacy.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "version = \"2.1.0\"\n",
        "unzip_dest = 'en_core_web_md-{0}.tar/dist/en_core_web_md-{0}/en_core_web_md/en_core_web_md-{0}'.format(version)\n",
        "if not os.path.exists(unzip_dest):\n",
        "    from pyquickhelper.pycode import is_travis_or_appveyor\n",
        "    if not is_travis_or_appveyor():\n",
        "        # On le fait seulement si ce n'est pas un test d'int\u00e9gration continue.\n",
        "        url = \"https://github.com/explosion/spacy-models/releases/download/en_core_web_md-%s/\" % version\n",
        "        name = \"en_core_web_md-%s.tar.gz\" % version\n",
        "        print(\"T\u00e9l\u00e9chargement de \", name)\n",
        "        from pyensae.datasource import download_data\n",
        "        unzipped = download_data(name, url=url, fLOG=print)\n",
        "        unzip_dest = os.path.split(unzipped[0])[0]\n",
        "        unzip_dest = \"en_core_web_md-{0}/en_core_web_md/en_core_web_md-{0}\".format(version)\n",
        "        print(\"Found\", unzip_dest)\n",
        "        \n",
        "if os.path.exists(unzip_dest):\n",
        "    print(\"Chargement des donn\u00e9es par spacy.\")\n",
        "    nlp = spacy.load(unzip_dest)\n",
        "    continue_wv = True\n",
        "else:\n",
        "    continue_wv = False\n",
        "    print('Pas de donn\u00e9es on passe la suite.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "      <th>films</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>about</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.212220</td>\n",
              "      <td>-0.027013</td>\n",
              "      <td>0.236452</td>\n",
              "      <td>0.256707</td>\n",
              "      <td>0.299878</td>\n",
              "      <td>-0.148594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>above</td>\n",
              "      <td>0.212220</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.232470</td>\n",
              "      <td>0.179590</td>\n",
              "      <td>0.088611</td>\n",
              "      <td>0.216481</td>\n",
              "      <td>0.280013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>absolutely</td>\n",
              "      <td>-0.027013</td>\n",
              "      <td>0.232470</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.014706</td>\n",
              "      <td>0.113076</td>\n",
              "      <td>-0.064618</td>\n",
              "      <td>-0.037417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>after</td>\n",
              "      <td>0.236452</td>\n",
              "      <td>0.179590</td>\n",
              "      <td>-0.014706</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.286992</td>\n",
              "      <td>0.248450</td>\n",
              "      <td>0.093066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>before</td>\n",
              "      <td>0.256707</td>\n",
              "      <td>0.088611</td>\n",
              "      <td>0.113076</td>\n",
              "      <td>0.286992</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.065779</td>\n",
              "      <td>-0.022599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>films</td>\n",
              "      <td>0.299878</td>\n",
              "      <td>0.216481</td>\n",
              "      <td>-0.064618</td>\n",
              "      <td>0.248450</td>\n",
              "      <td>0.065779</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.208975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>italian</td>\n",
              "      <td>-0.148594</td>\n",
              "      <td>0.280013</td>\n",
              "      <td>-0.037417</td>\n",
              "      <td>0.093066</td>\n",
              "      <td>-0.022599</td>\n",
              "      <td>0.208975</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             about     above  absolutely     after    before     films  \\\n",
              "w1                                                                         \n",
              "about       1.000000  0.212220   -0.027013  0.236452  0.256707  0.299878   \n",
              "above       0.212220  1.000000    0.232470  0.179590  0.088611  0.216481   \n",
              "absolutely -0.027013  0.232470    1.000000 -0.014706  0.113076 -0.064618   \n",
              "after       0.236452  0.179590   -0.014706  1.000000  0.286992  0.248450   \n",
              "before      0.256707  0.088611    0.113076  0.286992  1.000000  0.065779   \n",
              "films       0.299878  0.216481   -0.064618  0.248450  0.065779  1.000000   \n",
              "italian    -0.148594  0.280013   -0.037417  0.093066 -0.022599  0.208975   \n",
              "\n",
              "w2           italian  \n",
              "w1                    \n",
              "about      -0.148594  \n",
              "above       0.280013  \n",
              "absolutely -0.037417  \n",
              "after       0.093066  \n",
              "before     -0.022599  \n",
              "films       0.208975  \n",
              "italian     1.000000  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    tokens = nlp('after before italian films about above absolutely')\n",
        "    rows = []\n",
        "    for token1 in tokens:\n",
        "        for token2 in tokens:\n",
        "            sim = model.wv.similarity(token1.text, token2.text)\n",
        "            rows.append(dict(w1=token1.text, w2=token2.text, d=sim))\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(300,) [ 0.2069    0.44321  -0.12522  -0.017724 -0.064277 -0.44308   0.014019\n",
            " -0.10119   0.22699   3.1689  ]\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(tokens[0].vector.shape, tokens[0].vector[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2250, 300)\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def spacy_sum_vectors(phrase, nlp):\n",
        "    dec = nlp(phrase)\n",
        "    return sum(w.vector for w in dec)\n",
        "\n",
        "def spacy_word2vec_features(X, nlp):\n",
        "    feats = numpy.vstack([spacy_sum_vectors(p, nlp) for p in X])\n",
        "    return feats\n",
        "\n",
        "if continue_wv:\n",
        "    try:\n",
        "        wv_train_feat2 = spacy_word2vec_features(X_train[\"sentance\"], nlp)\n",
        "        print(wv_train_feat2.shape)\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "        continue_wv = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    clfwv2 = RandomForestClassifier(n_estimators=50)\n",
        "    clfwv2.fit(wv_train_feat2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    wv_test_feat2 = spacy_word2vec_features(X_test[\"sentance\"], nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7786666666666666\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(clfwv2.score(wv_test_feat2, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est un peu mieux mais un peu plus co\u00fbteux en temps de calcul mais m\u00eame sans entra\u00eenement, le mod\u00e8le obtenu est plus performant avec 300 dimensions que celui obtenu avec l'ACP. Le corpus ext\u00e9rieur au probl\u00e8me apporte de la valeur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}