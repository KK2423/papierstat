{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification de phrases avec word2vec\n",
        "\n",
        "Le texte est toujours d\u00e9licat \u00e0 traiter. La langue est importante et plus le vocabulaire est \u00e9tendu, plus il faut de donn\u00e9es. Le probl\u00e8me qui suit est classique, on cherche \u00e0 cat\u00e9goriser des phrases en sentiment positif ou n\u00e9gatif. Ce pourrait \u00eatre aussi classer des spams. Le probl\u00e8me le plus simple : une phrase, un label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les donn\u00e9es\n",
        "\n",
        "Elles proviennent de [Sentiment Labelled Sentences Data Set](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  sentiment  \\\n",
              "0  So there is no way for me to plug it in here i...          0   \n",
              "1                        Good case, Excellent value.          1   \n",
              "2                             Great for the jawbone.          1   \n",
              "3  Tied to charger for conversations lasting more...          0   \n",
              "4                                  The mic is great.          1   \n",
              "\n",
              "                  source  \n",
              "0  amazon_cells_labelled  \n",
              "1  amazon_cells_labelled  \n",
              "2  amazon_cells_labelled  \n",
              "3  amazon_cells_labelled  \n",
              "4  amazon_cells_labelled  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from papierstat.datasets import load_sentiment_dataset\n",
        "df = load_sentiment_dataset()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">amazon_cells_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">imdb_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">yelp_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 sentence\n",
              "source                sentiment          \n",
              "amazon_cells_labelled 0               500\n",
              "                      1               500\n",
              "imdb_labelled         0               500\n",
              "                      1               500\n",
              "yelp_labelled         0               500\n",
              "                      1               500"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(['source', 'sentiment']).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On d\u00e9coupe en train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[[\"sentence\"]], df['sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## L'approche classique\n",
        "\n",
        "[TF-IDF](https://fr.wikipedia.org/wiki/TF-IDF) est une approche tr\u00e8s r\u00e9pandue lorsqu'il s'agit de convertir des phrases en features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 4404)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "pipe = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
        "pipe.fit(X_train['sentence'])\n",
        "feat_train = pipe.transform(X_train['sentence'])\n",
        "feat_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_train.min(), feat_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(750, 4404)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test = pipe.transform(X_test['sentence'])\n",
        "feat_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=50)\n",
        "clf.fit(feat_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7853333333333333"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "score = clf.predict_proba(feat_test)\n",
        "fpr, tpr, th = roc_curve(y_test, score[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "aucf = auc(fpr, tpr)\n",
        "ax.plot(fpr, tpr, label='auc=%1.5f' % aucf)\n",
        "ax.set_title('Courbe ROC - classifieur de sentiments')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les n-grammes\n",
        "\n",
        "L'approche pr\u00e9sent\u00e9e ci-dessus ne tient pas compte de l'ordre des mots. Chaque phrase est convertie en un sac de mots (ou [bag of words](https://fr.wikipedia.org/wiki/Sac_de_mots)). Il est n\u00e9anmoins possible de tenir compte de s\u00e9quence plus ou moins longue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# s'il faut t\u00e9l\u00e9charger des donn\u00e9es\n",
        "if False:\n",
        "    import nltk\n",
        "    nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(None, None, 'The'),\n",
              " (None, 'The', 'attempts'),\n",
              " ('The', 'attempts', 'at'),\n",
              " ('attempts', 'at', 'humor'),\n",
              " ('at', 'humor', 'were'),\n",
              " ('humor', 'were', 'pitiful'),\n",
              " ('were', 'pitiful', 'and')]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "generated_ngrams = ngrams(word_tokenize(X_train.iloc[0,0]), 3, pad_left=True, pad_right=True)\n",
        "list(generated_ngrams)[:7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[scikit-learn](http://scikit-learn.org/stable/modules/feature_extraction.html#limitations-of-the-bag-of-words-representation) permet d'essayer cette id\u00e9e simplement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 20335)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe2 = make_pipeline(CountVectorizer(ngram_range=(1, 2)),\n",
        "                      TfidfTransformer())\n",
        "pipe2.fit(X_train['sentence'])\n",
        "feat_train2 = pipe2.transform(X_train['sentence'])\n",
        "feat_train2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il y a plus de colonnes, on v\u00e9rifie malgr\u00e9 tout que les features ressemblent \u00e0 des couples de mots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['00',\n",
              " '10',\n",
              " '10 10',\n",
              " '10 and',\n",
              " '10 feet',\n",
              " '10 for',\n",
              " '10 grade',\n",
              " '10 minutes',\n",
              " '10 of',\n",
              " '10 on']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cl = pipe2.steps[0]\n",
        "cl[1].get_feature_names()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est le cas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "feat_test2 = pipe2.transform(X_test['sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf2 = RandomForestClassifier(n_estimators=50)\n",
        "clf2.fit(feat_train2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7866666666666666"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf2.score(feat_test2, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cela n'am\u00e9liore pas de fa\u00e7on significative. Il faudrait faire une cross-validation pour s'en assurer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## R\u00e9duire les dimensions avec une ACP\n",
        "\n",
        "C'est un moyen fr\u00e9quemment utilis\u00e9 pour r\u00e9duire les dimensions. On choisit le mod\u00e8le [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD) plut\u00f4t que l'[ACP](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA) dont l'impl\u00e9mentation ne supporte pas les features sparses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "pipe_svd = make_pipeline(CountVectorizer(), TruncatedSVD(n_components=300))\n",
        "pipe_svd.fit(X_train['sentence'])\n",
        "feat_train_svd = pipe_svd.transform(X_train['sentence'])\n",
        "feat_train_svd.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_svd = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd.fit(feat_train_svd, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.724"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test_svd = pipe_svd.transform(X_test['sentence'])\n",
        "clf_svd.score(feat_test_svd, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et si on repart de TF-IDF :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.744"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_svd_tfidf = make_pipeline(CountVectorizer(), \n",
        "                     TfidfTransformer(),\n",
        "                     TruncatedSVD(n_components=300))\n",
        "pipe_svd_tfidf.fit(X_train['sentence'])\n",
        "feat_train_svd_tfidf = pipe_svd_tfidf.transform(X_train['sentence'])\n",
        "\n",
        "clf_svd_tfidf = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd_tfidf.fit(feat_train_svd_tfidf, y_train)\n",
        "\n",
        "feat_test_svd_tfidf = pipe_svd_tfidf.transform(X_test['sentence'])\n",
        "clf_svd_tfidf.score(feat_test_svd_tfidf, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est mieux mais cela reste moins bien que le *tf-idf* sans r\u00e9duction de dimensions. Cela veut dire qu'il faut garder plus de dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec\n",
        "\n",
        "[word2vec](https://en.wikipedia.org/wiki/Word2vec) est une sorte d'ACP non lin\u00e9aire en ce sens qu'il r\u00e9duit les dimensions. Il faut lire [Analyse en composantes principales (ACP) et Auto Encoders](http://www.xavierdupre.fr/app/mlstatpy/helpsphinx/c_ml/rn/rn_9_auto.html) pour comprendre le lien entre ACP, ACP non lin\u00e9aire, r\u00e9seaux de neurones diabolo et compression. *word2vec* est plus d'une ACP non lin\u00e9aire car il prend en compte le contexte mais ne s'en \u00e9loigne pas tant que ce \u00e7a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the',\n",
              " 'attempts',\n",
              " 'at',\n",
              " 'humor',\n",
              " 'were',\n",
              " 'pitiful',\n",
              " 'and',\n",
              " 'story',\n",
              " 'is',\n",
              " 'so',\n",
              " 'awful',\n",
              " 'it',\n",
              " 'dosen',\n",
              " 't',\n",
              " 'bear',\n",
              " 'thinking',\n",
              " 'about',\n",
              " 'which',\n",
              " 'basically',\n",
              " 'involves',\n",
              " 'a',\n",
              " 'vulcan',\n",
              " 'stealing',\n",
              " 'the',\n",
              " 'enterprise',\n",
              " 'to',\n",
              " 'find',\n",
              " 'god',\n",
              " 'seriously',\n",
              " 'i',\n",
              " 'just',\n",
              " 'didn',\n",
              " 't',\n",
              " 'care',\n",
              " 'about',\n",
              " 'any',\n",
              " 'of',\n",
              " 'this',\n",
              " 'film',\n",
              " 'and',\n",
              " 'oh',\n",
              " 'not',\n",
              " 'to',\n",
              " 'mention',\n",
              " 'uhura',\n",
              " 'does',\n",
              " 'a',\n",
              " 'belly',\n",
              " 'dance',\n",
              " 'to',\n",
              " 'distract',\n",
              " 'male',\n",
              " 'guards']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.utils import tokenize\n",
        "sentance = [list(tokenize(s, deacc=True, lower=True)) for s in X_train['sentence']]\n",
        "sentance[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les param\u00e8tres d'apprentissage du mod\u00e8le [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) ne sont pas toujours d\u00e9crit de fa\u00e7on explicite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2250"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.models import word2vec\n",
        "model = word2vec.Word2Vec(sentance, size=300, window=20,\n",
        "                          min_count=2, workers=1, iter=100)\n",
        "model.corpus_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the', 'attempts', 'at', 'were', 'pitiful']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = model.wv.vocab\n",
        "list(vocab)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('trained_word2vec.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les dix premi\u00e8res coordonn\u00e9es du vecteur associ\u00e9 au mot ``after``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((300,),\n",
              " array([ 0.01673949, -0.6810915 , -0.89865315, -0.8017018 ,  0.38698858,\n",
              "         0.21765004,  0.15453675,  0.7240845 , -1.0322706 ,  0.738904  ],\n",
              "       dtype=float32))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv['after'].shape, model.wv['after'][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lorsque le mot est inconnu :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"word 'rrrrrrrr' not in vocabulary\"\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    model.wv['rrrrrrrr']\n",
        "except KeyError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour chaque phrase, on fait la somme des vecteurs associ\u00e9s aux mots qui la composent ou pas si le mot n'est pas dans le vocabulaire. Il y a probablement des fonctions d\u00e9j\u00e0 pr\u00eates \u00e0 l'emploi mais la documentation de [gensim](https://radimrehurek.com/gensim/index.html) n'\u00e9tait pas assez explicite et lire l'article [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) puis celui-ci [Distributed Representations of Words and Phrases\n",
        "and their Compositionality](https://arxiv.org/pdf/1310.4546.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def get_vect(word, model):\n",
        "    try:\n",
        "        return model.wv[word]\n",
        "    except KeyError:\n",
        "        return numpy.zeros((model.vector_size,))\n",
        "\n",
        "def sum_vectors(phrase, model):\n",
        "    return sum(get_vect(w, model) for w in phrase)\n",
        "\n",
        "def word2vec_features(X, model):\n",
        "    feats = numpy.vstack([sum_vectors(p, model) for p in X])\n",
        "    return feats\n",
        "\n",
        "wv_train_feat = word2vec_features(X_train[\"sentence\"], model)\n",
        "wv_train_feat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv = RandomForestClassifier(n_estimators=50)\n",
        "clfwv.fit(wv_train_feat, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv_test_feat = word2vec_features(X_test[\"sentence\"], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5653333333333334"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv.score(wv_test_feat, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La performance est nettement moindre et notamment moindre que la performance obtenue avec l'*ACP*. Il faudrait sans doute jouer avec les hyperparam\u00e8tres de l'apprentissage ou r\u00e9utiliser un model appris sur un corpus similaire aux donn\u00e9es initiales mais nettement plus grand. On peut constater que la fonction de similarit\u00e9s ne retourne pas des r\u00e9sultat tr\u00e8s int\u00e9ressants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a',\n",
              " 'ability',\n",
              " 'about',\n",
              " 'above',\n",
              " 'absolutely',\n",
              " 'abysmal',\n",
              " 'accidentally',\n",
              " 'achievement',\n",
              " 'acknowledged',\n",
              " 'acted']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = list(sorted(model.wv.vocab))\n",
        "words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>abysmal</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>above</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.632553</td>\n",
              "      <td>0.585247</td>\n",
              "      <td>-0.083527</td>\n",
              "      <td>-0.187181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>0.632553</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.504434</td>\n",
              "      <td>-0.116366</td>\n",
              "      <td>-0.027921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abysmal</th>\n",
              "      <td>0.585247</td>\n",
              "      <td>0.504434</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.009874</td>\n",
              "      <td>-0.103956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>-0.083527</td>\n",
              "      <td>-0.116366</td>\n",
              "      <td>-0.009874</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.415322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>-0.187181</td>\n",
              "      <td>-0.027921</td>\n",
              "      <td>-0.103956</td>\n",
              "      <td>0.415322</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             above  absolutely   abysmal     after    before\n",
              "w1                                                            \n",
              "above       1.000000    0.632553  0.585247 -0.083527 -0.187181\n",
              "absolutely  0.632553    1.000000  0.504434 -0.116366 -0.027921\n",
              "abysmal     0.585247    0.504434  1.000000 -0.009874 -0.103956\n",
              "after      -0.083527   -0.116366 -0.009874  1.000000  0.415322\n",
              "before     -0.187181   -0.027921 -0.103956  0.415322  1.000000"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subset = ['after', 'before', words[3], words[4], words[5]]\n",
        "rows = []\n",
        "for w in subset:\n",
        "    for ww in subset:\n",
        "        rows.append(dict(w1=w, w2=ww, d=model.wv.similarity(w, ww)))\n",
        "import pandas\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec pr\u00e9-entra\u00een\u00e9s\n",
        "\n",
        "Ce mod\u00e8le est plus performant avec plus de donn\u00e9es.\n",
        "On peut t\u00e9l\u00e9charger des mod\u00e8les pr\u00e9-entra\u00eener sur des donn\u00e9es plus volumineuses :\n",
        " [Pre-Trained Word2Vec Models](https://github.com/jhlau/doc2vec) ou encore [Pre-trained word vectors of 30+ languages](https://github.com/Kyubyong/wordvectors). Ceux-ci sont plut\u00f4t gros (> 600 Mo). Le module *spacy* propose une version plus l\u00e9g\u00e8re et mieux document\u00e9e [Word Vectors and Semantic Similarity](https://spacy.io/usage/vectors-similarity) avec les donn\u00e9es [en_core_web_md](https://github.com/explosion/spacy-models/releases)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.cli import download\n",
        "# download(\"en_core_web_md\")  # \u00e7a ne marche pas toujours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T\u00e9l\u00e9chargement de  en_core_web_md-2.1.0.tar.gz\n",
            "[download_data]    download 'https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz' to 'en_core_web_md-2.1.0.tar.gz'\n",
            "Found en_core_web_md-2.1.0/en_core_web_md/en_core_web_md-2.1.0\n",
            "Chargement des donn\u00e9es par spacy.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "version = \"2.1.0\"\n",
        "unzip_dest = 'en_core_web_md-{0}.tar/dist/en_core_web_md-{0}/en_core_web_md/en_core_web_md-{0}'.format(version)\n",
        "if not os.path.exists(unzip_dest):\n",
        "    from pyquickhelper.pycode import is_travis_or_appveyor\n",
        "    if not is_travis_or_appveyor():\n",
        "        # On le fait seulement si ce n'est pas un test d'int\u00e9gration continue.\n",
        "        url = \"https://github.com/explosion/spacy-models/releases/download/en_core_web_md-%s/\" % version\n",
        "        name = \"en_core_web_md-%s.tar.gz\" % version\n",
        "        print(\"T\u00e9l\u00e9chargement de \", name)\n",
        "        from pyensae.datasource import download_data\n",
        "        unzipped = download_data(name, url=url, fLOG=print)\n",
        "        unzip_dest = os.path.split(unzipped[0])[0]\n",
        "        unzip_dest = \"en_core_web_md-{0}/en_core_web_md/en_core_web_md-{0}\".format(version)\n",
        "        print(\"Found\", unzip_dest)\n",
        "        \n",
        "if os.path.exists(unzip_dest):\n",
        "    print(\"Chargement des donn\u00e9es par spacy.\")\n",
        "    nlp = spacy.load(unzip_dest)\n",
        "    continue_wv = True\n",
        "else:\n",
        "    continue_wv = False\n",
        "    print('Pas de donn\u00e9es on passe la suite.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "      <th>films</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>about</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.073239</td>\n",
              "      <td>-0.008743</td>\n",
              "      <td>0.458690</td>\n",
              "      <td>0.147015</td>\n",
              "      <td>0.096424</td>\n",
              "      <td>0.155704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>above</th>\n",
              "      <td>-0.073239</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.632553</td>\n",
              "      <td>-0.083527</td>\n",
              "      <td>-0.187181</td>\n",
              "      <td>0.038300</td>\n",
              "      <td>0.239541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>-0.008743</td>\n",
              "      <td>0.632553</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.116366</td>\n",
              "      <td>-0.027921</td>\n",
              "      <td>-0.084661</td>\n",
              "      <td>0.105131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0.458690</td>\n",
              "      <td>-0.083527</td>\n",
              "      <td>-0.116366</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.415322</td>\n",
              "      <td>0.174211</td>\n",
              "      <td>0.105096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>0.147015</td>\n",
              "      <td>-0.187181</td>\n",
              "      <td>-0.027921</td>\n",
              "      <td>0.415322</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.096259</td>\n",
              "      <td>-0.116771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>films</th>\n",
              "      <td>0.096424</td>\n",
              "      <td>0.038300</td>\n",
              "      <td>-0.084661</td>\n",
              "      <td>0.174211</td>\n",
              "      <td>0.096259</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.047262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>italian</th>\n",
              "      <td>0.155704</td>\n",
              "      <td>0.239541</td>\n",
              "      <td>0.105131</td>\n",
              "      <td>0.105096</td>\n",
              "      <td>-0.116771</td>\n",
              "      <td>0.047262</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             about     above  absolutely     after    before     films  \\\n",
              "w1                                                                         \n",
              "about       1.000000 -0.073239   -0.008743  0.458690  0.147015  0.096424   \n",
              "above      -0.073239  1.000000    0.632553 -0.083527 -0.187181  0.038300   \n",
              "absolutely -0.008743  0.632553    1.000000 -0.116366 -0.027921 -0.084661   \n",
              "after       0.458690 -0.083527   -0.116366  1.000000  0.415322  0.174211   \n",
              "before      0.147015 -0.187181   -0.027921  0.415322  1.000000  0.096259   \n",
              "films       0.096424  0.038300   -0.084661  0.174211  0.096259  1.000000   \n",
              "italian     0.155704  0.239541    0.105131  0.105096 -0.116771  0.047262   \n",
              "\n",
              "w2           italian  \n",
              "w1                    \n",
              "about       0.155704  \n",
              "above       0.239541  \n",
              "absolutely  0.105131  \n",
              "after       0.105096  \n",
              "before     -0.116771  \n",
              "films       0.047262  \n",
              "italian     1.000000  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    tokens = nlp('after before italian films about above absolutely')\n",
        "    rows = []\n",
        "    for token1 in tokens:\n",
        "        for token2 in tokens:\n",
        "            sim = model.wv.similarity(token1.text, token2.text)\n",
        "            rows.append(dict(w1=token1.text, w2=token2.text, d=sim))\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(300,) [ 0.2069    0.44321  -0.12522  -0.017724 -0.064277 -0.44308   0.014019\n",
            " -0.10119   0.22699   3.1689  ]\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(tokens[0].vector.shape, tokens[0].vector[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2250, 300)\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def spacy_sum_vectors(phrase, nlp):\n",
        "    dec = nlp(phrase)\n",
        "    return sum(w.vector for w in dec)\n",
        "\n",
        "def spacy_word2vec_features(X, nlp):\n",
        "    feats = numpy.vstack([spacy_sum_vectors(p, nlp) for p in X])\n",
        "    return feats\n",
        "\n",
        "if continue_wv:\n",
        "    try:\n",
        "        wv_train_feat2 = spacy_word2vec_features(X_train[\"sentence\"], nlp)\n",
        "        print(wv_train_feat2.shape)\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "        continue_wv = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    clfwv2 = RandomForestClassifier(n_estimators=50)\n",
        "    clfwv2.fit(wv_train_feat2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    wv_test_feat2 = spacy_word2vec_features(X_test[\"sentence\"], nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7866666666666666\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(clfwv2.score(wv_test_feat2, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est un peu mieux mais un peu plus co\u00fbteux en temps de calcul mais m\u00eame sans entra\u00eenement, le mod\u00e8le obtenu est plus performant avec 300 dimensions que celui obtenu avec l'ACP. Le corpus ext\u00e9rieur au probl\u00e8me apporte de la valeur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}