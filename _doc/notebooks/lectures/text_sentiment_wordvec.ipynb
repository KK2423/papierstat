{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification de phrases avec word2vec\n",
        "\n",
        "Le texte est toujours d\u00e9licat \u00e0 traiter. La langue est importante et plus le vocabulaire est \u00e9tendu, plus il faut de donn\u00e9es. Le probl\u00e8me qui suit est classique, on cherche \u00e0 cat\u00e9goriser des phrases en sentiment positif ou n\u00e9gatif. Ce pourrait \u00eatre aussi classer des spams. Le probl\u00e8me le plus simple : une phrase, un label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les donn\u00e9es\n",
        "\n",
        "Elles proviennent de [Sentiment Labelled Sentences Data Set](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentance</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentance  sentiment  \\\n",
              "0  So there is no way for me to plug it in here i...          0   \n",
              "1                        Good case, Excellent value.          1   \n",
              "2                             Great for the jawbone.          1   \n",
              "3  Tied to charger for conversations lasting more...          0   \n",
              "4                                  The mic is great.          1   \n",
              "\n",
              "                  source  \n",
              "0  amazon_cells_labelled  \n",
              "1  amazon_cells_labelled  \n",
              "2  amazon_cells_labelled  \n",
              "3  amazon_cells_labelled  \n",
              "4  amazon_cells_labelled  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from papierstat.datasets import load_sentiment_dataset\n",
        "df = load_sentiment_dataset()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>sentance</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">amazon_cells_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">imdb_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">yelp_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 sentance\n",
              "source                sentiment          \n",
              "amazon_cells_labelled 0               500\n",
              "                      1               500\n",
              "imdb_labelled         0               500\n",
              "                      1               500\n",
              "yelp_labelled         0               500\n",
              "                      1               500"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(['source', 'sentiment']).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On d\u00e9coupe en train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[[\"sentance\"]], df['sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## L'approche classique\n",
        "\n",
        "[TF-IDF](https://fr.wikipedia.org/wiki/TF-IDF) est une approche tr\u00e8s r\u00e9pandue lorsqu'il s'agit de convertir des phrases en features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 4411)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "pipe = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
        "pipe.fit(X_train['sentance'])\n",
        "feat_train = pipe.transform(X_train['sentance'])\n",
        "feat_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_train.min(), feat_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(750, 4411)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test = pipe.transform(X_test['sentance'])\n",
        "feat_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=50)\n",
        "clf.fit(feat_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7666666666666667"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "score = clf.predict_proba(feat_test)\n",
        "fpr, tpr, th = roc_curve(y_test, score[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAEICAYAAABIwdH8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXd4FVX6xz9vCgmBJCQEAkkgdCkiVRBFAgSkSJOygKuAYEEXRbAsqKsu6+6CP1xFRIqKICggKlIEA0hHEEGUjoQmSYBUUgip9/z+mAuGEJIbSDL33pzP8+TJnZkzM985c+Y755yZeY8opdBoNJqicDFbgEajcQy0WWg0GpvQZqHRaGxCm4VGo7EJbRYajcYmtFloNBqbcDqzEJEFIvKW2TrMQETqiIgSEbdS2v4rIvJxnumHROSciKSJSCsROSwinUtj3zZoGyUiO8zYt62IyBwR+YfZOm6VMjELEXlYRPZaC9V5EVknIh3LYt+3g4hsEZEMq+54EflGRGrmS9NURFaJSLKIpIrIZhG5N1+aCiLypoicEJHLInJGROaLSJ2yPJ7bRSn1H6XU43lmTQfGKaUqK6X2K6WaKaW2mCTPrijIvJRSY5VS/zJBy5sisvh2t1PqZiEiE4H3gP8AgUBt4EOgfynsy7Wkt4n1YgAaAJUxLpCr+6sP7AQOAnWBIGAFsF5EOuTZxldAP+BhwBdoAewDwktBb1kSChwu7Z2UVk1JU0yUUqX2h3FhpAFDCknjgWEmMda/9wAP67JRwI586RXQwPp7ATAbWAtcBrpZ580BNgCpwFYgNM/6ja3LEoHjwF8K0bYFeDzP9DPA4TzTi4C1Baw3G9hm/d0NuALUKsF8rQi8A5wFkoEd1nl1rPnjZk33GHDUmg+ngKfybCMAWANcsubFdsDFuuzvQLR1veNAuHX+m8Bi6zlLs+7rMnDSuvwM0M362wWYBJwEEoAvAX/rss5AVL5jyrvumxgGuxhIyXsO8qSvCqyyLt8D/CtvWSnmeR5lzZ9U4DTw1zzLRlvzMAmIyFeWFDAWOGFdPgsQoAmQAeRa8+lSnvL6Vt48AF4GYoHzwACgN/C7VfcrefZVWH5ePe8jgT+AeOBV67KeQBaQbdXyW1HHfNN8KmWz6AnkYC28N0kzBdgNVAeqAT8C/yqGWSQD91kz09M6LxXohFGoZ1zdBlAJOIdxEbkBra0Z26wos7AWzo3AyjzLLwCPFbBeF2tB8QKmAltLOF9nWbUFA67AvdZjvVporprFg0B9awEOA9KB1tZl/8UwVXfr3/3WdHdY8ygoT0Gsn9csCjoXBVzwz1vPa4hV21xgSTHMIhvj4nEBKhaQB0sxLphKwJ0Y5lbs82xNmwLcYZ2ueTWddf+RGBe/G/Aa8GO+418DVMGoMccBPQspuwu43ixygNet+f+Edf0vAG+gGYbh1LMhP6+e948wbhotgEygyU3O202P2Uyz+CtwoYg0J4HeeaZ7AGeKYRafFXBCluaZroxx4dYChgLb86WfC7xRiFmkYxiSAn4FaudZnnO1cORbr7E1fbD1BC4taPu3mKcuGDWVFgUsu1poCjRn4FtgvPX3FGAleS526/wGGHe6boB7vmX5C11hZnEUa40kT4HMxrjoOlO0WWwrJA9crdtqnGfef/jTLGw+z9YL5xIwiHymBKwDxuTL+3SstQvr8XfMs/xLYFIhZXcB15vFFcDVOu1t3V77POn3AQNsyM+r5z0kz/I9wLCbnLebHnNhf6XdZ5EABBTR5gzCqE5f5ax1nq2cK2yeUioNo0oXhNHGbi8il67+YRhajUK2/5xSyhe4C/DDcParxGOctPzUBCwYVdOEm6QpEBH5q7VDNU1E1hWQJACjBnXShm31EpHdIpJoPdbe1vUB/g/jrrleRE6JyCQApVQkxl3sTSBWRJaKSHHOx1VCgRV58vkohmkH2rh+Qef1KtUwLpK8afKWIZvPs1LqMoa5jAXOi8h3ItI4z3Zm5NlGIkbtKzjPJi7k+Z2OcXOylQSlVK719xXr/4t5ll/Jsz1b8tMmLUUc800pbbPYhVGVGlBImhiMjLhKbes8MNrDXlcXiEhBF7UqYF6tPOtUBvyt2zyH0SSokuevslLq6aIORCl1EHgLmCUiYp29ERhSQPK/ALuUUunWNO1EJKSAdAXt53OrpspKqV4FJInHyNP6hW1HRDyArzE6ZAOVUlUw+nbEup9UpdQLSql6QF9gooiEW5d9oZTqiHFeFDDNFu35OAf0ypfXnkqpaG48r64YBpCXgs7rVeIwanW18syrnW/fNp9npVSEUqo7hqkfw6gNXt3OU/m2U1Ep9WPRh1+o/luhsPwstpZCjvmmlKpZKKWSMdpks0RkgIh4iYi79Y73tjXZEuA1EakmIgHW9Fcf8/wGNBORliLiiXG3s4XeItJRRCpgdHz9pJQ6h9G+bCQij1p1uIvI3SLSxMbtLsToW+lnnf4ncK+I/FtE/EXEW0SeBUZgdBKilNqI0dG2QkTaiIibNd1YERlt436voZSyAPOB/4lIkIi4ikgHqznkpQJG2zYOyBGRXsADVxeKSB8RaWA1vhSMu1SuiNwhIl2t28vAuLvlUnzmAP8WkVDr/qqJyNUnYL8DniLyoIi4Y/QF5Nd/U6x342+AN61lqilG595VbD7PIhIoIv1EpBJGOz8tz/HOASaLSDNrWl8RKejmUBAXgRBrGSwJCstPW7TUEREX67qFHfNNKfVHp0qp/wETMQpEHIZDjsNoP4Nxt94LHMB4BPmLdR5Kqd8x2tYbMXqcbX3p5gvgDYxqYxuMKihKqVSMC2YYRk3jAsZd06aCqpTKAt4H/mGdPgF0xOhQOoPRoz0I6KGU2pln1cEYd/VlGP0fh4C21uO6FV7EyKufrcc4jXzn0nqsz2G0o5MwHtuuypOkoXX/aRg1wA+V8Y6EB0anbDxG/lQHXrkFjTOs+1svIqkYnXPtrdqSMZ4sfYzRMXkZ48lAcRiHUc2+gNEX8OnVBcU8zy7AC9Z0iRgdwc9Yt7PCut5SEUnBOG8F1fYKYhPGY+ULIhJfvEMrkJvmpw0st/5PEJFfKOSYC0OsHR4ajUZTKE73urdGoykdtFloNBqb0Gah0WhsQpuFRqOxCdM+0AkICFB16tQxa/caTbll37598Uqp/O+1FIlpZlGnTh327t1r1u41mnKLiJwtOtWN6GaIRqOxCW0WGo3GJrRZaDQam7CrCETZ2dlERUWRkZFhthRNPjw9PQkJCcHd3d1sKRqTsCuziIqKwtvbmzp16vDnh50as1FKkZCQQFRUFHXr1jVbjsYkimyGWAPLxorIoZssFxF5X0QiReSAiLS+VTEZGRlUrVpVG4WdISJUrVpV1/jKObb0WSzACI93M3phfMHYEHgSI/7kLaONwj7R50VTZDNEKbVNCg9Z3x8jtJ0CdotIFRGpqZQ6X0IaNRqHxQhJ9+d0rlIkpGVxPvkKF5IzOJ+cwaX0rNveT9rly9SsWoUnOtW77W3djJLoswjm+vBmUdZ5N5iFiDyJUfugdu3a+ReXKxITExk6dChnzpyhTp06fPnll/j5+d2Q7uWXX+a7777DYrHQvXt3ZsyYgYjQuXNnzp8/T8WKFQFYv3491atX5+zZs4wePZq4uDj8/f1ZvHgxISEh/Prrrzz99NOkpKTg6urKq6++ytChQ6/b17PPPsunn35KWlpameSBI5CWmcPW43Ecu5By3XylICM7l8tZOaRl5nI5M4e0zBwuW/+uzruSbVvcoNuquCmwKAv+HtF2bxYFHWaBQTKUUvOAeQBt27Yt14E0pk6dSnh4OJMmTWLq1KlMnTqVadOuj173448/snPnTg4cOABAx44d2bp1K507dwbg888/p23bttet8+KLLzJixAhGjhzJpk2bmDx5MosWLcLLy4vPPvuMhg0bEhMTQ5s2bejRowdVqlQBYO/evVy6dKn0D9wBiEvN5IejF4k4fIGdkQlk5VoQubGge7q7UsnDjcoeblTycKVSBTcCfTyt84xpLw83XPM4gQgEVPaghq8HNXwqUsPXEz8v91tu5kVERDBgwAAaNGjA9xtvNZaSbZSEWURxfSzEEP6MoemQDBgwgHPnzpGRkcH48eN58sknqVy58rU77ldffcWaNWtYsGABFy9eZOzYsZw6dQqA2bNnc++99xa2eQBWrlzJli1bABg5ciSdO3e+wSxEhIyMDLKyslBKkZ2dTWBg4fFujxw5wrvvvgtAly5dGDDACH/aqFGja2mCgoKoXr06cXFxVKlShdzcXF566SW++OILVqxYYVsmOQE5uRYupGQQnXSFqKQrnEtKZ8eJePb9kYRSEOJXkUc7hPJA00DahPrh5mpfryWtWbOGQYMG0bRpUzZs2EBAQEDRK90GJWEWq4BxIrIUI8xXckn0V/xz9WGOxKQUnbAYNA3y4Y2+zYpMN3/+fPz9/bly5Qp33303gwYNumna5557jrCwMFasWEFubu41Q7n//vtJTU29If306dPp1q0bFy9epGZNI+h3zZo1iY2NvSFthw4d6NKlCzVr1kQpxbhx42jS5M8wko899hiurq4MGjSI1157DRGhRYsWfP3114wfP54VK1aQmppKQkICVatWvbbenj17yMrKon59I+bvBx98QL9+/a7pcSbSs3I4m5DO2YR0/ki8zB+JV3+nE510hRzL9RXcpjV9eD68EQ80C6RxDW+77tj99NNPueuuu4iIiMDf37/U91ekWYjIEowxDgJEJAojtqU7gFJqDkZsyd4YYeXTMQZ2cWjef//9a3fYc+fOceLEiZum3bRpE5999hkArq6u+Pr6ArB9+/bb1hEZGcnRo0eJijLCU3bv3p1t27bRqVMnPv/8c4KDg0lNTWXQoEEsWrSIESNGMH36dMaNG8eCBQvo1KkTwcHBuLn9eZrPnz/Po48+ysKFC3FxcSEmJobly5dfq+U4KrkWxeGYZHZGJnDiYipnraYQn5Z5XTrfiu6EVvWiebAvDzavSS1/L0L8KhLi50VNX0883UtjBMySJScnBzc3Nz7//HMyMzOvlbnSxpanIcOLWK6Av5WYIiu21ABKgy1btrBx40Z27dqFl5cXnTt3JiMj47o7jC3vGxRVswgMDOT8+fPUrFmT8+fPU7169RvSrlixgnvuuYfKlY3hH3r16sXu3buvmQCAt7c3Dz/8MHv27GHEiBEEBQXxzTffAJCWlsbXX399rTClpKTw4IMP8tZbb3HPPfcAsH//fiIjI2nQoAEA6enpNGjQgMjIyOJkmymcS0xnR2Q8O07Es/NkPJfSswEI8vWkdlUvwhtXp3ZVL0KrehHqX4na/l74ejn2G6iLFy/mvffeY/369fj7++Pp6Vlm+7arNzjtgeTkZPz8/PDy8uLYsWPs3r0bgMDAQI4ePcodd9zBihUr8Pb2BiA8PJzZs2fz/PPPk5uby+XLl/Hx8SmyZtGvXz8WLlzIpEmTWLhwIf373xjVvXbt2nz00UdMnjwZpRRbt27l+eefJycnh0uXLhEQEEB2djZr1qyhW7duAMTHx+Pv74+Liwv//e9/GT3aGG0gKyuLhx56iBEjRjBkyJ/R7B988EEuXPhzbJrKlSvbrVEkX8lm18kEdkTGseNEPGcS0gEI9PEgvHEg9zcM4L4GAVTztnlUAYdi/vz5PP7443Tp0gUPDxOO0dahy0r6r02bNio/R44cuWFeWZORkaF69uypmjdvrgYPHqzCwsLU5s2b1fLly1W9evVUWFiY+tvf/qZGjhyplFLqwoULql+/furOO+9ULVq0UD/++KNN+4mPj1ddu3ZVDRo0UF27dlUJCQlKKaV+/vlnNWbMGKWUUjk5OerJJ59UjRs3Vk2aNFETJkxQSimVlpamWrdurZo3b66aNm2qnnvuOZWTk6OUUmr58uWqQYMGqmHDhmrMmDEqIyNDKaXUokWLlJubm2rRosW1v/3799+gq1KlSjfVXJbnJzYlQ20+dlF9sOmEembxPhX29iYV+vc1KvTva1STf6xTj326R32y/ZT6/UKKslgsZabLLGbPnq0A1aNHD5Wenn5b2wL2qlu4Zk0bCqBt27Yqf/Cbo0ePXteBp7EvSuP8KKWISrrC4ZhkDkWncDgmmcMxKcSm/tnXEOJXkWZBPjQL8qV9XX9a1fajgpt9PZkoTRYuXMioUaPo06cPy5cvv+2mh4jsU0q1LTrl9ehmiKbMSbqcxY7IeLafiGP7iXjOJxt9QK4uQoNqlenYIICmVnNoGuSDb0XH7me4XcLDw3n22WeZPn06FSqU1ABnxUebhabUycqxsP+PJLafiGfbiTgORiejFPh4utGxYQDP1A/grmBf7qjh7RBPI8qKlStX0qdPH0JCQnj//ffNlmN/ZqGUsutn2+WV4jRXlVKcjr/M9hNG7WHXyQQuZ+Xi6iK0qlWFCd0acX/DAO4KqYKriz7X+VFK8eabbzJlyhQ+/vhjxowZY7YkwM7MwtPT89oLRNow7AdljWdRVFv5dPxlPtlxii3H44hKugJAbX8vHmodzP0Nq9GhflV8PMt3k6IolFJMnjyZadOmMXr0aEaNGmW2pGvYlVmEhIQQFRVFXFyc2VI0+bgaKasgopLSmflDJF/9EoW7q9CpYTWeCqtPp4YBhFatVMZKHRelFC+88ALvvvsuY8eOZdasWbi42E9Hrl2Zhbu7u47E5EDEpmTwweZIluz5A0F49J5QnulSn+reZfeikDMRGRnJ3Llzee6553jvvffsrnZtV2ahcQyycizM+OF3Pt5+mlyLYkjbWjzbtQFBVSqaLc0hudpP17BhQ/bv30/Dhg3tzihAm4WmmJxLTGfckv38du4SA1oGMaF7I93UuA1yc3MZM2YMHTp04Kmnnrru62B7Q5uFxmY2HLnIC1/+ilLw4V9b07u5832lWpbk5OQwYsQIlixZcu3bHHtGm4WmSDJzcnln/e/M23aKO4N9mPVwa12buE2ys7MZPnw4X3/9NVOnTuXvf/+72ZKKRJuF5gaycy0ciEpm96kEdp1MYO/ZRDKyLTx6TyivPthEvzh1m1gsFoYMGcLKlSv53//+x4QJE8yWZBPaLDTk5Fo4FJPCrpMJ7DqVwN4ziaRnGbEjG9fwZtjdteneNJD7GpRuJKbygouLC/fddx/du3fnb38r8egOpYY2i3JIVo6FQzHJ7DmdyJ7Tifx8OpHUzBwAGlSvzKDWIXSoX5X2df2pWtk5P/c2g/T0dE6cOEGLFi146aWXzJZTbLRZlAPSs3LY/8ela+aw/1wSGdkWAOoFVKJvyyA61KtK+3r++h2JUiItLY0+ffpw4MABTp06dS1QsiOhzcIJScvMYdfJBH4+Y5jDoehkciwKF4EmNX0Ydndt2tf1p20df6cNFGNPpKSk0Lt3b3bv3s2iRYsc0ihAm4VTkWtRLP35D95Z/zuJl7Oo4OpCi1q+PNmpHu3q+tM61E9/m1HGJCUl0bNnT3755ReWLVtWaPBne0ebhZPw48l4pqw+wrELqbSr48/44Q1pE+qnn1yYzPTp09m/fz9ff/01/fr1M1vObWFXkbI0xeePhHT+vfYIEYcvEuJXkVd6N6HXnTXs8nXh8kh2dja//PIL7du3N1vKNW41Upb9fNKmKRZpmTlMXXeMbv/byvYT8bzU4w42Tgyjd/Oa2ihM5sKFCwwePJjY2Fjc3d3tyihuB90McTAsFsVX+6J4O+I48WmZDGodwss97yDQRz/FsAeio6Pp2rUr0dHRREZGFjjEg6OizcKB2HM6kSlrDnMoOoXWtavw8ci2tKzlmD3rzsjZs2fp2rUrcXFxRERE2DSMpSOhzcIBiEpK57/rjvHdgfPU9PVkxrCW9GsRpJsbdsSpU6fo0qULycnJbNiwwWmaHnnRZmHHpGflMHvLSeZtO4UIPN+tIU91qk/FCvoJh73h5eVFSEgIK1asoHXr1mbLKRW0WdghFovi21+jmfb9MS6mZNKvRRCTejXWwWXskDNnzhASEkKNGjXYsWOHU9f2tFnYGfv/SOKfq4/w67lL3BXiy4d/bU2b0NIfIVtTfA4ePEh4eDhDhw5l5syZTm0UoM3Crth45CJjF+/Dv1IFpg9pwcBWwbjoUPl2yf79++nevTuenp48++yzZsspE7RZ2Ak7I+N55otfaBbkw6LH2+vXsu2YPXv20KNHD3x8fNi0aRP169c3W1KZoM3CDth3NoknPttL3aqVWPBYO20UdkxmZiYDBw7Ez8+PzZs3ExoaarakMsOmNzhFpKeIHBeRSBGZVMDy2iKyWUT2i8gBEeld8lKdk0PRyYz6dA+BPp4serwdfpXMG8tSUzQeHh4sX76cbdu2lSujABvMQkRcgVlAL6ApMFxEmuZL9hrwpVKqFTAM+LCkhTojkbGpjJi/Bx9PdxY/3l7HkrBjfvjhBz744AMAOnTocNMBl5wZW2oW7YBIpdQppVQWsBTony+NAnysv32BmJKT6HxYLIrvDpzn4Y9+wtVF+Pzx9gTrx6J2y/fff0+fPn346KOPyMzMNFuOadjSZxEMnMszHQXkfz3tTWC9iDwLVAK6FbQhEXkSeBKgdu3axdXq8Fgsiu8PX2DGxhMcv5hKg+qVmfVwa+oE6EjZ9srq1asZPHgwzZo1Y8OGDXh4lN9gQbaYRUHP7vJ/1z4cWKCUekdEOgCLROROpZTlupWUmgfMA+MT9VsR7IhYLIqIwxeY8cMJjl1IpX61SswY1pI+dwXpUcTtmG+++YahQ4fSqlUrIiIi8PPzM1uSqdhiFlFArTzTIdzYzBgD9ARQSu0SEU8gAIgtCZGOzMYjF5m+/jjHLqRST5uEQ3H+/HnatWvH2rVr8fX1NVuO6RQZ/EZE3IDfgXAgGvgZeFgpdThPmnXAMqXUAhFpAvwABKtCNl4egt+sORDDuC/2Uy+gEs+FN6RvC20SjkB8fDwBAcawBzk5Obi5OdcbBqUW/EYplQOMAyKAoxhPPQ6LyBQRuRon7AXgCRH5DVgCjCrMKMoDZ+IvM+nrg7SqXYXvn+/EgFbB2igcgPnz51OvXj1+/fVXAKczitvBppxQSq0F1uab93qe30eA+0pWmuOSmZPLuCW/4OoizBzeigpuOiCZIzB79myeeeYZevbsyR133GG2HLtDl+JS4L9rj3EoOoX/G3wXIX5eZsvR2MCMGTN45pln6Nu3L99++y0VK+pH2fnRZlHCfH/oPAt+PMPo++ryQLMaZsvR2MB3333H888/z8CBA/nqq6/K9ePRwtBmUYKcS0znpa8O0CLEl0m9GpstR2MjPXr0YObMmSxdupQKFfTr9jdDm0UJkZmTy7gvfgHgg4db634KO0cpxXvvvUdMTAxubm6MGzcOd3f9AV9h6BJdApxLTGfInF38FpXM24Puopa/7qewZ5RSTJo0iQkTJjBv3jyz5TgM+rnQbRJx+AIvLv8NgLmPtqGH7qewa5RSTJgwgRkzZvD000/z+uuvF72SBtBmcctk5ViY9v0xPtlxmrtCfJn1cGtdo7BzLBYL48aNY/bs2YwfP553333X6UPhlSTaLG6BK1m5jJy/hz1nEhl1bx0m926Mh5uOuG3vpKamsn37dl5++WWmTp2qjaKYaLMoJrkWxfil+/n5bCIzhrWkf8tgsyVpiiAnJweLxYKvry8//vgjlStX1kZxC+gOzmLy1ndHWH/kIm/0aaqNwgHIzs7m0UcfZejQoVgsFry9vbVR3CLaLIrB/B2n+XSn8cLVqPvqmi1HUwRZWVkMGzaMpUuXcu+99+Lioov77aCbITay9uB5/vXdEXo0C+TVB5uYLUdTBJmZmQwZMoTVq1fz3nvvMX78eLMlOTzaLGxgy/FYxi/dT+vafrw3tJX+etQBGDVqFKtXr+bDDz/k6aefNluOU6DNogh+OpXA2MX7aBTozfxRd+txRh2E559/ngceeIDHHnvMbClOg27EFcKBqEuMWbiX4CoV+Wx0O3wr6teB7ZnU1FQ+//xzANq3b6+NooTRZnETfr+Yysj5e6jiZYTpr1pZf4lozyQnJ9OjRw9GjhzJ8ePHzZbjlOhmSAH8kZDOIx//hLurC58/3p6avjq2gT2TlJREjx492L9/P8uWLdOBa0oJbRb5uJCcwcMf7yYr18KXT3UgtKoO02/PxMfH0717d44cOcI333xD3759zZbktGizyENCWiaPfPITl9Kz+eKJ9jQK9DZbkqYINm/ezPHjx1m5ciU9e/Y0W45To83Cyr6zSbz81W9EJV3hs9HtuCukitmSNIVgsVhwcXFhyJAhdOzYkZo1a5otyekp9x2cyVeyeXXFQQbP+ZH0rFw+fexu2terarYsTSFERUXRqlUrNm/eDKCNoowotzULpRTfHTzPP1cfISEtk8furcvEBxpR2aPcZolDcObMGbp27UpCQoKOlVnGlMsr41xiOq+vPMTm43HcGezD/JF30zxEjzhl75w8eZKuXbuSkpLCxo0bufvuu82WVK4od2ZxOCaZIXN2AfCPPk0Z2SEUN9dy3xqze2JiYggLCyMjI4NNmzbRqlUrsyWVO8qVWWTlWHhx+QEqebix4pl79ZgeDkSNGjUYMmQIo0ePpnnz5mbLKZeUK7OYveUkR8+nMO/RNtooHISDBw/i4+NDaGgo7777rtlyyjXlpv59JCaFmZtO0L9lkB78x0H45Zdf6Ny5MyNHjjRbioZyYhbZuRZe+uo3qni582bfZmbL0djAnj17CA8Px9vbm/nz55stR0M5MYs5W05yOCaFtwY0x6+SHnHK3tm5cyfdunXD39+frVu3Uq9ePbMlaSgHZnHsQgrvbzpB3xZB9LxTNz/sHaUUr776KjVr1mTbtm2EhoaaLUljxSazEJGeInJcRCJFZNJN0vxFRI6IyGER+aJkZd46b605io+nO//sp5sfjoCI8PXXX7N161aCg3VAZHuiSLMQEVdgFtALaAoMF5Gm+dI0BCYD9ymlmgHPl4LWYqOUYv8fSfRtEYS/bn7YNevWrWPgwIFkZmZStWpVatTQtUB7w5aaRTsgUil1SimVBSwF+udL8wQwSymVBKCUii1ZmbdGTHIGl7NyaRhY2WwpmkJYtWoVAwYM4OxaSVAYAAAViElEQVTZs6Snp5stR3MTbDGLYOBcnuko67y8NAIaichOEdktIgV+KywiT4rIXhHZGxcXd2uKi8HvF1MBaFhdf2pur3z11VcMGjSIli1b8sMPP+Dn52e2JM1NsMUsCgplrfJNuwENgc7AcOBjEbnhG2+l1DylVFulVNtq1aoVV2uxibyYBkDD6rpmYY98+eWXDBs2jHbt2rFhwwaqVNFhAewZW8wiCqiVZzoEiCkgzUqlVLZS6jRwHMM8TOX3i6kEVPbQj0vtlEaNGtG3b18iIiLw8fExW46mCGwxi5+BhiJSV0QqAMOAVfnSfAt0ARCRAIxmyamSFHor/B6bRiPdX2F37Nu3D4CWLVuyYsUKKlfW58gRKNIslFI5wDggAjgKfKmUOiwiU0SknzVZBJAgIkeAzcBLSqmE0hJtC5k5uZy4mKqbIHbGrFmzaNu2LUuWLDFbiqaY2PQhmVJqLbA237zX8/xWwETrn12w+Vgc6Vm5dGlc3WwpGivvvvsuEydOpH///gwcONBsOZpi4rRvcH7zSxTVvD3o2CDAbCkaYOrUqUycOJHBgwezfPlyHeXKAXFKs0i8nMXm47EMaBmkA9vYAQcPHuSVV15h+PDhLFmyBHd3PbKbI+KU8SzWHIghO1fxUKsQs6VogObNm7N582Y6duyIq6seK9ZRccrb7te/RNO4hjdNg/TjOLNQSjF58mTWrVsHQFhYmDYKB8fpzOJkXBq/nbvEoNa6VmEWSinGjx/P1KlT2bhxo9lyNCWE0zVDVvwSjYtA/5ZBZkspl1gsFp555hnmzp3LxIkTmT59utmSNCWEU9UsLBbFiv3R3N+wGtV9PM2WU+7Izc3l8ccfZ+7cuUyaNInp06cjUtDXAhpHxKnM4qfTiURfusLA1joOghmICO7u7rzxxhv85z//0UbhZDhVM2TtwfNUdHflgaY6FkJZkp2dTWxsLMHBwcyZM0ebhJPiNDULpRQbj17k/oYBVKyge93LiqysLIYOHcp9991HamqqNgonxmnM4lB0CueTM+jeNNBsKeWGjIwMBg4cyIoVK5g4cSLe3jpuiDPjNM2QDUcu4CIQ3kSbRVlw5coVBgwYwPr165kzZw5PPfWU2ZI0pYzTmMX6IxdpW8dfx9osI1599VU2bNjAJ598wujRo82WoykDnKIZci4xnWMXUnlAN0HKjDfeeIOVK1dqoyhHOIVZrD9yEUD3V5QyycnJvPDCC1y5cgVfX1/69u1rtiRNGeLwZpGVY+HLn89xR6A3oVUrmS3HaUlMTKRbt27MnDmTn3/+2Ww5GhNweLP4cEskxy+m8lKPO8yW4rTEx8cTHh7OgQMH+Oabb+jUqZPZkjQm4NAdnEdiUvhgUyQPtQqmm26ClAoXL14kPDyckydPsnr1ah544AGzJWlMwmHNwmJR1pHRK/BG36ZFr6C5JRITE7l8+TLfffcdXbt2NVuOxkQc1iz2nk3icEwK/zf4Lqp46celJU1SUhJVqlShSZMmHD9+nAoVdB6Xdxy2z2Llr9FUdHeld/OaZktxOs6cOUObNm146623ALRRaAAHNYvsXAtrD56nW9NAKnk4bOXILomMjKRTp05cunSJXr16mS1HY0c45JW2IzKepPRs+rXQAW5KkmPHjhEeHk5WVhabNm2iZcuWZkvS2BEOaRarf4vBx9ONTo10mP+SIj09nW7dupGbm8vmzZu58847zZaksTMc0iz2nU3ivgYBeLjpT9FLCi8vL2bMmEGzZs1o3Lix2XI0dojD9VlkZOfyR2I6jQL159Alwb59+1i1yhi6dtCgQdooNDfF4WoWkbFpKIU2ixJg9+7d9OzZk8DAQHr16qUH/9EUisPVLCJj0wBoqEdHvy127NhB9+7dCQgIYMOGDdooNEXicGbx+8VU3FyEOvqjsVtmy5Yt9OjRg+DgYLZu3Urt2rXNlqRxABzOLE7EplEnoBIV3BxOut2wdu1a6tSpw5YtWwgO1pHQNbbhcFfciYupNNJNkFsiMzMTgGnTpvHjjz9So4aOgq6xHZvMQkR6ishxEYkUkUmFpBssIkpE2pacxD/JzrVwLukK9QK0WRSXb7/9lsaNG3Py5ElEBF9fX7MlaRyMIs1CRFyBWUAvoCkwXERu+MxTRLyB54CfSlrkVaKTrpBrUdSu6lVau3BKli9fzpAhQ6hRowZVq1Y1W47GQbGlZtEOiFRKnVJKZQFLgf4FpPsX8DaQUYL6ruNsYjoAof7aLGzliy++YNiwYdxzzz1ERERQpUoVsyVpHBRbzCIYOJdnOso67xoi0gqopZRaU9iGRORJEdkrInvj4uKKLfaPhMsAOnyejXz33Xc88sgjhIWFsW7dOnx8fMyWpHFgbDGLgoaYUtcWirgA7wIvFLUhpdQ8pVRbpVTbatWq2a7SytmEdDzcXKju7VHsdcsjnTp14sUXX2TNmjVUrqz7eTS3hy1mEQXUyjMdAsTkmfYG7gS2iMgZ4B5gVWl0cp5NTKe2vxcuLnqIvMJYvnw5aWlpeHt78/bbb+PlpZttmtvHFrP4GWgoInVFpAIwDFh1daFSKlkpFaCUqqOUqgPsBvoppfaWtNg/EtIJ1Z2bhfLOO+/wl7/8hXfeecdsKRono0izUErlAOOACOAo8KVS6rCITBGRfqUtMI8O/khMp7a/7q+4Gf/973958cUXGTJkCK+88orZcjROhk0fkiml1gJr8817/SZpO9++rBuJT8viSnYutf0rlsbmHRqlFFOmTOHNN9/kr3/9KwsWLMDNzeG+EdTYOQ7zBmdUkvHYNMRPN0Pyk5CQwNy5cxk1ahQLFy7URqEpFRymVEVfugJAiK5ZXEMp46FUQEAAe/bsISgoCBcXh/F/jYPhMCUrOskwi+Aq2izAMIrx48czceJElFKEhIRoo9CUKg5TuqKSruDj6Ya3p467YLFYGDt2LDNnztQGoSkzHKakRV+6QrDuryA3N5cxY8Ywb948Jk+ezPTp0xHR751oSh/HMYukK4T46SbIE088wYIFC3jzzTf597//rY1CU2Y4RAenUoroS1foUF9/Mdm3b18aNWrEpEk3jRSg0ZQKDmEWKVdySMvMKbc1i8zMTHbv3k1YWBgPPfSQ2XI05RSHaIacs75jUR6fhGRkZDBw4EC6devG6dOnzZajKcc4RM3i+IVUoPxF9E5PT2fAgAFs3LiROXPmULduXbMlacoxDmEWh2NSqOjuSt1yFE4vLS2Nvn37snXrVubPn8+oUaPMlqQp5ziEWRyKSaZxTW9cy9Gn6V988QXbt29n8eLFPPzww2bL0Wjs3ywsFsXRmBQGtCpfIeufeOIJ2rVrp0cy19gNdt/B+UdiOqmZOTQLcv6QcImJifTu3ZsjR44gItooNHaF3ZvF4ZgUAJoFOXfo+ri4OLp06cKmTZs4d+5c0StoNGWM3TdDoi9ZI3oHOO+r3hcuXCA8PJzTp0+zevVqunfvbrYkjeYG7N4sYlMy8XBzwdvD7qXeEhcuXCAsLIzo6GjWrl1L586dzZak0RSI3TdD4tIyqe7j4bTfQPj4+NCkSRMiIiK0UWjsGru/XcemZFLd29NsGSXOmTNn8PPzw9fXl2+//dZsORpNkdh9zSI2NcPpxgk5ceIE999/P4888ojZUjQam3EAs8h0KrM4duwYYWFhZGRk8NZbb5ktR6OxGbtuhmRk55KakUN1H+dohhw6dIjw8HBEhC1bttCsWTOzJWk0NmPXZhGXmglAtcqOX7NQSjFy5Ejc3NzYtGkTd9xxh9mSNJpiYddmEZtqDMhezcfxzUJEWLZsGQANGjQwWY1GU3zsus8iNsWoWThyn8WuXbt48cUXUUrRoEEDbRQah8WuzSIu7apZOGafxbZt23jggQdYuXIliYmJZsvRaG4L+zaL1ExcBPwrVTBbSrHZtGkTvXr1IiQkhK1bt1K1qo4fqnFs7NossnMVbq4uDhfHYv369Tz44IPUq1ePLVu2EBQUZLYkjea2sWuzcFRycnK466672Lx5M4GBgWbL0WhKBG0WJUhUVBQAvXv3ZteuXQQEBJisSKMpOWwyCxHpKSLHRSRSRG4YsEJEJorIERE5ICI/iEhoyUu1b5YtW0b9+vVZu3YtgB5WUON0FFmiRcQVmAX0ApoCw0Wkab5k+4G2Sqm7gK+At0taqD1zNU5m+/btuf/++82Wo9GUCrbc/toBkUqpU0qpLGAp0D9vAqXUZqVUunVyNxBSsjLtl/nz5zNixAg6d+7MunXr8Pb2NluSRlMq2GIWwUDeOG9R1nk3YwywrqAFIvKkiOwVkb1xcXG2q7RT9u3bx5gxY+jevTtr1qyhUqVKZkvSaEoNW8yioOeWqsCEIo8AbYH/K2i5UmqeUqqtUqpttWrVbFdpp7Rp04ZFixaxcuVKKlYsf6OlacoXtphFFFArz3QIEJM/kYh0A14F+imlMktGnn0yc+ZMfvvtNwAeeeQRPD0d8w1TjaY42GIWPwMNRaSuiFQAhgGr8iYQkVbAXAyjiC15mfbDv//9b5577jnmzJljthSNpkwp0iyUUjnAOCACOAp8qZQ6LCJTRKSfNdn/AZWB5SLyq4isusnmHBalFG+88QavvfYajzzyCDNnzjRbkkZTptj0ibpSai2wNt+81/P87lbCuuwKpRSTJ09m2rRpPPbYY3z00Ue4urqaLUujKVP0m0M2kJOTw2+//cbYsWP5+OOPtVFoyiV2HfzGbCwWC5cvX8bb25tvv/2WChUqOO2QBBpNUeiaxU2wWCw89dRTdOnShfT0dDw8nHfsEo3GFrRZFEBubi6jR4/m448/plevXvodCo0G3Qy5gZycHEaMGMGSJUuYMmUK//jHP8yWpNHYBdos8vHiiy+yZMkSpk2bxssvv2y2HI3GbtBmkY8JEybQrFkznnjiCbOlaDR2he6zAK5cucKMGTOwWCyEhoZqo9BoCqDcm0V6ejr9+vVjwoQJ7Ny502w5Go3dUq6bIWlpafTp04ft27ezYMECHbhGoymEcmsWKSkp9OrVi59++onFixczfPhwsyVpNHZNuTWLw4cPc+jQIZYtW8agQYPMlqPR2D3lziyys7Nxd3enQ4cOnD59Gn9/f7MlaTQOQbnq4IyNjeXuu+/m008/BdBGodEUg3JTszh//jzdunXj9OnT1KpVq+gVNBrNdZQLs4iOjqZr165ER0ezbt06wsLCzJak0TgcTm8WqamphIWFERsbS0REBPfdd5/ZkjQah8TpzcLb25unn36ajh070r59e7PlaDQOi9OaxYkTJ7h06RJ33303L7zwgtlyNBqHxynN4ujRo3Tt2hUfHx8OHz6Mm5tTHqZGU6Y43aPTgwcPXuvAXLFihTYKjaaEcCqz2L9/P126dKFChQps3bqVpk3zj9+s0WhuFacyixkzZlCpUiW2bt1Ko0aNzJaj0TgVTlFHV0ohIsydO5f4+HiCgwsbt1mj0dwKDl+z2LZtGx07diQhIQEPDw9tFBpNKeHQZvHDDz/Qs2dPEhMTycrKMluORuPUOKxZfP/99/Tp04f69euzZcsWatasabYkjcapcUizWL9+Pf3796dx48Zs3ryZwMBAsyVpNE6PQ5pFs2bNeOihh9i0aRMBAQFmy9FoygUOZRY7duwgNzeX4OBgli5dip+fn9mSNJpyg8OYxWeffUZYWBjTp083W4pGUy6xySxEpKeIHBeRSBGZVMByDxFZZl3+k4jUKUmRn3zyCaNGjaJz586MGzeuJDet0WhspEizEBFXYBbQC2gKDBeR/O9RjwGSlFINgHeBaSUhrlFgZepWSOXxxx+nR48erFmzhkqVKpXEpjUaTTGxpWbRDohUSp1SSmUBS4H++dL0BxZaf38FhIuI3K64e4Pc2Pn2aPr27cu3336rRzPXaEzElte9g4FzeaajgPxRZK6lUUrliEgyUBWIz5tIRJ4EngSoXbt2kTuuUaMGO3bsoGnTplSoUMEGqRqNprSwpWZRUA1B3UIalFLzlFJtlVJtq1WrZos+WrZsqY1Co7EDbDGLKCBvOOwQIOZmaUTEDfAFEktCoEajsQ9sMYufgYYiUldEKgDDgFX50qwCRlp/DwY2KaVuqFloNBrHpcg+C2sfxDggAnAF5iulDovIFGCvUmoV8AmwSEQiMWoUw0pTtEajKXtsimehlFoLrM037/U8vzOAISUrTaPR2BMO8wanRqMxF20WGo3GJrRZaDQam9BmodFobELMesIpInHAWRuSBpDvTVA7xN412rs+0BpLAlv1hSqlbHsrMg+mmYWtiMhepVRbs3UUhr1rtHd9oDWWBKWtTzdDNBqNTWiz0Gg0NuEIZjHPbAE2YO8a7V0faI0lQanqs/s+C41GYx84Qs1Co9HYAdosNBqNTdiNWZgdFLgE9E0UkSMickBEfhCR0LLUZ4vGPOkGi4gSkTJ/DGiLRhH5izUvD4vIF/akT0Rqi8hmEdlvPde9y1jffBGJFZFDN1kuIvK+Vf8BEWldYjtXSpn+h/Hp+0mgHlAB+A1omi/NM8Ac6+9hwDI709cF8LL+fros9dmq0ZrOG9gG7Aba2ptGoCGwH/CzTle3M33zgKetv5sCZ8o4DzsBrYFDN1neG1iHEb3uHuCnktq3vdQsTAsKXFL6lFKblVLp1sndGBHFyhJb8hDgX8DbQEZZirNii8YngFlKqSQApVSsnelTgI/1ty83Ro0rVZRS2yg8Cl1/4DNlsBuoIiIlMhCwvZhFQUGBg2+WRimVA1wNClwW2KIvL2Mw3L0sKVKjiLQCaiml1pSlsDzYko+NgEYislNEdotIzzJTZ5u+N4FHRCQKI8bLs2UjzWaKW1ZtxqbgN2VAiQUFLiVs3reIPAK0BcJKVVEBuy5g3jWNIuKCMabLqLISVAC25KMbRlOkM0btbLuI3KmUulTK2sA2fcOBBUqpd0SkA0aEuDuVUpbSl2cTpXad2EvNwt6DAtuiDxHpBrwK9FNKZZaRtqsUpdEbuBPYIiJnMNqzq8q4k9PW87xSKZWtlDoNHMcwD3vRNwb4EkAptQvwxPiAy16wqazeEmXZOVNIp40bcAqoy58dS83ypfkb13dwfmln+lphdI41tNc8zJd+C2XfwWlLPvYEFlp/B2BUqavakb51wCjr7yYYF6KUcT7W4eYdnA9yfQfnnhLbb1keZBEZ0Bv43XrBvWqdNwXjLg2Ggy8HIoE9QD0707cRuAj8av1bZW95mC9tmZuFjfkowP+AI8BBYJid6WsK7LQaya/AA2WsbwlwHsjGqEWMAcYCY/Pk3yyr/oMleY71694ajcYm7KXPQqPR2DnaLDQajU1os9BoNDahzUKj0diENguNRmMT2iw0Go1NaLPQaDQ28f/wbPcroVzohwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "aucf = auc(fpr, tpr)\n",
        "ax.plot(fpr, tpr, label='auc=%1.5f' % aucf)\n",
        "ax.set_title('Courbe ROC - classifieur de sentiments')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les n-grammes\n",
        "\n",
        "L'approche pr\u00e9sent\u00e9e ci-dessus ne tient pas compte de l'ordre des mots. Chaque phrase est convertie en un sac de mots (ou [bag of words](https://fr.wikipedia.org/wiki/Sac_de_mots)). Il est n\u00e9anmoins possible de tenir compte de s\u00e9quence plus ou moins longue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(None, None, 'If'),\n",
              " (None, 'If', 'you'),\n",
              " ('If', 'you', 'see'),\n",
              " ('you', 'see', 'it'),\n",
              " ('see', 'it', ','),\n",
              " ('it', ',', 'you'),\n",
              " (',', 'you', 'should')]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "generated_ngrams = ngrams(word_tokenize(X_train.iloc[0,0]), 3, pad_left=True, pad_right=True)\n",
        "list(generated_ngrams)[:7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[scikit-learn](http://scikit-learn.org/stable/modules/feature_extraction.html#limitations-of-the-bag-of-words-representation) permet d'essayer cette id\u00e9e simplement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 20347)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe2 = make_pipeline(CountVectorizer(ngram_range=(1, 2)),\n",
        "                      TfidfTransformer())\n",
        "pipe2.fit(X_train['sentance'])\n",
        "feat_train2 = pipe2.transform(X_train['sentance'])\n",
        "feat_train2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il y a plus de colonnes, on v\u00e9rifie malgr\u00e9 tout que les features ressemblent \u00e0 des couples de mots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['00',\n",
              " '10',\n",
              " '10 10',\n",
              " '10 and',\n",
              " '10 feet',\n",
              " '10 for',\n",
              " '10 minutes',\n",
              " '10 of',\n",
              " '10 on',\n",
              " '10 out']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cl = pipe2.steps[0]\n",
        "cl[1].get_feature_names()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est le cas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "feat_test2 = pipe2.transform(X_test['sentance'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf2 = RandomForestClassifier(n_estimators=50)\n",
        "clf2.fit(feat_train2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7693333333333333"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf2.score(feat_test2, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cela n'am\u00e9liore pas de fa\u00e7on significative. Il faudrait faire une cross-validation pour s'en assurer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## R\u00e9duire les dimensions avec une ACP\n",
        "\n",
        "C'est un moyen fr\u00e9quemment utilis\u00e9 pour r\u00e9duire les dimensions. On choisit le mod\u00e8le [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD) plut\u00f4t que l'[ACP](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA) dont l'impl\u00e9mentation ne supporte pas les features sparses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "pipe_svd = make_pipeline(CountVectorizer(), TruncatedSVD(n_components=300))\n",
        "pipe_svd.fit(X_train['sentance'])\n",
        "feat_train_svd = pipe_svd.transform(X_train['sentance'])\n",
        "feat_train_svd.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_svd = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd.fit(feat_train_svd, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6573333333333333"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test_svd = pipe.transform(X_test['sentance'])\n",
        "clf_svd.score(feat_test_svd, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et si on repart de TF-IDF :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6933333333333334"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_svd_tfidf = make_pipeline(CountVectorizer(), \n",
        "                     TfidfTransformer(),\n",
        "                     TruncatedSVD(n_components=300))\n",
        "pipe_svd_tfidf.fit(X_train['sentance'])\n",
        "feat_train_svd_tfidf = pipe_svd_tfidf.transform(X_train['sentance'])\n",
        "\n",
        "clf_svd_tfidf = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd_tfidf.fit(feat_train_svd_tfidf, y_train)\n",
        "\n",
        "feat_test_svd_tfidf = pipe_svd_tfidf.transform(X_test['sentance'])\n",
        "clf_svd_tfidf.score(feat_test_svd_tfidf, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est mieux mais cela reste moins bien que les le tf-idf sans r\u00e9duction de dimensions. Cela veut dire qu'il faut garder plus de dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec\n",
        "\n",
        "[word2vec](https://en.wikipedia.org/wiki/Word2vec) est une sorte d'ACP non lin\u00e9aire en ce sens qu'il r\u00e9duit les dimensions. Il faut lire [Analyse en composantes principales (ACP) et Auto Encoders](http://www.xavierdupre.fr/app/mlstatpy/helpsphinx/c_ml/rn/rn_9_auto.html) pour comprendre le lien entre ACP, ACP non lin\u00e9aire, r\u00e9seaux de neurones diabolo et compression. *word2vec* est plus d'une ACP non lin\u00e9aire car il prend en compte le contexte mais ne s'en \u00e9loigne pas tant que ce \u00e7a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['if',\n",
              " 'you',\n",
              " 'see',\n",
              " 'it',\n",
              " 'you',\n",
              " 'should',\n",
              " 'probably',\n",
              " 'just',\n",
              " 'leave',\n",
              " 'it',\n",
              " 'on',\n",
              " 'the',\n",
              " 'shelf']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.utils import tokenize\n",
        "sentance = [list(tokenize(s, deacc=True, lower=True)) for s in X_train['sentance']]\n",
        "sentance[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les param\u00e8tres d'apprentissage du mod\u00e8le [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) ne sont pas toujours d\u00e9crit de fa\u00e7on explicite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2250"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.models import word2vec\n",
        "model = word2vec.Word2Vec(sentance, size=300, window=20,\n",
        "                          min_count=2, workers=1, iter=100)\n",
        "model.corpus_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['if', 'you', 'see', 'it', 'should']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = model.wv.vocab\n",
        "list(vocab)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('trained_word2vec.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les dix premi\u00e8res coordonn\u00e9es du vecteur associ\u00e9 au mot ``after``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((300,),\n",
              " array([ 1.5655669 , -0.3461043 , -0.86914146,  0.29144952,  1.5173551 ,\n",
              "         1.5578845 , -1.0138339 , -1.3393453 , -0.08423068,  0.87053865],\n",
              "       dtype=float32))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv['after'].shape, model.wv['after'][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lorsque le mot est inconnu :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"word 'rrrrrrrr' not in vocabulary\"\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    model.wv['rrrrrrrr']\n",
        "except KeyError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour chaque phrase, on fait la somme des vecteurs associ\u00e9s aux mots qui la composent ou pas si le mot n'est pas dans le vocabulaire. Il y a probablement des fonctions d\u00e9j\u00e0 pr\u00eates \u00e0 l'emploi mais la documentation de [gensim](https://radimrehurek.com/gensim/index.html) n'\u00e9tait pas assez explicite et lire l'article [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) puis celui-ci [Distributed Representations of Words and Phrases\n",
        "and their Compositionality](https://arxiv.org/pdf/1310.4546.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def get_vect(word, model):\n",
        "    try:\n",
        "        return model.wv[word]\n",
        "    except KeyError:\n",
        "        return numpy.zeros((model.vector_size,))\n",
        "\n",
        "def sum_vectors(phrase, model):\n",
        "    return sum(get_vect(w, model) for w in phrase)\n",
        "\n",
        "def word2vec_features(X, model):\n",
        "    feats = numpy.vstack([sum_vectors(p, model) for p in X])\n",
        "    return feats\n",
        "\n",
        "wv_train_feat = word2vec_features(X_train[\"sentance\"], model)\n",
        "wv_train_feat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv = RandomForestClassifier(n_estimators=50)\n",
        "clfwv.fit(wv_train_feat, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv_test_feat = word2vec_features(X_test[\"sentance\"], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5986666666666667"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv.score(wv_test_feat, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La performance est nettement moindre et notamment moindre que la performance obtenue avec l'*ACP*. Il faudrait sans doute jouer avec les hyperparam\u00e8tres de l'apprentissage ou r\u00e9utiliser un model appris sur un corpus similaire aux donn\u00e9es initiales mais nettement plus grand. On peut constater que la fonction de similarit\u00e9s ne retourne pas des r\u00e9sultat tr\u00e8s int\u00e9ressants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9526177798855179"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv.similarity(\"after\", \"before\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4183273846551096"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv.similarity(\"after\", \"greek\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9925711421981278"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv.similarity(\"dressing\", \"greek\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec pr\u00e9-entra\u00een\u00e9s\n",
        "\n",
        "Ce mod\u00e8le est plus performant avec plus de donn\u00e9es.\n",
        "On peut t\u00e9l\u00e9charger des mod\u00e8les pr\u00e9-entra\u00eener sur des donn\u00e9es plus volumineuses :\n",
        " [Pre-Trained Word2Vec Models](https://github.com/jhlau/doc2vec) ou encore [Pre-trained word vectors of 30+ languages](https://github.com/Kyubyong/wordvectors). Ceux-ci sont plut\u00f4t gros (> 600 Mo). Le module *spacy* propose une version plus l\u00e9g\u00e8re et mieux document\u00e9e [Word Vectors and Semantic Similarity](https://spacy.io/usage/vectors-similarity) avec les donn\u00e9es [en_core_web_md](https://github.com/explosion/spacy-models/releases)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.cli import download\n",
        "# download(\"en_core_web_md\")  # \u00e7a ne marche pas toujours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "root = \"c:/temp/\"\n",
        "unzip_dest = root + 'en_core_web_md-2.0.0.tar/dist/en_core_web_md-2.0.0/' + \\\n",
        "                    'en_core_web_md/en_core_web_md-2.0.0'\n",
        "if os.path.exists(unzip_dest):\n",
        "    nlp = spacy.load(unzip_dest)\n",
        "    continue_wv = True\n",
        "else:\n",
        "    continue_wv = False\n",
        "    print('Pas de donn\u00e9es on passe la suite.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "after after 1.0\n",
            "after before 0.87566733\n",
            "after greek 0.08783853\n",
            "after dressing 0.24195954\n",
            "before after 0.87566733\n",
            "before before 1.0\n",
            "before greek 0.0960651\n",
            "before dressing 0.28992757\n",
            "greek after 0.08783853\n",
            "greek before 0.0960651\n",
            "greek greek 1.0\n",
            "greek dressing 0.28894117\n",
            "dressing after 0.24195954\n",
            "dressing before 0.28992757\n",
            "dressing greek 0.28894117\n",
            "dressing dressing 1.0\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    tokens = nlp('after before greek dressing')\n",
        "    for token1 in tokens:\n",
        "        for token2 in tokens:\n",
        "            print(token1.text, token2.text, token1.similarity(token2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(300,) [ 0.2069    0.44321  -0.12522  -0.017724 -0.064277 -0.44308   0.014019\n",
            " -0.10119   0.22699   3.1689  ]\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(tokens[0].vector.shape, tokens[0].vector[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2250, 300)\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def spacy_sum_vectors(phrase, nlp):\n",
        "    dec = nlp(phrase)\n",
        "    return sum(w.vector for w in dec)\n",
        "\n",
        "def spacy_word2vec_features(X, nlp):\n",
        "    feats = numpy.vstack([spacy_sum_vectors(p, nlp) for p in X])\n",
        "    return feats\n",
        "\n",
        "if continue_wv:\n",
        "    wv_train_feat2 = spacy_word2vec_features(X_train[\"sentance\"], nlp)\n",
        "    print(wv_train_feat2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    clfwv2 = RandomForestClassifier(n_estimators=50)\n",
        "    clfwv2.fit(wv_train_feat2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    wv_test_feat2 = spacy_word2vec_features(X_test[\"sentance\"], nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7866666666666666\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(clfwv2.score(wv_test_feat2, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est un peu mieux mais un peu plus co\u00fbteux en temps de calcul mais m\u00eame sans entra\u00eenement, le mod\u00e8le obtenu est plus performant avec 300 dimensions que celui obtenu avec l'ACP. Le corpus ext\u00e9rieur au probl\u00e8me apporte de la valeur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}