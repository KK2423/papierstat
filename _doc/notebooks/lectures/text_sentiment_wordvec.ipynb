{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification de phrases avec word2vec\n",
        "\n",
        "Le texte est toujours d\u00e9licat \u00e0 traiter. La langue est importante et plus le vocabulaire est \u00e9tendu, plus il faut de donn\u00e9es. Le probl\u00e8me qui suit est classique, on cherche \u00e0 cat\u00e9goriser des phrases en sentiment positif ou n\u00e9gatif. Ce pourrait \u00eatre aussi classer des spams. Le probl\u00e8me le plus simple : une phrase, un label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les donn\u00e9es\n",
        "\n",
        "Elles proviennent de [Sentiment Labelled Sentences Data Set](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentance</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "      <td>amazon_cells_labelled</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentance  sentiment  \\\n",
              "0  So there is no way for me to plug it in here i...          0   \n",
              "1                        Good case, Excellent value.          1   \n",
              "2                             Great for the jawbone.          1   \n",
              "3  Tied to charger for conversations lasting more...          0   \n",
              "4                                  The mic is great.          1   \n",
              "\n",
              "                  source  \n",
              "0  amazon_cells_labelled  \n",
              "1  amazon_cells_labelled  \n",
              "2  amazon_cells_labelled  \n",
              "3  amazon_cells_labelled  \n",
              "4  amazon_cells_labelled  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from papierstat.datasets import load_sentiment_dataset\n",
        "df = load_sentiment_dataset()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>sentance</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">amazon_cells_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">imdb_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">yelp_labelled</th>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 sentance\n",
              "source                sentiment          \n",
              "amazon_cells_labelled 0               500\n",
              "                      1               500\n",
              "imdb_labelled         0               500\n",
              "                      1               500\n",
              "yelp_labelled         0               500\n",
              "                      1               500"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(['source', 'sentiment']).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On d\u00e9coupe en train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[[\"sentance\"]], df['sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## L'approche classique\n",
        "\n",
        "[TF-IDF](https://fr.wikipedia.org/wiki/TF-IDF) est une approche tr\u00e8s r\u00e9pandue lorsqu'il s'agit de convertir des phrases en features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 4320)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "pipe = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
        "pipe.fit(X_train['sentance'])\n",
        "feat_train = pipe.transform(X_train['sentance'])\n",
        "feat_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_train.min(), feat_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(750, 4320)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test = pipe.transform(X_test['sentance'])\n",
        "feat_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=50)\n",
        "clf.fit(feat_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.764"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.score(feat_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "score = clf.predict_proba(feat_test)\n",
        "fpr, tpr, th = roc_curve(y_test, score[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "aucf = auc(fpr, tpr)\n",
        "ax.plot(fpr, tpr, label='auc=%1.5f' % aucf)\n",
        "ax.set_title('Courbe ROC - classifieur de sentiments')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Les n-grammes\n",
        "\n",
        "L'approche pr\u00e9sent\u00e9e ci-dessus ne tient pas compte de l'ordre des mots. Chaque phrase est convertie en un sac de mots (ou [bag of words](https://fr.wikipedia.org/wiki/Sac_de_mots)). Il est n\u00e9anmoins possible de tenir compte de s\u00e9quence plus ou moins longue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(None, None, 'I'),\n",
              " (None, 'I', 'got'),\n",
              " ('I', 'got', 'home'),\n",
              " ('got', 'home', 'to'),\n",
              " ('home', 'to', 'see'),\n",
              " ('to', 'see', 'the'),\n",
              " ('see', 'the', 'driest')]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "generated_ngrams = ngrams(word_tokenize(X_train.iloc[0,0]), 3, pad_left=True, pad_right=True)\n",
        "list(generated_ngrams)[:7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[scikit-learn](http://scikit-learn.org/stable/modules/feature_extraction.html#limitations-of-the-bag-of-words-representation) permet d'essayer cette id\u00e9e simplement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 20057)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe2 = make_pipeline(CountVectorizer(ngram_range=(1, 2)),\n",
        "                      TfidfTransformer())\n",
        "pipe2.fit(X_train['sentance'])\n",
        "feat_train2 = pipe2.transform(X_train['sentance'])\n",
        "feat_train2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il y a plus de colonnes, on v\u00e9rifie malgr\u00e9 tout que les features ressemblent \u00e0 des couples de mots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['00',\n",
              " '10',\n",
              " '10 10',\n",
              " '10 feet',\n",
              " '10 for',\n",
              " '10 minutes',\n",
              " '10 of',\n",
              " '10 on',\n",
              " '10 out',\n",
              " '10 plus']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cl = pipe2.steps[0]\n",
        "cl[1].get_feature_names()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est le cas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "feat_test2 = pipe2.transform(X_test['sentance'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf2 = RandomForestClassifier(n_estimators=50)\n",
        "clf2.fit(feat_train2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7626666666666667"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf2.score(feat_test2, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cela n'am\u00e9liore pas de fa\u00e7on significative. Il faudrait faire une cross-validation pour s'en assurer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## R\u00e9duire les dimensions avec une ACP\n",
        "\n",
        "C'est un moyen fr\u00e9quemment utilis\u00e9 pour r\u00e9duire les dimensions. On choisit le mod\u00e8le [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD) plut\u00f4t que l'[ACP](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA) dont l'impl\u00e9mentation ne supporte pas les features sparses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "pipe_svd = make_pipeline(CountVectorizer(), TruncatedSVD(n_components=300))\n",
        "pipe_svd.fit(X_train['sentance'])\n",
        "feat_train_svd = pipe_svd.transform(X_train['sentance'])\n",
        "feat_train_svd.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_svd = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd.fit(feat_train_svd, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6986666666666667"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_test_svd = pipe_svd.transform(X_test['sentance'])\n",
        "clf_svd.score(feat_test_svd, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et si on repart de TF-IDF :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7053333333333334"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_svd_tfidf = make_pipeline(CountVectorizer(), \n",
        "                     TfidfTransformer(),\n",
        "                     TruncatedSVD(n_components=300))\n",
        "pipe_svd_tfidf.fit(X_train['sentance'])\n",
        "feat_train_svd_tfidf = pipe_svd_tfidf.transform(X_train['sentance'])\n",
        "\n",
        "clf_svd_tfidf = RandomForestClassifier(n_estimators=50)\n",
        "clf_svd_tfidf.fit(feat_train_svd_tfidf, y_train)\n",
        "\n",
        "feat_test_svd_tfidf = pipe_svd_tfidf.transform(X_test['sentance'])\n",
        "clf_svd_tfidf.score(feat_test_svd_tfidf, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est mieux mais cela reste moins bien que le *tf-idf* sans r\u00e9duction de dimensions. Cela veut dire qu'il faut garder plus de dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec\n",
        "\n",
        "[word2vec](https://en.wikipedia.org/wiki/Word2vec) est une sorte d'ACP non lin\u00e9aire en ce sens qu'il r\u00e9duit les dimensions. Il faut lire [Analyse en composantes principales (ACP) et Auto Encoders](http://www.xavierdupre.fr/app/mlstatpy/helpsphinx/c_ml/rn/rn_9_auto.html) pour comprendre le lien entre ACP, ACP non lin\u00e9aire, r\u00e9seaux de neurones diabolo et compression. *word2vec* est plus d'une ACP non lin\u00e9aire car il prend en compte le contexte mais ne s'en \u00e9loigne pas tant que ce \u00e7a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python365_x64\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
            "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['i', 'got', 'home', 'to', 'see', 'the', 'driest', 'damn', 'wings', 'ever']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.utils import tokenize\n",
        "sentance = [list(tokenize(s, deacc=True, lower=True)) for s in X_train['sentance']]\n",
        "sentance[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les param\u00e8tres d'apprentissage du mod\u00e8le [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) ne sont pas toujours d\u00e9crit de fa\u00e7on explicite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2250"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.models import word2vec\n",
        "model = word2vec.Word2Vec(sentance, size=300, window=20,\n",
        "                          min_count=2, workers=1, iter=100)\n",
        "model.corpus_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i', 'got', 'home', 'to', 'see']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = model.wv.vocab\n",
        "list(vocab)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('trained_word2vec.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les dix premi\u00e8res coordonn\u00e9es du vecteur associ\u00e9 au mot ``after``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((300,),\n",
              " array([-0.8605097 , -0.5213117 , -1.1111898 ,  0.02232992, -0.865633  ,\n",
              "        -1.5479972 , -1.0050113 ,  0.8964202 , -0.7618984 ,  0.08574714],\n",
              "       dtype=float32))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv['after'].shape, model.wv['after'][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lorsque le mot est inconnu :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"word 'rrrrrrrr' not in vocabulary\"\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    model.wv['rrrrrrrr']\n",
        "except KeyError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour chaque phrase, on fait la somme des vecteurs associ\u00e9s aux mots qui la composent ou pas si le mot n'est pas dans le vocabulaire. Il y a probablement des fonctions d\u00e9j\u00e0 pr\u00eates \u00e0 l'emploi mais la documentation de [gensim](https://radimrehurek.com/gensim/index.html) n'\u00e9tait pas assez explicite et lire l'article [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) puis celui-ci [Distributed Representations of Words and Phrases\n",
        "and their Compositionality](https://arxiv.org/pdf/1310.4546.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2250, 300)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def get_vect(word, model):\n",
        "    try:\n",
        "        return model.wv[word]\n",
        "    except KeyError:\n",
        "        return numpy.zeros((model.vector_size,))\n",
        "\n",
        "def sum_vectors(phrase, model):\n",
        "    return sum(get_vect(w, model) for w in phrase)\n",
        "\n",
        "def word2vec_features(X, model):\n",
        "    feats = numpy.vstack([sum_vectors(p, model) for p in X])\n",
        "    return feats\n",
        "\n",
        "wv_train_feat = word2vec_features(X_train[\"sentance\"], model)\n",
        "wv_train_feat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv = RandomForestClassifier(n_estimators=50)\n",
        "clfwv.fit(wv_train_feat, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "wv_test_feat = word2vec_features(X_test[\"sentance\"], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5693333333333334"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clfwv.score(wv_test_feat, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La performance est nettement moindre et notamment moindre que la performance obtenue avec l'*ACP*. Il faudrait sans doute jouer avec les hyperparam\u00e8tres de l'apprentissage ou r\u00e9utiliser un model appris sur un corpus similaire aux donn\u00e9es initiales mais nettement plus grand. On peut constater que la fonction de similarit\u00e9s ne retourne pas des r\u00e9sultat tr\u00e8s int\u00e9ressants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a',\n",
              " 'ability',\n",
              " 'able',\n",
              " 'about',\n",
              " 'above',\n",
              " 'absolutely',\n",
              " 'abysmal',\n",
              " 'accept',\n",
              " 'access',\n",
              " 'accidentally']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = list(sorted(model.wv.vocab))\n",
        "words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>about</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.061235</td>\n",
              "      <td>-0.028419</td>\n",
              "      <td>0.383403</td>\n",
              "      <td>0.036102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>above</th>\n",
              "      <td>-0.061235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.267196</td>\n",
              "      <td>0.071003</td>\n",
              "      <td>0.168092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>-0.028419</td>\n",
              "      <td>0.267196</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.039037</td>\n",
              "      <td>0.317163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0.383403</td>\n",
              "      <td>0.071003</td>\n",
              "      <td>0.039037</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.349647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>0.036102</td>\n",
              "      <td>0.168092</td>\n",
              "      <td>0.317163</td>\n",
              "      <td>0.349647</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             about     above  absolutely     after    before\n",
              "w1                                                            \n",
              "about       1.000000 -0.061235   -0.028419  0.383403  0.036102\n",
              "above      -0.061235  1.000000    0.267196  0.071003  0.168092\n",
              "absolutely -0.028419  0.267196    1.000000  0.039037  0.317163\n",
              "after       0.383403  0.071003    0.039037  1.000000  0.349647\n",
              "before      0.036102  0.168092    0.317163  0.349647  1.000000"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subset = ['after', 'before', words[3], words[4], words[5]]\n",
        "rows = []\n",
        "for w in subset:\n",
        "    for ww in subset:\n",
        "        rows.append(dict(w1=w, w2=ww, d=model.wv.similarity(w, ww)))\n",
        "import pandas\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## word2vec pr\u00e9-entra\u00een\u00e9s\n",
        "\n",
        "Ce mod\u00e8le est plus performant avec plus de donn\u00e9es.\n",
        "On peut t\u00e9l\u00e9charger des mod\u00e8les pr\u00e9-entra\u00eener sur des donn\u00e9es plus volumineuses :\n",
        " [Pre-Trained Word2Vec Models](https://github.com/jhlau/doc2vec) ou encore [Pre-trained word vectors of 30+ languages](https://github.com/Kyubyong/wordvectors). Ceux-ci sont plut\u00f4t gros (> 600 Mo). Le module *spacy* propose une version plus l\u00e9g\u00e8re et mieux document\u00e9e [Word Vectors and Semantic Similarity](https://spacy.io/usage/vectors-similarity) avec les donn\u00e9es [en_core_web_md](https://github.com/explosion/spacy-models/releases)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.cli import download\n",
        "# download(\"en_core_web_md\")  # \u00e7a ne marche pas toujours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T\u00e9l\u00e9chargement de  en_core_web_md-2.0.0.tar.gz\n",
            "Found en_core_web_md-2.0.0/en_core_web_md/en_core_web_md-2.0.0\n",
            "Chargement des donn\u00e9es par spacy.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "unzip_dest = 'en_core_web_md-2.0.0.tar/dist/en_core_web_md-2.0.0/en_core_web_md/en_core_web_md-2.0.0'\n",
        "if not os.path.exists(unzip_dest):\n",
        "    from pyquickhelper.pycode import is_travis_or_appveyor\n",
        "    if not is_travis_or_appveyor():\n",
        "        # On le fait seulement si ce n'est pas un test d'int\u00e9gration continue.\n",
        "        url = \"https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/\"\n",
        "        name = \"en_core_web_md-2.0.0.tar.gz\"\n",
        "        print(\"T\u00e9l\u00e9chargement de \", name)\n",
        "        from pyensae.datasource import download_data\n",
        "        unzipped = download_data(name, url=url, fLOG=print)\n",
        "        unzip_dest = os.path.split(unzipped[0])[0]\n",
        "        unzip_dest = \"en_core_web_md-2.0.0/en_core_web_md/en_core_web_md-2.0.0\"\n",
        "        print(\"Found\", unzip_dest)\n",
        "        \n",
        "if os.path.exists(unzip_dest):\n",
        "    print(\"Chargement des donn\u00e9es par spacy.\")\n",
        "    nlp = spacy.load(unzip_dest)\n",
        "    continue_wv = True\n",
        "else:\n",
        "    continue_wv = False\n",
        "    print('Pas de donn\u00e9es on passe la suite.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>w2</th>\n",
              "      <th>about</th>\n",
              "      <th>above</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>after</th>\n",
              "      <th>before</th>\n",
              "      <th>films</th>\n",
              "      <th>greek</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>about</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.061235</td>\n",
              "      <td>-0.028419</td>\n",
              "      <td>0.383403</td>\n",
              "      <td>0.036102</td>\n",
              "      <td>0.251959</td>\n",
              "      <td>-0.151259</td>\n",
              "      <td>-0.085309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>above</th>\n",
              "      <td>-0.061235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.267196</td>\n",
              "      <td>0.071003</td>\n",
              "      <td>0.168092</td>\n",
              "      <td>-0.252266</td>\n",
              "      <td>0.424876</td>\n",
              "      <td>0.388087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absolutely</th>\n",
              "      <td>-0.028419</td>\n",
              "      <td>0.267196</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.039037</td>\n",
              "      <td>0.317163</td>\n",
              "      <td>-0.042051</td>\n",
              "      <td>0.450723</td>\n",
              "      <td>0.329339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0.383403</td>\n",
              "      <td>0.071003</td>\n",
              "      <td>0.039037</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.349647</td>\n",
              "      <td>0.224141</td>\n",
              "      <td>0.061423</td>\n",
              "      <td>-0.010883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>0.036102</td>\n",
              "      <td>0.168092</td>\n",
              "      <td>0.317163</td>\n",
              "      <td>0.349647</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.066547</td>\n",
              "      <td>0.133459</td>\n",
              "      <td>0.103670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>films</th>\n",
              "      <td>0.251959</td>\n",
              "      <td>-0.252266</td>\n",
              "      <td>-0.042051</td>\n",
              "      <td>0.224141</td>\n",
              "      <td>-0.066547</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.280047</td>\n",
              "      <td>0.233318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>greek</th>\n",
              "      <td>-0.151259</td>\n",
              "      <td>0.424876</td>\n",
              "      <td>0.450723</td>\n",
              "      <td>0.061423</td>\n",
              "      <td>0.133459</td>\n",
              "      <td>-0.280047</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.505065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>italian</th>\n",
              "      <td>-0.085309</td>\n",
              "      <td>0.388087</td>\n",
              "      <td>0.329339</td>\n",
              "      <td>-0.010883</td>\n",
              "      <td>0.103670</td>\n",
              "      <td>0.233318</td>\n",
              "      <td>0.505065</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "w2             about     above  absolutely     after    before     films  \\\n",
              "w1                                                                         \n",
              "about       1.000000 -0.061235   -0.028419  0.383403  0.036102  0.251959   \n",
              "above      -0.061235  1.000000    0.267196  0.071003  0.168092 -0.252266   \n",
              "absolutely -0.028419  0.267196    1.000000  0.039037  0.317163 -0.042051   \n",
              "after       0.383403  0.071003    0.039037  1.000000  0.349647  0.224141   \n",
              "before      0.036102  0.168092    0.317163  0.349647  1.000000 -0.066547   \n",
              "films       0.251959 -0.252266   -0.042051  0.224141 -0.066547  1.000000   \n",
              "greek      -0.151259  0.424876    0.450723  0.061423  0.133459 -0.280047   \n",
              "italian    -0.085309  0.388087    0.329339 -0.010883  0.103670  0.233318   \n",
              "\n",
              "w2             greek   italian  \n",
              "w1                              \n",
              "about      -0.151259 -0.085309  \n",
              "above       0.424876  0.388087  \n",
              "absolutely  0.450723  0.329339  \n",
              "after       0.061423 -0.010883  \n",
              "before      0.133459  0.103670  \n",
              "films      -0.280047  0.233318  \n",
              "greek       1.000000  0.505065  \n",
              "italian     0.505065  1.000000  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    tokens = nlp('after before greek italian films about above absolutely')\n",
        "    rows = []\n",
        "    for token1 in tokens:\n",
        "        for token2 in tokens:\n",
        "            sim = model.wv.similarity(token1.text, token2.text)\n",
        "            rows.append(dict(w1=token1.text, w2=token2.text, d=sim))\n",
        "pandas.DataFrame(rows).pivot(\"w1\", \"w2\", \"d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(300,) [ 0.2069    0.44321  -0.12522  -0.017724 -0.064277 -0.44308   0.014019\n",
            " -0.10119   0.22699   3.1689  ]\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(tokens[0].vector.shape, tokens[0].vector[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2250, 300)\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "\n",
        "def spacy_sum_vectors(phrase, nlp):\n",
        "    dec = nlp(phrase)\n",
        "    return sum(w.vector for w in dec)\n",
        "\n",
        "def spacy_word2vec_features(X, nlp):\n",
        "    feats = numpy.vstack([spacy_sum_vectors(p, nlp) for p in X])\n",
        "    return feats\n",
        "\n",
        "if continue_wv:\n",
        "    wv_train_feat2 = spacy_word2vec_features(X_train[\"sentance\"], nlp)\n",
        "    print(wv_train_feat2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    clfwv2 = RandomForestClassifier(n_estimators=50)\n",
        "    clfwv2.fit(wv_train_feat2, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_wv:\n",
        "    wv_test_feat2 = spacy_word2vec_features(X_test[\"sentance\"], nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7853333333333333\n"
          ]
        }
      ],
      "source": [
        "if continue_wv:\n",
        "    print(clfwv2.score(wv_test_feat2, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est un peu mieux mais un peu plus co\u00fbteux en temps de calcul mais m\u00eame sans entra\u00eenement, le mod\u00e8le obtenu est plus performant avec 300 dimensions que celui obtenu avec l'ACP. Le corpus ext\u00e9rieur au probl\u00e8me apporte de la valeur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}